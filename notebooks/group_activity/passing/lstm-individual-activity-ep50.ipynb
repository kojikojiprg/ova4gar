{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621a2a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid6/home/yokoyama/research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyama/research/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# back to project root\n",
    "%cd ~/research\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch import nn, optim\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "from group.passing.dataset import make_data_loaders, make_all_data\n",
    "from group.passing.lstm_model import LSTMModel\n",
    "from utility.activity_loader import load_individuals\n",
    "from utility.logger import logger\n",
    "from tools.train_passing import init_model, init_loss, init_optim, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc298add-7d1e-4c1a-8a98-767bde6e9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams[\"font.size\"] = 24\n",
    "plt.rcParams['xtick.direction'] = 'in'  # x axis in\n",
    "plt.rcParams['ytick.direction'] = 'in'  # y axis in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28083f0-6a29-4348-b2f0-6099f5289d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f8937b-15e0-489c-adfe-fc605429bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"config/passing/pass_train.yaml\"\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    train_cfg = yaml.safe_load(f)\n",
    "with open(train_cfg[\"config_path\"][\"individual\"], \"r\") as f:\n",
    "    ind_cfg = yaml.safe_load(f)\n",
    "with open(train_cfg[\"config_path\"][\"group\"], \"r\") as f:\n",
    "    grp_cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe7d65b-260f-4091-b271-5cf80ff3c575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:02<00:00, 10.49s/it]\n"
     ]
    }
   ],
   "source": [
    "data_dirs_all = {}\n",
    "for room_num, surgery_items in train_cfg[\"dataset\"][\"setting\"].items():\n",
    "    for surgery_num in surgery_items.keys():\n",
    "        dirs = sorted(glob(os.path.join(\"data\", room_num, surgery_num, \"passing\", \"*\")))\n",
    "        data_dirs_all[f\"{room_num}_{surgery_num}\"] = dirs\n",
    "\n",
    "inds = {}\n",
    "for key_prefix, dirs in tqdm(data_dirs_all.items()):\n",
    "    for model_path in dirs:\n",
    "        num = model_path.split(\"/\")[-1]\n",
    "        json_path = os.path.join(model_path, \".json\", \"individual.json\")\n",
    "        tmp_inds = load_individuals(json_path, ind_cfg)\n",
    "        for pid, ind in tmp_inds.items():\n",
    "            inds[f\"{key_prefix}_{num}_{pid}\"] = ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b174-dd28-4aa8-8d26-9bc4427a0163",
   "metadata": {},
   "source": [
    "# グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b443de49-2306-476a-b2bb-295506a68dc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 10:43:54,778 => createing time series 02_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.10it/s]\n",
      "2022-08-19 10:43:58,928 => createing time series 07_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:28<00:00,  1.69it/s]\n",
      "2022-08-19 10:44:27,258 => createing time series 08_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:05<00:00,  6.85it/s]\n",
      "2022-08-19 10:44:32,812 => createing time series 08_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:30<00:00,  1.46it/s]\n",
      "2022-08-19 10:45:03,560 => createing time series 09_001\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.12it/s]\n",
      "2022-08-19 10:45:06,451 => createing time series 09_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.22it/s]\n",
      "2022-08-19 10:45:19,579 => extracting feature 02_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:15<00:00,  1.07it/s]\n",
      "2022-08-19 10:45:35,517 => extracting feature 07_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:55<00:00,  1.15s/it]\n",
      "2022-08-19 10:46:30,591 => extracting feature 08_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  3.04it/s]\n",
      "2022-08-19 10:46:43,088 => extracting feature 08_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [01:02<00:00,  1.38s/it]\n",
      "2022-08-19 10:47:45,391 => extracting feature 09_001\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:09<00:00,  1.08s/it]\n",
      "2022-08-19 10:47:55,117 => extracting feature 09_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:40<00:00,  2.54s/it]\n",
      "2022-08-19 10:48:35,913 => create train loader\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:03<00:00, 2797.73it/s]\n",
      "2022-08-19 10:48:39,522 => skip creating val loader\n",
      "2022-08-19 10:48:39,523 => create test loader\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2520/2520 [00:00<00:00, 8946.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# create data loader\n",
    "dataset_cfg = train_cfg[\"dataset\"]\n",
    "passing_defs = grp_cfg[\"passing\"][\"default\"]\n",
    "train_loader, val_loader, test_loader = make_data_loaders(\n",
    "    inds, dataset_cfg, passing_defs, logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60011bb5-8a2a-497d-8f5e-a1fe6b56b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "mdl_cfg = {\n",
    "    \"dropouts\": [0.1, 0],\n",
    "    \"hidden_dims\": [128, 64],\n",
    "    \"n_classes\": 2,\n",
    "    \"n_linears\": 2,\n",
    "    \"rnn_dropout\": 0.1,\n",
    "    \"size\": 4,\n",
    "}\n",
    "\n",
    "# grid search parameters\n",
    "params = {\n",
    "    'n_rnns': [1, 2, 3],\n",
    "    'rnn_hidden_dim': [128, 256],\n",
    "    'pos_weight': [8, 16, 32]\n",
    "}\n",
    "\n",
    "# epoch\n",
    "# epoch_len = train_cfg[\"optim\"][\"epoch\"]\n",
    "epoch_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9a76f-fd7b-4bde-8e77-33dba46fd26a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 10:48:42,656 => start training\n",
      "2022-08-19 10:48:55,183 Epoch[1/50] train loss: 0.46141, val loss: nan, lr: 0.0010000, time: 12.53\n",
      "2022-08-19 10:49:05,681 Epoch[2/50] train loss: 0.39774, val loss: nan, lr: 0.0010000, time: 10.50\n",
      "2022-08-19 10:49:16,458 Epoch[3/50] train loss: 0.39448, val loss: nan, lr: 0.0010000, time: 10.78\n",
      "2022-08-19 10:49:27,672 Epoch[4/50] train loss: 0.39317, val loss: nan, lr: 0.0010000, time: 11.21\n",
      "2022-08-19 10:49:38,434 Epoch[5/50] train loss: 0.39200, val loss: nan, lr: 0.0010000, time: 10.76\n",
      "2022-08-19 10:49:49,218 Epoch[6/50] train loss: 0.39098, val loss: nan, lr: 0.0010000, time: 10.78\n",
      "2022-08-19 10:49:59,703 Epoch[7/50] train loss: 0.39037, val loss: nan, lr: 0.0010000, time: 10.48\n",
      "2022-08-19 10:50:10,920 Epoch[8/50] train loss: 0.38899, val loss: nan, lr: 0.0010000, time: 11.22\n",
      "2022-08-19 10:50:21,670 Epoch[9/50] train loss: 0.38835, val loss: nan, lr: 0.0010000, time: 10.75\n",
      "2022-08-19 10:50:32,256 Epoch[10/50] train loss: 0.38732, val loss: nan, lr: 0.0010000, time: 10.58\n",
      "2022-08-19 10:50:43,014 Epoch[11/50] train loss: 0.38622, val loss: nan, lr: 0.0010000, time: 10.76\n",
      "2022-08-19 10:50:54,216 Epoch[12/50] train loss: 0.38614, val loss: nan, lr: 0.0010000, time: 11.20\n",
      "2022-08-19 10:51:05,369 Epoch[13/50] train loss: 0.38499, val loss: nan, lr: 0.0010000, time: 11.15\n",
      "2022-08-19 10:51:16,180 Epoch[14/50] train loss: 0.38436, val loss: nan, lr: 0.0010000, time: 10.81\n",
      "2022-08-19 10:51:26,695 Epoch[15/50] train loss: 0.38360, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 10:51:37,368 Epoch[16/50] train loss: 0.38303, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 10:51:48,090 Epoch[17/50] train loss: 0.38206, val loss: nan, lr: 0.0010000, time: 10.72\n",
      "2022-08-19 10:51:58,691 Epoch[18/50] train loss: 0.38095, val loss: nan, lr: 0.0010000, time: 10.60\n",
      "2022-08-19 10:52:09,201 Epoch[19/50] train loss: 0.38055, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 10:52:19,821 Epoch[20/50] train loss: 0.37959, val loss: nan, lr: 0.0010000, time: 10.62\n",
      "2022-08-19 10:52:30,926 Epoch[21/50] train loss: 0.37879, val loss: nan, lr: 0.0010000, time: 11.10\n",
      "2022-08-19 10:52:41,493 Epoch[22/50] train loss: 0.37863, val loss: nan, lr: 0.0010000, time: 10.57\n",
      "2022-08-19 10:52:52,072 Epoch[23/50] train loss: 0.37772, val loss: nan, lr: 0.0010000, time: 10.58\n",
      "2022-08-19 10:53:02,541 Epoch[24/50] train loss: 0.37659, val loss: nan, lr: 0.0010000, time: 10.47\n",
      "2022-08-19 10:53:13,200 Epoch[25/50] train loss: 0.37601, val loss: nan, lr: 0.0010000, time: 10.66\n",
      "2022-08-19 10:53:23,908 Epoch[26/50] train loss: 0.37556, val loss: nan, lr: 0.0010000, time: 10.71\n",
      "2022-08-19 10:53:34,705 Epoch[27/50] train loss: 0.37502, val loss: nan, lr: 0.0010000, time: 10.80\n",
      "2022-08-19 10:53:45,799 Epoch[28/50] train loss: 0.37450, val loss: nan, lr: 0.0010000, time: 11.09\n",
      "2022-08-19 10:53:56,347 Epoch[29/50] train loss: 0.37367, val loss: nan, lr: 0.0010000, time: 10.55\n",
      "2022-08-19 10:54:06,862 Epoch[30/50] train loss: 0.37388, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 10:54:17,340 Epoch[31/50] train loss: 0.37300, val loss: nan, lr: 0.0010000, time: 10.48\n",
      "2022-08-19 10:54:27,855 Epoch[32/50] train loss: 0.37254, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 10:54:38,635 Epoch[33/50] train loss: 0.37191, val loss: nan, lr: 0.0010000, time: 10.78\n",
      "2022-08-19 10:54:49,447 Epoch[34/50] train loss: 0.37169, val loss: nan, lr: 0.0010000, time: 10.81\n",
      "2022-08-19 10:55:00,376 Epoch[35/50] train loss: 0.37106, val loss: nan, lr: 0.0010000, time: 10.93\n",
      "2022-08-19 10:55:11,025 Epoch[36/50] train loss: 0.37121, val loss: nan, lr: 0.0010000, time: 10.65\n",
      "2022-08-19 10:55:21,623 Epoch[37/50] train loss: 0.37016, val loss: nan, lr: 0.0010000, time: 10.60\n",
      "2022-08-19 10:55:33,059 Epoch[38/50] train loss: 0.37048, val loss: nan, lr: 0.0010000, time: 11.43\n",
      "2022-08-19 10:55:44,123 Epoch[39/50] train loss: 0.36949, val loss: nan, lr: 0.0010000, time: 11.06\n",
      "2022-08-19 10:55:55,287 Epoch[40/50] train loss: 0.37026, val loss: nan, lr: 0.0010000, time: 11.16\n",
      "2022-08-19 10:56:06,063 Epoch[41/50] train loss: 0.36897, val loss: nan, lr: 0.0010000, time: 10.77\n",
      "2022-08-19 10:56:16,697 Epoch[42/50] train loss: 0.36846, val loss: nan, lr: 0.0010000, time: 10.63\n",
      "2022-08-19 10:56:27,125 Epoch[43/50] train loss: 0.36861, val loss: nan, lr: 0.0010000, time: 10.43\n",
      "2022-08-19 10:56:37,638 Epoch[44/50] train loss: 0.36815, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 10:56:48,105 Epoch[45/50] train loss: 0.36800, val loss: nan, lr: 0.0010000, time: 10.46\n",
      "2022-08-19 10:56:58,660 Epoch[46/50] train loss: 0.36763, val loss: nan, lr: 0.0010000, time: 10.55\n",
      "2022-08-19 10:57:09,121 Epoch[47/50] train loss: 0.36729, val loss: nan, lr: 0.0010000, time: 10.46\n",
      "2022-08-19 10:57:19,593 Epoch[48/50] train loss: 0.36710, val loss: nan, lr: 0.0010000, time: 10.47\n",
      "2022-08-19 10:57:30,188 Epoch[49/50] train loss: 0.36676, val loss: nan, lr: 0.0010000, time: 10.59\n",
      "2022-08-19 10:57:41,015 Epoch[50/50] train loss: 0.36601, val loss: nan, lr: 0.0010000, time: 10.83\n",
      "2022-08-19 10:57:41,016 => end training\n",
      "2022-08-19 10:57:41,017 => calculating train scores\n",
      "2022-08-19 10:57:56,051 => train score\n",
      "accuracy: 0.9976023143014124\n",
      "presision: 0.6920449537241076\n",
      "recall: 0.9545592705167173\n",
      "f1: 0.8023760858456821\n",
      "2022-08-19 10:57:56,053 => calculating test scores\n",
      "2022-08-19 10:58:00,172 => test score\n",
      "accuracy: 0.9931392758904581\n",
      "presision: 0.1889483065953654\n",
      "recall: 0.2883046237533998\n",
      "f1: 0.2282842785355348\n",
      "2022-08-19 10:58:00,187 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 10:58:11,088 Epoch[1/50] train loss: 0.48475, val loss: nan, lr: 0.0010000, time: 10.90\n",
      "2022-08-19 10:58:21,977 Epoch[2/50] train loss: 0.42814, val loss: nan, lr: 0.0010000, time: 10.89\n",
      "2022-08-19 10:58:32,544 Epoch[3/50] train loss: 0.42500, val loss: nan, lr: 0.0010000, time: 10.57\n",
      "2022-08-19 10:58:43,641 Epoch[4/50] train loss: 0.42261, val loss: nan, lr: 0.0010000, time: 11.09\n",
      "2022-08-19 10:58:54,689 Epoch[5/50] train loss: 0.42118, val loss: nan, lr: 0.0010000, time: 11.05\n",
      "2022-08-19 10:59:05,593 Epoch[6/50] train loss: 0.41998, val loss: nan, lr: 0.0010000, time: 10.90\n",
      "2022-08-19 10:59:16,473 Epoch[7/50] train loss: 0.41773, val loss: nan, lr: 0.0010000, time: 10.88\n",
      "2022-08-19 10:59:27,002 Epoch[8/50] train loss: 0.41680, val loss: nan, lr: 0.0010000, time: 10.53\n",
      "2022-08-19 10:59:38,069 Epoch[9/50] train loss: 0.41543, val loss: nan, lr: 0.0010000, time: 11.06\n",
      "2022-08-19 10:59:48,969 Epoch[10/50] train loss: 0.41456, val loss: nan, lr: 0.0010000, time: 10.90\n",
      "2022-08-19 10:59:59,506 Epoch[11/50] train loss: 0.41353, val loss: nan, lr: 0.0010000, time: 10.53\n",
      "2022-08-19 11:00:10,288 Epoch[12/50] train loss: 0.41186, val loss: nan, lr: 0.0010000, time: 10.78\n",
      "2022-08-19 11:00:20,910 Epoch[13/50] train loss: 0.41059, val loss: nan, lr: 0.0010000, time: 10.62\n",
      "2022-08-19 11:00:31,933 Epoch[14/50] train loss: 0.40989, val loss: nan, lr: 0.0010000, time: 11.02\n",
      "2022-08-19 11:00:43,041 Epoch[15/50] train loss: 0.40818, val loss: nan, lr: 0.0010000, time: 11.11\n",
      "2022-08-19 11:00:53,534 Epoch[16/50] train loss: 0.40695, val loss: nan, lr: 0.0010000, time: 10.49\n",
      "2022-08-19 11:01:04,476 Epoch[17/50] train loss: 0.40593, val loss: nan, lr: 0.0010000, time: 10.94\n",
      "2022-08-19 11:01:15,029 Epoch[18/50] train loss: 0.40490, val loss: nan, lr: 0.0010000, time: 10.55\n",
      "2022-08-19 11:01:25,868 Epoch[19/50] train loss: 0.40368, val loss: nan, lr: 0.0010000, time: 10.84\n",
      "2022-08-19 11:01:37,046 Epoch[20/50] train loss: 0.40250, val loss: nan, lr: 0.0010000, time: 11.18\n",
      "2022-08-19 11:01:48,289 Epoch[21/50] train loss: 0.40135, val loss: nan, lr: 0.0010000, time: 11.24\n",
      "2022-08-19 11:01:59,537 Epoch[22/50] train loss: 0.40081, val loss: nan, lr: 0.0010000, time: 11.25\n",
      "2022-08-19 11:02:10,207 Epoch[23/50] train loss: 0.39962, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 11:02:20,773 Epoch[24/50] train loss: 0.39887, val loss: nan, lr: 0.0010000, time: 10.56\n",
      "2022-08-19 11:02:32,118 Epoch[25/50] train loss: 0.39786, val loss: nan, lr: 0.0010000, time: 11.34\n",
      "2022-08-19 11:02:42,624 Epoch[26/50] train loss: 0.39669, val loss: nan, lr: 0.0010000, time: 10.50\n",
      "2022-08-19 11:02:53,265 Epoch[27/50] train loss: 0.39709, val loss: nan, lr: 0.0010000, time: 10.64\n",
      "2022-08-19 11:03:03,738 Epoch[28/50] train loss: 0.39554, val loss: nan, lr: 0.0010000, time: 10.47\n",
      "2022-08-19 11:03:14,544 Epoch[29/50] train loss: 0.39610, val loss: nan, lr: 0.0010000, time: 10.80\n",
      "2022-08-19 11:03:25,104 Epoch[30/50] train loss: 0.39403, val loss: nan, lr: 0.0010000, time: 10.56\n",
      "2022-08-19 11:03:36,141 Epoch[31/50] train loss: 0.39284, val loss: nan, lr: 0.0010000, time: 11.04\n",
      "2022-08-19 11:03:46,711 Epoch[32/50] train loss: 0.39294, val loss: nan, lr: 0.0010000, time: 10.57\n",
      "2022-08-19 11:03:57,771 Epoch[33/50] train loss: 0.39264, val loss: nan, lr: 0.0010000, time: 11.06\n",
      "2022-08-19 11:04:08,582 Epoch[34/50] train loss: 0.39225, val loss: nan, lr: 0.0010000, time: 10.81\n",
      "2022-08-19 11:04:19,584 Epoch[35/50] train loss: 0.39087, val loss: nan, lr: 0.0010000, time: 11.00\n",
      "2022-08-19 11:04:30,517 Epoch[36/50] train loss: 0.39022, val loss: nan, lr: 0.0010000, time: 10.93\n",
      "2022-08-19 11:04:41,504 Epoch[37/50] train loss: 0.38961, val loss: nan, lr: 0.0010000, time: 10.98\n",
      "2022-08-19 11:04:52,524 Epoch[38/50] train loss: 0.39337, val loss: nan, lr: 0.0010000, time: 11.02\n",
      "2022-08-19 11:05:03,152 Epoch[39/50] train loss: 0.38881, val loss: nan, lr: 0.0010000, time: 10.63\n",
      "2022-08-19 11:05:13,783 Epoch[40/50] train loss: 0.38898, val loss: nan, lr: 0.0010000, time: 10.63\n",
      "2022-08-19 11:05:24,659 Epoch[41/50] train loss: 0.38864, val loss: nan, lr: 0.0010000, time: 10.87\n",
      "2022-08-19 11:05:35,537 Epoch[42/50] train loss: 0.38772, val loss: nan, lr: 0.0010000, time: 10.88\n",
      "2022-08-19 11:05:46,714 Epoch[43/50] train loss: 0.38706, val loss: nan, lr: 0.0010000, time: 11.17\n",
      "2022-08-19 11:05:57,631 Epoch[44/50] train loss: 0.38747, val loss: nan, lr: 0.0010000, time: 10.92\n",
      "2022-08-19 11:06:08,234 Epoch[45/50] train loss: 0.38735, val loss: nan, lr: 0.0010000, time: 10.60\n",
      "2022-08-19 11:06:19,718 Epoch[46/50] train loss: 0.38612, val loss: nan, lr: 0.0010000, time: 11.48\n",
      "2022-08-19 11:06:30,191 Epoch[47/50] train loss: 0.38540, val loss: nan, lr: 0.0010000, time: 10.47\n",
      "2022-08-19 11:06:40,890 Epoch[48/50] train loss: 0.38577, val loss: nan, lr: 0.0010000, time: 10.70\n",
      "2022-08-19 11:06:51,450 Epoch[49/50] train loss: 0.38587, val loss: nan, lr: 0.0010000, time: 10.56\n",
      "2022-08-19 11:07:02,312 Epoch[50/50] train loss: 0.38558, val loss: nan, lr: 0.0010000, time: 10.86\n",
      "2022-08-19 11:07:02,313 => end training\n",
      "2022-08-19 11:07:02,313 => calculating train scores\n",
      "2022-08-19 11:07:17,567 => train score\n",
      "accuracy: 0.9933866031830169\n",
      "presision: 0.4343854936198791\n",
      "recall: 0.9829787234042553\n",
      "f1: 0.6025151374010247\n",
      "2022-08-19 11:07:17,569 => calculating test scores\n",
      "2022-08-19 11:07:21,617 => test score\n",
      "accuracy: 0.9875549655687381\n",
      "presision: 0.12476522672390662\n",
      "recall: 0.4215775158658205\n",
      "f1: 0.19254658385093165\n",
      "2022-08-19 11:07:21,631 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:07:32,325 Epoch[1/50] train loss: 0.53945, val loss: nan, lr: 0.0010000, time: 10.69\n",
      "2022-08-19 11:07:42,892 Epoch[2/50] train loss: 0.48092, val loss: nan, lr: 0.0010000, time: 10.57\n",
      "2022-08-19 11:07:53,919 Epoch[3/50] train loss: 0.47727, val loss: nan, lr: 0.0010000, time: 11.03\n",
      "2022-08-19 11:08:05,755 Epoch[4/50] train loss: 0.47445, val loss: nan, lr: 0.0010000, time: 11.83\n",
      "2022-08-19 11:08:16,538 Epoch[5/50] train loss: 0.47192, val loss: nan, lr: 0.0010000, time: 10.78\n",
      "2022-08-19 11:08:27,280 Epoch[6/50] train loss: 0.46967, val loss: nan, lr: 0.0010000, time: 10.74\n",
      "2022-08-19 11:08:38,127 Epoch[7/50] train loss: 0.46708, val loss: nan, lr: 0.0010000, time: 10.84\n",
      "2022-08-19 11:08:48,778 Epoch[8/50] train loss: 0.46419, val loss: nan, lr: 0.0010000, time: 10.65\n",
      "2022-08-19 11:08:59,347 Epoch[9/50] train loss: 0.46289, val loss: nan, lr: 0.0010000, time: 10.57\n",
      "2022-08-19 11:09:09,931 Epoch[10/50] train loss: 0.46156, val loss: nan, lr: 0.0010000, time: 10.58\n",
      "2022-08-19 11:09:20,582 Epoch[11/50] train loss: 0.45992, val loss: nan, lr: 0.0010000, time: 10.65\n",
      "2022-08-19 11:09:31,776 Epoch[12/50] train loss: 0.45745, val loss: nan, lr: 0.0010000, time: 11.19\n",
      "2022-08-19 11:09:42,892 Epoch[13/50] train loss: 0.45552, val loss: nan, lr: 0.0010000, time: 11.11\n",
      "2022-08-19 11:09:53,790 Epoch[14/50] train loss: 0.45469, val loss: nan, lr: 0.0010000, time: 10.90\n",
      "2022-08-19 11:10:04,452 Epoch[15/50] train loss: 0.45286, val loss: nan, lr: 0.0010000, time: 10.66\n",
      "2022-08-19 11:10:15,237 Epoch[16/50] train loss: 0.45068, val loss: nan, lr: 0.0010000, time: 10.78\n",
      "2022-08-19 11:10:26,226 Epoch[17/50] train loss: 0.44986, val loss: nan, lr: 0.0010000, time: 10.99\n",
      "2022-08-19 11:10:36,866 Epoch[18/50] train loss: 0.44671, val loss: nan, lr: 0.0010000, time: 10.64\n",
      "2022-08-19 11:10:47,534 Epoch[19/50] train loss: 0.44630, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 11:10:58,509 Epoch[20/50] train loss: 0.44403, val loss: nan, lr: 0.0010000, time: 10.97\n",
      "2022-08-19 11:11:09,052 Epoch[21/50] train loss: 0.44366, val loss: nan, lr: 0.0010000, time: 10.54\n",
      "2022-08-19 11:11:19,857 Epoch[22/50] train loss: 0.44076, val loss: nan, lr: 0.0010000, time: 10.80\n",
      "2022-08-19 11:11:30,598 Epoch[23/50] train loss: 0.44020, val loss: nan, lr: 0.0010000, time: 10.74\n",
      "2022-08-19 11:11:41,460 Epoch[24/50] train loss: 0.43856, val loss: nan, lr: 0.0010000, time: 10.86\n",
      "2022-08-19 11:11:52,005 Epoch[25/50] train loss: 0.43647, val loss: nan, lr: 0.0010000, time: 10.54\n",
      "2022-08-19 11:12:03,302 Epoch[26/50] train loss: 0.43743, val loss: nan, lr: 0.0010000, time: 11.29\n",
      "2022-08-19 11:12:14,564 Epoch[27/50] train loss: 0.43546, val loss: nan, lr: 0.0010000, time: 11.26\n",
      "2022-08-19 11:12:25,700 Epoch[28/50] train loss: 0.43411, val loss: nan, lr: 0.0010000, time: 11.13\n",
      "2022-08-19 11:12:36,622 Epoch[29/50] train loss: 0.43364, val loss: nan, lr: 0.0010000, time: 10.92\n",
      "2022-08-19 11:12:47,136 Epoch[30/50] train loss: 0.43320, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 11:12:58,416 Epoch[31/50] train loss: 0.43247, val loss: nan, lr: 0.0010000, time: 11.28\n",
      "2022-08-19 11:13:09,055 Epoch[32/50] train loss: 0.42957, val loss: nan, lr: 0.0010000, time: 10.64\n",
      "2022-08-19 11:13:19,759 Epoch[33/50] train loss: 0.43054, val loss: nan, lr: 0.0010000, time: 10.70\n",
      "2022-08-19 11:13:30,533 Epoch[34/50] train loss: 0.42909, val loss: nan, lr: 0.0010000, time: 10.77\n",
      "2022-08-19 11:13:41,475 Epoch[35/50] train loss: 0.42834, val loss: nan, lr: 0.0010000, time: 10.94\n",
      "2022-08-19 11:13:52,394 Epoch[36/50] train loss: 0.42682, val loss: nan, lr: 0.0010000, time: 10.92\n",
      "2022-08-19 11:14:04,129 Epoch[37/50] train loss: 0.42592, val loss: nan, lr: 0.0010000, time: 11.73\n",
      "2022-08-19 11:14:15,185 Epoch[38/50] train loss: 0.42737, val loss: nan, lr: 0.0010000, time: 11.05\n",
      "2022-08-19 11:14:26,220 Epoch[39/50] train loss: 0.42651, val loss: nan, lr: 0.0010000, time: 11.03\n",
      "2022-08-19 11:14:37,107 Epoch[40/50] train loss: 0.42696, val loss: nan, lr: 0.0010000, time: 10.88\n",
      "2022-08-19 11:14:48,876 Epoch[41/50] train loss: 0.42473, val loss: nan, lr: 0.0010000, time: 11.77\n",
      "2022-08-19 11:14:59,987 Epoch[42/50] train loss: 0.42402, val loss: nan, lr: 0.0010000, time: 11.11\n",
      "2022-08-19 11:15:11,675 Epoch[43/50] train loss: 0.42414, val loss: nan, lr: 0.0010000, time: 11.69\n",
      "2022-08-19 11:15:22,709 Epoch[44/50] train loss: 0.42331, val loss: nan, lr: 0.0010000, time: 11.03\n",
      "2022-08-19 11:15:33,365 Epoch[45/50] train loss: 0.42331, val loss: nan, lr: 0.0010000, time: 10.65\n",
      "2022-08-19 11:15:43,919 Epoch[46/50] train loss: 0.42151, val loss: nan, lr: 0.0010000, time: 10.55\n",
      "2022-08-19 11:15:54,554 Epoch[47/50] train loss: 0.42295, val loss: nan, lr: 0.0010000, time: 10.63\n",
      "2022-08-19 11:16:05,151 Epoch[48/50] train loss: 0.42251, val loss: nan, lr: 0.0010000, time: 10.60\n",
      "2022-08-19 11:16:16,447 Epoch[49/50] train loss: 0.41990, val loss: nan, lr: 0.0010000, time: 11.29\n",
      "2022-08-19 11:16:27,160 Epoch[50/50] train loss: 0.42136, val loss: nan, lr: 0.0010000, time: 10.71\n",
      "2022-08-19 11:16:27,161 => end training\n",
      "2022-08-19 11:16:27,162 => calculating train scores\n",
      "2022-08-19 11:16:41,433 => train score\n",
      "accuracy: 0.9900148092351971\n",
      "presision: 0.3318935636964752\n",
      "recall: 0.9458966565349544\n",
      "f1: 0.4913748865116646\n",
      "2022-08-19 11:16:41,435 => calculating test scores\n",
      "2022-08-19 11:16:45,522 => test score\n",
      "accuracy: 0.98482024902833\n",
      "presision: 0.11520640269587194\n",
      "recall: 0.4959202175883953\n",
      "f1: 0.18697658519911126\n",
      "2022-08-19 11:16:45,544 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:16:58,580 Epoch[1/50] train loss: 0.46982, val loss: nan, lr: 0.0010000, time: 13.04\n",
      "2022-08-19 11:17:11,697 Epoch[2/50] train loss: 0.39832, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:17:24,698 Epoch[3/50] train loss: 0.39469, val loss: nan, lr: 0.0010000, time: 13.00\n",
      "2022-08-19 11:17:37,725 Epoch[4/50] train loss: 0.39315, val loss: nan, lr: 0.0010000, time: 13.02\n",
      "2022-08-19 11:17:50,789 Epoch[5/50] train loss: 0.39187, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:18:03,884 Epoch[6/50] train loss: 0.39087, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:18:16,953 Epoch[7/50] train loss: 0.38954, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:18:29,998 Epoch[8/50] train loss: 0.38815, val loss: nan, lr: 0.0010000, time: 13.04\n",
      "2022-08-19 11:18:43,083 Epoch[9/50] train loss: 0.38735, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:18:56,179 Epoch[10/50] train loss: 0.38686, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:19:09,316 Epoch[11/50] train loss: 0.38576, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:19:22,402 Epoch[12/50] train loss: 0.38456, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:19:35,520 Epoch[13/50] train loss: 0.38382, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:19:48,576 Epoch[14/50] train loss: 0.38310, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:20:01,737 Epoch[15/50] train loss: 0.38222, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:20:14,886 Epoch[16/50] train loss: 0.38096, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:20:27,917 Epoch[17/50] train loss: 0.38028, val loss: nan, lr: 0.0010000, time: 13.03\n",
      "2022-08-19 11:20:40,995 Epoch[18/50] train loss: 0.37903, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:20:54,190 Epoch[19/50] train loss: 0.37861, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:21:07,364 Epoch[20/50] train loss: 0.37728, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:21:20,433 Epoch[21/50] train loss: 0.37692, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:21:33,484 Epoch[22/50] train loss: 0.37611, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:21:46,513 Epoch[23/50] train loss: 0.37542, val loss: nan, lr: 0.0010000, time: 13.03\n",
      "2022-08-19 11:21:59,609 Epoch[24/50] train loss: 0.37418, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:22:12,643 Epoch[25/50] train loss: 0.37414, val loss: nan, lr: 0.0010000, time: 13.03\n",
      "2022-08-19 11:22:25,695 Epoch[26/50] train loss: 0.37307, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:22:38,874 Epoch[27/50] train loss: 0.37246, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:22:51,930 Epoch[28/50] train loss: 0.37209, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:23:05,009 Epoch[29/50] train loss: 0.37075, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:23:18,248 Epoch[30/50] train loss: 0.37077, val loss: nan, lr: 0.0010000, time: 13.24\n",
      "2022-08-19 11:23:31,345 Epoch[31/50] train loss: 0.37022, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:23:44,621 Epoch[32/50] train loss: 0.37019, val loss: nan, lr: 0.0010000, time: 13.28\n",
      "2022-08-19 11:23:57,765 Epoch[33/50] train loss: 0.36907, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:24:10,939 Epoch[34/50] train loss: 0.36965, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:24:24,162 Epoch[35/50] train loss: 0.36840, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:24:37,283 Epoch[36/50] train loss: 0.36786, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:24:50,391 Epoch[37/50] train loss: 0.36776, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:25:03,453 Epoch[38/50] train loss: 0.36712, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:25:16,593 Epoch[39/50] train loss: 0.36722, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:25:29,655 Epoch[40/50] train loss: 0.36691, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:25:42,765 Epoch[41/50] train loss: 0.36629, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:25:55,859 Epoch[42/50] train loss: 0.36602, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:26:09,214 Epoch[43/50] train loss: 0.36485, val loss: nan, lr: 0.0010000, time: 13.35\n",
      "2022-08-19 11:26:22,283 Epoch[44/50] train loss: 0.36564, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:26:35,324 Epoch[45/50] train loss: 0.36501, val loss: nan, lr: 0.0010000, time: 13.04\n",
      "2022-08-19 11:26:48,458 Epoch[46/50] train loss: 0.36549, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:27:01,571 Epoch[47/50] train loss: 0.36439, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:27:14,651 Epoch[48/50] train loss: 0.36465, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:27:27,835 Epoch[49/50] train loss: 0.36456, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:27:40,904 Epoch[50/50] train loss: 0.36364, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:27:40,906 => end training\n",
      "2022-08-19 11:27:40,907 => calculating train scores\n",
      "2022-08-19 11:27:55,584 => train score\n",
      "accuracy: 0.9984408068437111\n",
      "presision: 0.7759787336877718\n",
      "recall: 0.9759878419452888\n",
      "f1: 0.864566505115778\n",
      "2022-08-19 11:27:55,586 => calculating test scores\n",
      "2022-08-19 11:27:59,619 => test score\n",
      "accuracy: 0.9933179738207533\n",
      "presision: 0.1897307451471509\n",
      "recall: 0.2747053490480508\n",
      "f1: 0.22444444444444445\n",
      "2022-08-19 11:27:59,633 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:28:12,636 Epoch[1/50] train loss: 0.47623, val loss: nan, lr: 0.0010000, time: 13.00\n",
      "2022-08-19 11:28:25,704 Epoch[2/50] train loss: 0.42852, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:28:38,762 Epoch[3/50] train loss: 0.42555, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:28:51,843 Epoch[4/50] train loss: 0.42378, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:29:04,989 Epoch[5/50] train loss: 0.42238, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:29:18,212 Epoch[6/50] train loss: 0.42039, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:29:31,318 Epoch[7/50] train loss: 0.41876, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:29:44,433 Epoch[8/50] train loss: 0.41669, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:29:57,557 Epoch[9/50] train loss: 0.41590, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:30:10,668 Epoch[10/50] train loss: 0.41462, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:30:23,727 Epoch[11/50] train loss: 0.41318, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:30:36,856 Epoch[12/50] train loss: 0.41194, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:30:49,915 Epoch[13/50] train loss: 0.41033, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:31:03,038 Epoch[14/50] train loss: 0.40928, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:31:16,151 Epoch[15/50] train loss: 0.40806, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:31:29,326 Epoch[16/50] train loss: 0.40714, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:31:42,323 Epoch[17/50] train loss: 0.40491, val loss: nan, lr: 0.0010000, time: 12.99\n",
      "2022-08-19 11:31:55,422 Epoch[18/50] train loss: 0.40459, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:32:08,558 Epoch[19/50] train loss: 0.40412, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:32:21,661 Epoch[20/50] train loss: 0.40192, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:32:34,686 Epoch[21/50] train loss: 0.40071, val loss: nan, lr: 0.0010000, time: 13.02\n",
      "2022-08-19 11:32:47,784 Epoch[22/50] train loss: 0.40050, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:33:00,904 Epoch[23/50] train loss: 0.39874, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:33:14,065 Epoch[24/50] train loss: 0.39761, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:33:27,189 Epoch[25/50] train loss: 0.39617, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:33:40,399 Epoch[26/50] train loss: 0.39607, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:33:53,484 Epoch[27/50] train loss: 0.39660, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:34:06,629 Epoch[28/50] train loss: 0.39411, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:34:19,751 Epoch[29/50] train loss: 0.39363, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:34:32,843 Epoch[30/50] train loss: 0.39249, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:34:45,920 Epoch[31/50] train loss: 0.39181, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:34:59,007 Epoch[32/50] train loss: 0.39221, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:35:12,232 Epoch[33/50] train loss: 0.39126, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:35:25,292 Epoch[34/50] train loss: 0.38938, val loss: nan, lr: 0.0010000, time: 13.06\n",
      "2022-08-19 11:35:38,446 Epoch[35/50] train loss: 0.38969, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:35:51,573 Epoch[36/50] train loss: 0.38937, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:36:04,692 Epoch[37/50] train loss: 0.38842, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:36:17,777 Epoch[38/50] train loss: 0.38806, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:36:30,931 Epoch[39/50] train loss: 0.38753, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:36:44,115 Epoch[40/50] train loss: 0.38840, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:36:57,190 Epoch[41/50] train loss: 0.38614, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:37:10,384 Epoch[42/50] train loss: 0.38638, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:37:23,541 Epoch[43/50] train loss: 0.38786, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:37:36,672 Epoch[44/50] train loss: 0.38662, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:37:49,795 Epoch[45/50] train loss: 0.38556, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:38:02,818 Epoch[46/50] train loss: 0.38483, val loss: nan, lr: 0.0010000, time: 13.02\n",
      "2022-08-19 11:38:15,866 Epoch[47/50] train loss: 0.38456, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:38:28,978 Epoch[48/50] train loss: 0.38340, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:38:42,114 Epoch[49/50] train loss: 0.38366, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:38:55,188 Epoch[50/50] train loss: 0.38489, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:38:55,189 => end training\n",
      "2022-08-19 11:38:55,190 => calculating train scores\n",
      "2022-08-19 11:39:09,553 => train score\n",
      "accuracy: 0.9946342676868067\n",
      "presision: 0.48696179502728926\n",
      "recall: 0.9762917933130699\n",
      "f1: 0.6498078090228606\n",
      "2022-08-19 11:39:09,555 => calculating test scores\n",
      "2022-08-19 11:39:13,580 => test score\n",
      "accuracy: 0.9904843352117889\n",
      "presision: 0.16434440871739908\n",
      "recall: 0.4170444242973708\n",
      "f1: 0.23577652485904668\n",
      "2022-08-19 11:39:13,590 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:39:26,680 Epoch[1/50] train loss: 0.54118, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:39:39,724 Epoch[2/50] train loss: 0.48118, val loss: nan, lr: 0.0010000, time: 13.04\n",
      "2022-08-19 11:39:52,833 Epoch[3/50] train loss: 0.47732, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:40:05,882 Epoch[4/50] train loss: 0.47413, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:40:18,932 Epoch[5/50] train loss: 0.47218, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:40:32,032 Epoch[6/50] train loss: 0.46987, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:40:45,127 Epoch[7/50] train loss: 0.46735, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:40:58,330 Epoch[8/50] train loss: 0.46468, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:41:11,339 Epoch[9/50] train loss: 0.46414, val loss: nan, lr: 0.0010000, time: 13.01\n",
      "2022-08-19 11:41:24,461 Epoch[10/50] train loss: 0.46030, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:41:37,580 Epoch[11/50] train loss: 0.45878, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:41:50,872 Epoch[12/50] train loss: 0.45739, val loss: nan, lr: 0.0010000, time: 13.29\n",
      "2022-08-19 11:42:03,985 Epoch[13/50] train loss: 0.45559, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:42:17,066 Epoch[14/50] train loss: 0.45463, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:42:30,205 Epoch[15/50] train loss: 0.45351, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:42:43,276 Epoch[16/50] train loss: 0.45135, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:42:56,406 Epoch[17/50] train loss: 0.44973, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:43:09,609 Epoch[18/50] train loss: 0.44863, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:43:22,728 Epoch[19/50] train loss: 0.44537, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:43:35,864 Epoch[20/50] train loss: 0.44510, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:43:49,101 Epoch[21/50] train loss: 0.44308, val loss: nan, lr: 0.0010000, time: 13.23\n",
      "2022-08-19 11:44:02,311 Epoch[22/50] train loss: 0.44188, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:44:15,396 Epoch[23/50] train loss: 0.44010, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:44:28,519 Epoch[24/50] train loss: 0.43733, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:44:41,720 Epoch[25/50] train loss: 0.43618, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:44:54,859 Epoch[26/50] train loss: 0.43556, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:45:07,934 Epoch[27/50] train loss: 0.43348, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:45:21,119 Epoch[28/50] train loss: 0.43264, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:45:34,285 Epoch[29/50] train loss: 0.43495, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:45:47,372 Epoch[30/50] train loss: 0.43282, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:46:00,485 Epoch[31/50] train loss: 0.43025, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:46:13,684 Epoch[32/50] train loss: 0.42871, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:46:26,893 Epoch[33/50] train loss: 0.42795, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:46:40,023 Epoch[34/50] train loss: 0.42699, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:46:53,156 Epoch[35/50] train loss: 0.42634, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:47:06,319 Epoch[36/50] train loss: 0.42473, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:47:19,444 Epoch[37/50] train loss: 0.42642, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:47:32,610 Epoch[38/50] train loss: 0.42363, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:47:45,747 Epoch[39/50] train loss: 0.42433, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:47:58,929 Epoch[40/50] train loss: 0.42358, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:48:12,036 Epoch[41/50] train loss: 0.42189, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:48:25,134 Epoch[42/50] train loss: 0.42080, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:48:38,300 Epoch[43/50] train loss: 0.42450, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:48:51,508 Epoch[44/50] train loss: 0.42178, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:49:04,629 Epoch[45/50] train loss: 0.42007, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:49:17,725 Epoch[46/50] train loss: 0.41957, val loss: nan, lr: 0.0010000, time: 13.09\n",
      "2022-08-19 11:49:31,168 Epoch[47/50] train loss: 0.42036, val loss: nan, lr: 0.0010000, time: 13.44\n",
      "2022-08-19 11:49:44,404 Epoch[48/50] train loss: 0.41890, val loss: nan, lr: 0.0010000, time: 13.23\n",
      "2022-08-19 11:49:57,556 Epoch[49/50] train loss: 0.41771, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:50:10,815 Epoch[50/50] train loss: 0.42032, val loss: nan, lr: 0.0010000, time: 13.26\n",
      "2022-08-19 11:50:10,817 => end training\n",
      "2022-08-19 11:50:10,818 => calculating train scores\n",
      "2022-08-19 11:50:25,447 => train score\n",
      "accuracy: 0.9911942784120719\n",
      "presision: 0.3639415144791489\n",
      "recall: 0.9721884498480243\n",
      "f1: 0.5296187440493438\n",
      "2022-08-19 11:50:25,449 => calculating test scores\n",
      "2022-08-19 11:50:29,745 => test score\n",
      "accuracy: 0.9858477621275265\n",
      "presision: 0.1220508166969147\n",
      "recall: 0.4877606527651859\n",
      "f1: 0.19524587189257847\n",
      "2022-08-19 11:50:29,758 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 2, 'rnn_hidden_dim': 128, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:50:41,603 Epoch[1/50] train loss: 0.43161, val loss: nan, lr: 0.0010000, time: 11.84\n",
      "2022-08-19 11:50:53,413 Epoch[2/50] train loss: 0.39668, val loss: nan, lr: 0.0010000, time: 11.81\n",
      "2022-08-19 11:51:05,187 Epoch[3/50] train loss: 0.39460, val loss: nan, lr: 0.0010000, time: 11.77\n",
      "2022-08-19 11:51:16,326 Epoch[4/50] train loss: 0.39326, val loss: nan, lr: 0.0010000, time: 11.14\n",
      "2022-08-19 11:51:28,120 Epoch[5/50] train loss: 0.39260, val loss: nan, lr: 0.0010000, time: 11.79\n",
      "2022-08-19 11:51:39,635 Epoch[6/50] train loss: 0.39176, val loss: nan, lr: 0.0010000, time: 11.51\n",
      "2022-08-19 11:51:51,503 Epoch[7/50] train loss: 0.39096, val loss: nan, lr: 0.0010000, time: 11.87\n",
      "2022-08-19 11:52:02,925 Epoch[8/50] train loss: 0.38984, val loss: nan, lr: 0.0010000, time: 11.42\n",
      "2022-08-19 11:52:14,600 Epoch[9/50] train loss: 0.38895, val loss: nan, lr: 0.0010000, time: 11.67\n",
      "2022-08-19 11:52:26,081 Epoch[10/50] train loss: 0.38802, val loss: nan, lr: 0.0010000, time: 11.48\n",
      "2022-08-19 11:52:37,300 Epoch[11/50] train loss: 0.38705, val loss: nan, lr: 0.0010000, time: 11.22\n",
      "2022-08-19 11:52:48,962 Epoch[12/50] train loss: 0.38613, val loss: nan, lr: 0.0010000, time: 11.66\n",
      "2022-08-19 11:53:00,045 Epoch[13/50] train loss: 0.38508, val loss: nan, lr: 0.0010000, time: 11.08\n"
     ]
    }
   ],
   "source": [
    "max_acc = [[0, 0, 0, 0], None]\n",
    "max_pre = [[0, 0, 0, 0], None]\n",
    "max_rcl = [[0, 0, 0, 0], None]\n",
    "max_f1 = [[0, 0, 0, 0], None]\n",
    "max_models = [None for _ in range(4)]\n",
    "\n",
    "for n_rnns in params['n_rnns']:\n",
    "    for dim in params['rnn_hidden_dim']:\n",
    "        for weight in params['pos_weight']:\n",
    "            param = dict(n_rnns=n_rnns, rnn_hidden_dim=dim, weight=weight)\n",
    "            print(param)\n",
    "            \n",
    "            # update config\n",
    "            config = {}\n",
    "            for key, val in mdl_cfg.items():\n",
    "                config[key] = val\n",
    "            for key, val in param.items():\n",
    "                config[key] = val\n",
    "            pos_weight = param[\"weight\"]\n",
    "                \n",
    "            # init model, loss, optim\n",
    "            model = init_model(config, device)\n",
    "            criterion = init_loss([1, pos_weight], device)\n",
    "            optimizer, scheduler = init_optim(\n",
    "                model, train_cfg[\"optim\"][\"lr\"], train_cfg[\"optim\"][\"lr_rate\"]\n",
    "            )\n",
    "            \n",
    "            # training\n",
    "            model, epoch, history = train(\n",
    "                model, train_loader, val_loader,\n",
    "                criterion, optimizer, scheduler,\n",
    "                epoch_len, logger, device\n",
    "            )\n",
    "            \n",
    "            # test\n",
    "            score = test(model, test_loader, logger, device)\n",
    "            acc, pre, rcl, f1 = score\n",
    "            \n",
    "            # update max scores\n",
    "            if acc > max_acc[0][0]:\n",
    "                max_acc[0] = score\n",
    "                max_acc[1] = param\n",
    "                max_models[0] = model\n",
    "            if pre > max_pre[0][1]:\n",
    "                max_pre[0] = score\n",
    "                max_pre[1] = param\n",
    "                max_models[1] = model\n",
    "            if rcl > max_rcl[0][2]:\n",
    "                max_rcl[0] = score\n",
    "                max_rcl[1] = param\n",
    "                max_models[2] = model\n",
    "            if f1 > max_f1[0][3]:\n",
    "                max_f1[0] = score\n",
    "                max_f1[1] = param\n",
    "                max_models[3] = model\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd10c2-70ac-46bb-a799-ea597a2204ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"epoch={epoch}\")\n",
    "print('max accuracy: ', max_acc[1])\n",
    "acc, pre, rcl, f1 = max_acc[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max precision: ', max_pre[1])\n",
    "acc, pre, rcl, f1 = max_pre[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max recall: ', max_rcl[1])\n",
    "acc, pre, rcl, f1 = max_rcl[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max f1: ', max_f1[1])\n",
    "acc, pre, rcl, f1 = max_f1[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "784c9760-81f6-4649-8df0-1d465e53a98f",
   "metadata": {},
   "source": [
    "epoch=50\n",
    "max accuracy:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.522 recall: 0.475 f1_score: 0.497\n",
    "max precision:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.522 recall: 0.475 f1_score: 0.497\n",
    "max recall:  {'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 32}\n",
    "accuracy: 0.979 precision: 0.158 recall: 0.760 f1_score: 0.261\n",
    "max f1:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.522 recall: 0.475 f1_score: 0.497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0835b-4abf-46d4-ba43-1d4c26646dbb",
   "metadata": {},
   "source": [
    "## モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54bf6e-f404-4857-b6cb-5b82b32d6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max recall\n",
    "model = max_models[2]\n",
    "param = max_rcl[1]\n",
    "config = {}\n",
    "for key, val in mdl_cfg.items():\n",
    "    config[key] = val\n",
    "for key, val in param.items():\n",
    "    config[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9824f0c-aaf5-4d21-9350-2b5137621cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/passing/pass_model_lstm_recall_ep{epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0d883-965c-43a5-9c60-bac39e468dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"pretrained_path\"] = model_path\n",
    "with open(f'config/passing/pass_model_lstm_recall_ep{epoch}.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e18e5-12d3-41cb-a631-48554ecc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max f1\n",
    "model = max_models[3]\n",
    "param = max_f1[1]\n",
    "config = {}\n",
    "for key, val in mdl_cfg.items():\n",
    "    config[key] = val\n",
    "for key, val in param.items():\n",
    "    config[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc4a91-ce20-4aa0-a790-effed2c75aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/passing/pass_model_lstm_f1_ep{epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb143daa-abbe-419a-9fb9-8d58fc1ad234",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"pretrained_path\"] = model_path\n",
    "with open(f'config/passing/pass_model_lstm_f1_ep{epoch}.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a60fd-b6fe-4f37-9dea-75091bdeaf20",
   "metadata": {},
   "source": [
    "# 検証\n",
    "## モデルロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3656ce-2abd-4508-9594-2a72718a379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "epoch = 50\n",
    "rcl_f1 = \"f1\"\n",
    "\n",
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "    del model\n",
    "    gc.collect()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "mdl_cfg_path = f'config/passing/pass_model_lstm_{rcl_f1}_ep{epoch}.yaml'\n",
    "with open(mdl_cfg_path, \"r\") as f:\n",
    "    mdl_cfg = yaml.safe_load(f)\n",
    "model = init_model(mdl_cfg, device)\n",
    "\n",
    "param = torch.load(mdl_cfg[\"pretrained_path\"])\n",
    "model.load_state_dict(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caade6b7-93f0-4a5a-ac67-4901ddddaafe",
   "metadata": {},
   "source": [
    "## データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbc7d5-075e-4f54-af8d-bac19a4860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict, y_dict = make_all_data(inds, train_cfg[\"dataset\"][\"setting\"], grp_cfg[\"passing\"][\"default\"], logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77857721-bff3-42e1-af5a-83703d6d769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(train_cfg[\"dataset\"][\"random_seed\"])\n",
    "\n",
    "seq_len = grp_cfg[\"passing\"][\"default\"][\"seq_len\"]\n",
    "size = mdl_cfg[\"size\"]\n",
    "\n",
    "keys_1 = [key for key in x_dict if 1 in y_dict[key]]\n",
    "keys_0 = [key for key in x_dict if 1 not in y_dict[key]]\n",
    "random_keys_1 = np.random.choice(keys_1, size=len(keys_1), replace=False)\n",
    "random_keys_0 = np.random.choice(keys_0, size=len(keys_0), replace=False)\n",
    "\n",
    "train_ratio = train_cfg[\"dataset\"][\"train_ratio\"]\n",
    "val_ratio = train_cfg[\"dataset\"][\"val_ratio\"]\n",
    "train_len_1 = int(len(keys_1) * train_ratio)\n",
    "train_len_0 = int(len(keys_0) * train_ratio)\n",
    "val_len_1 = int(len(keys_1) * val_ratio)\n",
    "val_len_0 = int(len(keys_0) * val_ratio)\n",
    "\n",
    "train_keys_1 = random_keys_1[:train_len_1].tolist()\n",
    "val_keys_1 = random_keys_1[train_len_1 : train_len_1 + val_len_1].tolist()\n",
    "test_keys_1 = random_keys_1[train_len_1 + val_len_1 :].tolist()\n",
    "train_keys_0 = random_keys_0[:train_len_0].tolist()\n",
    "test_keys_0 = random_keys_0[train_len_0:].tolist()\n",
    "val_keys_0 = random_keys_1[train_len_0 : train_len_0 + val_len_0].tolist()\n",
    "\n",
    "train_keys = sorted(train_keys_1 + train_keys_0)\n",
    "val_keys = sorted(val_keys_1 + val_keys_0)\n",
    "test_keys = sorted(test_keys_1 + test_keys_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc30e4-b08b-4287-8b07-f8effaaebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(x_lst, y_lst, seq_len=30, size=4):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(x_lst) - seq_len + 1):\n",
    "        x = x_lst[i:i + seq_len]\n",
    "        x_seq.append(x)\n",
    "        y_seq.append(y_lst[i + seq_len - 1])\n",
    "    \n",
    "    return x_seq, y_seq\n",
    "\n",
    "\n",
    "columns = [\"distance\", \"body_direction\", \"arm_ave\", \"wrist_distance\"]\n",
    "def plot(x_lst, y_lst, pred, seq_len=30, path=None):\n",
    "    x_lst = [[0 for _ in range(x_lst.shape[1])]] + [[np.nan for _ in range(x_lst.shape[1])] for i in range(seq_len - 1)] + x_lst.tolist()\n",
    "    y_lst = [0] + [np.nan for i in range(seq_len - 1)] + y_lst\n",
    "    pred = [0] + [np.nan for i in range(seq_len - 1)] + pred.tolist()\n",
    "    \n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    ax = fig.add_axes((0.04, 0.17, 0.80, 0.81))\n",
    "    \n",
    "    ax.plot(pred, label='pred')\n",
    "    ax.plot(y_lst, linestyle=':', label='ground truth')\n",
    "    for i, feature in enumerate(np.array(x_lst).T):\n",
    "        ax.plot(feature, alpha=0.4, label=columns[i])\n",
    "\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    ax.set_xlabel('frame')\n",
    "    ax.legend(\n",
    "        bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0,\n",
    "        fontsize=20, handlelength=0.8, handletextpad=0.2\n",
    "    )\n",
    "    \n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    if path is not None:\n",
    "        fig.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae855e-89c6-4545-8cc2-6850204c1cf9",
   "metadata": {},
   "source": [
    "## トレインデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a72bc4-e0f7-42e4-946d-0727cdf210a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keys = [\n",
    "    '02_06_1_3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f9e0e-6b00-4dac-9641-1088126b63c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_train = []\n",
    "pred_all_train = []\n",
    "y_eve_train = []\n",
    "pred_eve_train = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in train_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "        \n",
    "        x, _ = create_sequence(x_lst, y_lst, seq_len, size)\n",
    "        x = torch.Tensor(np.array(x)).float().to(device)\n",
    "        \n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[seq_len - 1:]\n",
    "        y_lst = y_lst[seq_len - 1:]\n",
    "            \n",
    "        y_all_train += y_lst\n",
    "        pred_all_train += pred.tolist()\n",
    "        y_eve_train.append(1 in y_lst)\n",
    "        pred_eve_train.append(1 in pred.tolist())\n",
    "        \n",
    "        if 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        path = None\n",
    "        if key in save_keys:\n",
    "            path = os.path.join(\"data\", \"passing\", \"image\", f\"rnn_test_{key}.pdf\")\n",
    "        plot(x_lst, y_lst, pred, seq_len, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24e519-53ca-405c-a4ed-5bc31fc7d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_train, pred_all_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_train, pred_all_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_train, pred_all_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_train, pred_all_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388e620-e79f-4a62-9530-ba821dcb9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per event\n",
    "print('accuracy: {:.3f}'.format(accuracy_score(y_eve_train, pred_eve_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_eve_train, pred_eve_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_eve_train, pred_eve_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_eve_train, pred_eve_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055dc76-a0e1-42b0-85a8-358c036dba57",
   "metadata": {},
   "source": [
    "## テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445c2a5-4a0f-49c4-9ef1-97983f804401",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keys = [\n",
    "    '08_03_2_5',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4075ac9-b3b6-460b-9cc2-dac368fed21f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_test = []\n",
    "pred_all_test = []\n",
    "y_eve_test = []\n",
    "pred_eve_test = []\n",
    "tn, fn = 0, 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in test_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "\n",
    "        x, _ = create_sequence(x_lst, y_lst, seq_len, size)\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "\n",
    "        if len(x) == 0:\n",
    "            tn += 1\n",
    "            continue\n",
    "            \n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[seq_len - 1:]\n",
    "        y_lst = y_lst[seq_len - 1:]\n",
    "        \n",
    "        y_all_test += y_lst\n",
    "        pred_all_test += pred.tolist()\n",
    "        y_eve_test.append(1 in y_lst)\n",
    "        pred_eve_test.append(1 in pred.tolist())\n",
    "        if 1 not in y_lst:\n",
    "            if 1 not in pred:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        \n",
    "        if 1 not in pred and 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        path = None\n",
    "        if key in save_keys:\n",
    "            path = os.path.join(\"data\", \"passing\", \"image\", f\"rnn_test_{key}.pdf\")\n",
    "        plot(x_lst, y_lst, pred, seq_len, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125394d0-a266-4220-9cab-a86b943a9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_test, pred_all_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_test, pred_all_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_test, pred_all_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_test, pred_all_test)))\n",
    "\n",
    "cm = confusion_matrix(y_all_test, pred_all_test)\n",
    "sns.heatmap(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa66db1-dae9-433e-a64b-803a7d9f02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per event\n",
    "print('accuracy: {:.3f}'.format(accuracy_score(y_eve_test, pred_eve_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_eve_test, pred_eve_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_eve_test, pred_eve_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_eve_test, pred_eve_test)))\n",
    "\n",
    "print('true negative:', tn)\n",
    "print('false negative:', fn)\n",
    "\n",
    "cm = confusion_matrix(y_eve_test, pred_eve_test)\n",
    "sns.heatmap(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30255301-5894-4c67-961f-6123eff18fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
