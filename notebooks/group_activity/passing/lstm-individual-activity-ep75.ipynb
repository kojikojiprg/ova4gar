{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621a2a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid6/home/yokoyama/research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyama/research/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# back to project root\n",
    "%cd ~/research\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch import nn, optim\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "from group.passing.dataset import make_data_loaders, make_all_data\n",
    "from group.passing.lstm_model import LSTMModel\n",
    "from utility.activity_loader import load_individuals\n",
    "from utility.logger import logger\n",
    "from tools.train_passing import init_model, init_loss, init_optim, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc298add-7d1e-4c1a-8a98-767bde6e9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams[\"font.size\"] = 24\n",
    "plt.rcParams['xtick.direction'] = 'in'  # x axis in\n",
    "plt.rcParams['ytick.direction'] = 'in'  # y axis in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28083f0-6a29-4348-b2f0-6099f5289d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f8937b-15e0-489c-adfe-fc605429bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"config/passing/pass_train.yaml\"\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    train_cfg = yaml.safe_load(f)\n",
    "with open(train_cfg[\"config_path\"][\"individual\"], \"r\") as f:\n",
    "    ind_cfg = yaml.safe_load(f)\n",
    "with open(train_cfg[\"config_path\"][\"group\"], \"r\") as f:\n",
    "    grp_cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe7d65b-260f-4091-b271-5cf80ff3c575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:04<00:00, 10.81s/it]\n"
     ]
    }
   ],
   "source": [
    "data_dirs_all = {}\n",
    "for room_num, surgery_items in train_cfg[\"dataset\"][\"setting\"].items():\n",
    "    for surgery_num in surgery_items.keys():\n",
    "        dirs = sorted(glob(os.path.join(\"data\", room_num, surgery_num, \"passing\", \"*\")))\n",
    "        data_dirs_all[f\"{room_num}_{surgery_num}\"] = dirs\n",
    "\n",
    "inds = {}\n",
    "for key_prefix, dirs in tqdm(data_dirs_all.items()):\n",
    "    for model_path in dirs:\n",
    "        num = model_path.split(\"/\")[-1]\n",
    "        json_path = os.path.join(model_path, \".json\", \"individual.json\")\n",
    "        tmp_inds = load_individuals(json_path, ind_cfg)\n",
    "        for pid, ind in tmp_inds.items():\n",
    "            inds[f\"{key_prefix}_{num}_{pid}\"] = ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b174-dd28-4aa8-8d26-9bc4427a0163",
   "metadata": {},
   "source": [
    "# グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b443de49-2306-476a-b2bb-295506a68dc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 10:43:56,372 => createing time series 02_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  4.04it/s]\n",
      "2022-08-19 10:44:00,581 => createing time series 07_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:29<00:00,  1.65it/s]\n",
      "2022-08-19 10:44:29,610 => createing time series 08_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:05<00:00,  6.74it/s]\n",
      "2022-08-19 10:44:35,252 => createing time series 08_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:31<00:00,  1.42it/s]\n",
      "2022-08-19 10:45:06,842 => createing time series 09_001\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.07it/s]\n",
      "2022-08-19 10:45:09,779 => createing time series 09_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.20it/s]\n",
      "2022-08-19 10:45:23,137 => extracting feature 02_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:15<00:00,  1.09it/s]\n",
      "2022-08-19 10:45:38,742 => extracting feature 07_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:52<00:00,  1.10s/it]\n",
      "2022-08-19 10:46:31,367 => extracting feature 08_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  3.15it/s]\n",
      "2022-08-19 10:46:43,427 => extracting feature 08_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [01:00<00:00,  1.35s/it]\n",
      "2022-08-19 10:47:44,072 => extracting feature 09_001\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:09<00:00,  1.04s/it]\n",
      "2022-08-19 10:47:53,466 => extracting feature 09_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:39<00:00,  2.47s/it]\n",
      "2022-08-19 10:48:33,214 => create train loader\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:03<00:00, 2738.62it/s]\n",
      "2022-08-19 10:48:36,902 => skip creating val loader\n",
      "2022-08-19 10:48:36,903 => create test loader\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2520/2520 [00:00<00:00, 8854.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# create data loader\n",
    "dataset_cfg = train_cfg[\"dataset\"]\n",
    "passing_defs = grp_cfg[\"passing\"][\"default\"]\n",
    "train_loader, val_loader, test_loader = make_data_loaders(\n",
    "    inds, dataset_cfg, passing_defs, logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60011bb5-8a2a-497d-8f5e-a1fe6b56b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "mdl_cfg = {\n",
    "    \"dropouts\": [0.1, 0],\n",
    "    \"hidden_dims\": [128, 64],\n",
    "    \"n_classes\": 2,\n",
    "    \"n_linears\": 2,\n",
    "    \"rnn_dropout\": 0.1,\n",
    "    \"size\": 4,\n",
    "}\n",
    "\n",
    "# grid search parameters\n",
    "params = {\n",
    "    'n_rnns': [1, 2, 3],\n",
    "    'rnn_hidden_dim': [128, 256],\n",
    "    'pos_weight': [8, 16, 32]\n",
    "}\n",
    "\n",
    "# epoch\n",
    "# epoch_len = train_cfg[\"optim\"][\"epoch\"]\n",
    "epoch_len = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9a76f-fd7b-4bde-8e77-33dba46fd26a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 10:48:40,043 => start training\n",
      "2022-08-19 10:48:51,677 Epoch[1/75] train loss: 0.43455, val loss: nan, lr: 0.0010000, time: 11.63\n",
      "2022-08-19 10:49:01,964 Epoch[2/75] train loss: 0.39620, val loss: nan, lr: 0.0010000, time: 10.28\n",
      "2022-08-19 10:49:13,145 Epoch[3/75] train loss: 0.39358, val loss: nan, lr: 0.0010000, time: 11.18\n",
      "2022-08-19 10:49:23,546 Epoch[4/75] train loss: 0.39269, val loss: nan, lr: 0.0010000, time: 10.40\n",
      "2022-08-19 10:49:34,120 Epoch[5/75] train loss: 0.39156, val loss: nan, lr: 0.0010000, time: 10.57\n",
      "2022-08-19 10:49:44,684 Epoch[6/75] train loss: 0.39097, val loss: nan, lr: 0.0010000, time: 10.56\n",
      "2022-08-19 10:49:55,976 Epoch[7/75] train loss: 0.38973, val loss: nan, lr: 0.0010000, time: 11.29\n",
      "2022-08-19 10:50:08,017 Epoch[8/75] train loss: 0.38879, val loss: nan, lr: 0.0010000, time: 12.04\n",
      "2022-08-19 10:50:19,596 Epoch[9/75] train loss: 0.38783, val loss: nan, lr: 0.0010000, time: 11.58\n",
      "2022-08-19 10:50:30,055 Epoch[10/75] train loss: 0.38693, val loss: nan, lr: 0.0010000, time: 10.46\n",
      "2022-08-19 10:50:41,571 Epoch[11/75] train loss: 0.38600, val loss: nan, lr: 0.0010000, time: 11.51\n",
      "2022-08-19 10:50:51,993 Epoch[12/75] train loss: 0.38553, val loss: nan, lr: 0.0010000, time: 10.42\n",
      "2022-08-19 10:51:02,679 Epoch[13/75] train loss: 0.38496, val loss: nan, lr: 0.0010000, time: 10.68\n",
      "2022-08-19 10:51:13,130 Epoch[14/75] train loss: 0.38401, val loss: nan, lr: 0.0010000, time: 10.45\n",
      "2022-08-19 10:51:24,714 Epoch[15/75] train loss: 0.38323, val loss: nan, lr: 0.0010000, time: 11.58\n",
      "2022-08-19 10:51:35,763 Epoch[16/75] train loss: 0.38253, val loss: nan, lr: 0.0010000, time: 11.05\n",
      "2022-08-19 10:51:46,433 Epoch[17/75] train loss: 0.38156, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 10:51:57,068 Epoch[18/75] train loss: 0.38069, val loss: nan, lr: 0.0010000, time: 10.63\n",
      "2022-08-19 10:52:08,529 Epoch[19/75] train loss: 0.38015, val loss: nan, lr: 0.0010000, time: 11.46\n",
      "2022-08-19 10:52:19,360 Epoch[20/75] train loss: 0.37917, val loss: nan, lr: 0.0010000, time: 10.83\n",
      "2022-08-19 10:52:31,238 Epoch[21/75] train loss: 0.37873, val loss: nan, lr: 0.0010000, time: 11.88\n",
      "2022-08-19 10:52:41,375 Epoch[22/75] train loss: 0.37743, val loss: nan, lr: 0.0010000, time: 10.13\n",
      "2022-08-19 10:52:51,951 Epoch[23/75] train loss: 0.37704, val loss: nan, lr: 0.0010000, time: 10.58\n",
      "2022-08-19 10:53:02,238 Epoch[24/75] train loss: 0.37670, val loss: nan, lr: 0.0010000, time: 10.28\n",
      "2022-08-19 10:53:12,451 Epoch[25/75] train loss: 0.37605, val loss: nan, lr: 0.0010000, time: 10.21\n",
      "2022-08-19 10:53:23,003 Epoch[26/75] train loss: 0.37542, val loss: nan, lr: 0.0010000, time: 10.55\n",
      "2022-08-19 10:53:33,369 Epoch[27/75] train loss: 0.37410, val loss: nan, lr: 0.0010000, time: 10.36\n",
      "2022-08-19 10:53:43,689 Epoch[28/75] train loss: 0.37384, val loss: nan, lr: 0.0010000, time: 10.32\n",
      "2022-08-19 10:53:55,654 Epoch[29/75] train loss: 0.37307, val loss: nan, lr: 0.0010000, time: 11.96\n",
      "2022-08-19 10:54:06,083 Epoch[30/75] train loss: 0.37271, val loss: nan, lr: 0.0010000, time: 10.43\n",
      "2022-08-19 10:54:17,545 Epoch[31/75] train loss: 0.37218, val loss: nan, lr: 0.0010000, time: 11.46\n",
      "2022-08-19 10:54:27,874 Epoch[32/75] train loss: 0.37162, val loss: nan, lr: 0.0010000, time: 10.33\n",
      "2022-08-19 10:54:39,700 Epoch[33/75] train loss: 0.37132, val loss: nan, lr: 0.0010000, time: 11.82\n",
      "2022-08-19 10:54:51,276 Epoch[34/75] train loss: 0.37067, val loss: nan, lr: 0.0010000, time: 11.57\n",
      "2022-08-19 10:55:01,611 Epoch[35/75] train loss: 0.37057, val loss: nan, lr: 0.0010000, time: 10.33\n",
      "2022-08-19 10:55:13,621 Epoch[36/75] train loss: 0.37058, val loss: nan, lr: 0.0010000, time: 12.01\n",
      "2022-08-19 10:55:25,225 Epoch[37/75] train loss: 0.36998, val loss: nan, lr: 0.0010000, time: 11.60\n",
      "2022-08-19 10:55:36,090 Epoch[38/75] train loss: 0.36978, val loss: nan, lr: 0.0010000, time: 10.86\n",
      "2022-08-19 10:55:47,002 Epoch[39/75] train loss: 0.36931, val loss: nan, lr: 0.0010000, time: 10.91\n",
      "2022-08-19 10:55:57,887 Epoch[40/75] train loss: 0.36841, val loss: nan, lr: 0.0010000, time: 10.88\n",
      "2022-08-19 10:56:10,111 Epoch[41/75] train loss: 0.36823, val loss: nan, lr: 0.0010000, time: 12.22\n",
      "2022-08-19 10:56:20,440 Epoch[42/75] train loss: 0.36823, val loss: nan, lr: 0.0010000, time: 10.33\n",
      "2022-08-19 10:56:30,588 Epoch[43/75] train loss: 0.36769, val loss: nan, lr: 0.0010000, time: 10.15\n",
      "2022-08-19 10:56:40,952 Epoch[44/75] train loss: 0.36775, val loss: nan, lr: 0.0010000, time: 10.36\n",
      "2022-08-19 10:56:51,181 Epoch[45/75] train loss: 0.36685, val loss: nan, lr: 0.0010000, time: 10.23\n",
      "2022-08-19 10:57:01,604 Epoch[46/75] train loss: 0.36712, val loss: nan, lr: 0.0010000, time: 10.42\n",
      "2022-08-19 10:57:12,373 Epoch[47/75] train loss: 0.36613, val loss: nan, lr: 0.0010000, time: 10.77\n",
      "2022-08-19 10:57:23,195 Epoch[48/75] train loss: 0.36690, val loss: nan, lr: 0.0010000, time: 10.82\n",
      "2022-08-19 10:57:33,836 Epoch[49/75] train loss: 0.36652, val loss: nan, lr: 0.0010000, time: 10.64\n",
      "2022-08-19 10:57:45,232 Epoch[50/75] train loss: 0.36661, val loss: nan, lr: 0.0010000, time: 11.39\n",
      "2022-08-19 10:57:55,836 Epoch[51/75] train loss: 0.36585, val loss: nan, lr: 0.0010000, time: 10.60\n",
      "2022-08-19 10:58:06,794 Epoch[52/75] train loss: 0.36607, val loss: nan, lr: 0.0010000, time: 10.96\n",
      "2022-08-19 10:58:17,481 Epoch[53/75] train loss: 0.36551, val loss: nan, lr: 0.0010000, time: 10.68\n",
      "2022-08-19 10:58:27,870 Epoch[54/75] train loss: 0.36538, val loss: nan, lr: 0.0010000, time: 10.39\n",
      "2022-08-19 10:58:38,613 Epoch[55/75] train loss: 0.36543, val loss: nan, lr: 0.0010000, time: 10.74\n",
      "2022-08-19 10:58:49,005 Epoch[56/75] train loss: 0.36499, val loss: nan, lr: 0.0010000, time: 10.39\n",
      "2022-08-19 10:58:59,614 Epoch[57/75] train loss: 0.36416, val loss: nan, lr: 0.0010000, time: 10.61\n",
      "2022-08-19 10:59:10,610 Epoch[58/75] train loss: 0.36443, val loss: nan, lr: 0.0010000, time: 10.99\n",
      "2022-08-19 10:59:21,308 Epoch[59/75] train loss: 0.36519, val loss: nan, lr: 0.0010000, time: 10.70\n",
      "2022-08-19 10:59:33,344 Epoch[60/75] train loss: 0.36406, val loss: nan, lr: 0.0010000, time: 12.04\n",
      "2022-08-19 10:59:44,434 Epoch[61/75] train loss: 0.36460, val loss: nan, lr: 0.0010000, time: 11.09\n",
      "2022-08-19 10:59:54,621 Epoch[62/75] train loss: 0.36459, val loss: nan, lr: 0.0010000, time: 10.19\n",
      "2022-08-19 11:00:05,390 Epoch[63/75] train loss: 0.36449, val loss: nan, lr: 0.0010000, time: 10.77\n",
      "2022-08-19 11:00:15,888 Epoch[64/75] train loss: 0.36370, val loss: nan, lr: 0.0010000, time: 10.50\n",
      "2022-08-19 11:00:27,354 Epoch[65/75] train loss: 0.36436, val loss: nan, lr: 0.0010000, time: 11.46\n",
      "2022-08-19 11:00:39,466 Epoch[66/75] train loss: 0.36349, val loss: nan, lr: 0.0010000, time: 12.11\n",
      "2022-08-19 11:00:50,466 Epoch[67/75] train loss: 0.36307, val loss: nan, lr: 0.0010000, time: 11.00\n",
      "2022-08-19 11:01:00,675 Epoch[68/75] train loss: 0.36427, val loss: nan, lr: 0.0010000, time: 10.21\n",
      "2022-08-19 11:01:10,949 Epoch[69/75] train loss: 0.36382, val loss: nan, lr: 0.0010000, time: 10.27\n",
      "2022-08-19 11:01:21,201 Epoch[70/75] train loss: 0.36372, val loss: nan, lr: 0.0010000, time: 10.25\n",
      "2022-08-19 11:01:31,499 Epoch[71/75] train loss: 0.36367, val loss: nan, lr: 0.0010000, time: 10.30\n",
      "2022-08-19 11:01:42,379 Epoch[72/75] train loss: 0.36238, val loss: nan, lr: 0.0010000, time: 10.88\n",
      "2022-08-19 11:01:52,902 Epoch[73/75] train loss: 0.36299, val loss: nan, lr: 0.0010000, time: 10.52\n",
      "2022-08-19 11:02:03,513 Epoch[74/75] train loss: 0.36241, val loss: nan, lr: 0.0010000, time: 10.61\n",
      "2022-08-19 11:02:14,496 Epoch[75/75] train loss: 0.36315, val loss: nan, lr: 0.0010000, time: 10.98\n",
      "2022-08-19 11:02:14,498 => end training\n",
      "2022-08-19 11:02:14,498 => calculating train scores\n",
      "2022-08-19 11:02:28,945 => train score\n",
      "accuracy: 0.9981215287222444\n",
      "presision: 0.7335356259833671\n",
      "recall: 0.9919452887537994\n",
      "f1: 0.8433906189430158\n",
      "2022-08-19 11:02:28,947 => calculating test scores\n",
      "2022-08-19 11:02:32,859 => test score\n",
      "accuracy: 0.992539361410182\n",
      "presision: 0.19536260483473114\n",
      "recall: 0.3590208522212149\n",
      "f1: 0.25303514376996805\n",
      "2022-08-19 11:02:32,872 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:02:43,119 Epoch[1/75] train loss: 0.47699, val loss: nan, lr: 0.0010000, time: 10.25\n",
      "2022-08-19 11:02:53,314 Epoch[2/75] train loss: 0.42830, val loss: nan, lr: 0.0010000, time: 10.19\n",
      "2022-08-19 11:03:03,418 Epoch[3/75] train loss: 0.42508, val loss: nan, lr: 0.0010000, time: 10.10\n",
      "2022-08-19 11:03:13,930 Epoch[4/75] train loss: 0.42309, val loss: nan, lr: 0.0010000, time: 10.51\n",
      "2022-08-19 11:03:24,234 Epoch[5/75] train loss: 0.42122, val loss: nan, lr: 0.0010000, time: 10.30\n",
      "2022-08-19 11:03:34,652 Epoch[6/75] train loss: 0.41997, val loss: nan, lr: 0.0010000, time: 10.42\n",
      "2022-08-19 11:03:45,373 Epoch[7/75] train loss: 0.41900, val loss: nan, lr: 0.0010000, time: 10.72\n",
      "2022-08-19 11:03:55,782 Epoch[8/75] train loss: 0.41745, val loss: nan, lr: 0.0010000, time: 10.41\n",
      "2022-08-19 11:04:06,465 Epoch[9/75] train loss: 0.41585, val loss: nan, lr: 0.0010000, time: 10.68\n",
      "2022-08-19 11:04:16,724 Epoch[10/75] train loss: 0.41464, val loss: nan, lr: 0.0010000, time: 10.26\n",
      "2022-08-19 11:04:27,208 Epoch[11/75] train loss: 0.41372, val loss: nan, lr: 0.0010000, time: 10.48\n",
      "2022-08-19 11:04:37,576 Epoch[12/75] train loss: 0.41157, val loss: nan, lr: 0.0010000, time: 10.37\n",
      "2022-08-19 11:04:48,067 Epoch[13/75] train loss: 0.41082, val loss: nan, lr: 0.0010000, time: 10.49\n",
      "2022-08-19 11:04:58,415 Epoch[14/75] train loss: 0.40938, val loss: nan, lr: 0.0010000, time: 10.35\n",
      "2022-08-19 11:05:08,718 Epoch[15/75] train loss: 0.40766, val loss: nan, lr: 0.0010000, time: 10.30\n",
      "2022-08-19 11:05:19,035 Epoch[16/75] train loss: 0.40633, val loss: nan, lr: 0.0010000, time: 10.31\n",
      "2022-08-19 11:05:29,704 Epoch[17/75] train loss: 0.40505, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 11:05:41,006 Epoch[18/75] train loss: 0.40408, val loss: nan, lr: 0.0010000, time: 11.30\n",
      "2022-08-19 11:05:51,847 Epoch[19/75] train loss: 0.40201, val loss: nan, lr: 0.0010000, time: 10.84\n",
      "2022-08-19 11:06:03,144 Epoch[20/75] train loss: 0.40164, val loss: nan, lr: 0.0010000, time: 11.30\n",
      "2022-08-19 11:06:14,328 Epoch[21/75] train loss: 0.40042, val loss: nan, lr: 0.0010000, time: 11.18\n",
      "2022-08-19 11:06:24,637 Epoch[22/75] train loss: 0.39977, val loss: nan, lr: 0.0010000, time: 10.31\n",
      "2022-08-19 11:06:34,985 Epoch[23/75] train loss: 0.39832, val loss: nan, lr: 0.0010000, time: 10.35\n",
      "2022-08-19 11:06:46,558 Epoch[24/75] train loss: 0.39756, val loss: nan, lr: 0.0010000, time: 11.57\n",
      "2022-08-19 11:06:57,446 Epoch[25/75] train loss: 0.39637, val loss: nan, lr: 0.0010000, time: 10.89\n",
      "2022-08-19 11:07:08,152 Epoch[26/75] train loss: 0.39518, val loss: nan, lr: 0.0010000, time: 10.70\n",
      "2022-08-19 11:07:19,251 Epoch[27/75] train loss: 0.39631, val loss: nan, lr: 0.0010000, time: 11.10\n",
      "2022-08-19 11:07:30,120 Epoch[28/75] train loss: 0.39446, val loss: nan, lr: 0.0010000, time: 10.87\n",
      "2022-08-19 11:07:40,377 Epoch[29/75] train loss: 0.39290, val loss: nan, lr: 0.0010000, time: 10.26\n",
      "2022-08-19 11:07:52,029 Epoch[30/75] train loss: 0.39280, val loss: nan, lr: 0.0010000, time: 11.65\n",
      "2022-08-19 11:08:02,516 Epoch[31/75] train loss: 0.39187, val loss: nan, lr: 0.0010000, time: 10.49\n",
      "2022-08-19 11:08:13,874 Epoch[32/75] train loss: 0.39156, val loss: nan, lr: 0.0010000, time: 11.36\n",
      "2022-08-19 11:08:24,363 Epoch[33/75] train loss: 0.39093, val loss: nan, lr: 0.0010000, time: 10.49\n",
      "2022-08-19 11:08:34,796 Epoch[34/75] train loss: 0.39084, val loss: nan, lr: 0.0010000, time: 10.43\n",
      "2022-08-19 11:08:45,865 Epoch[35/75] train loss: 0.39016, val loss: nan, lr: 0.0010000, time: 11.07\n",
      "2022-08-19 11:08:56,244 Epoch[36/75] train loss: 0.39001, val loss: nan, lr: 0.0010000, time: 10.38\n",
      "2022-08-19 11:09:07,136 Epoch[37/75] train loss: 0.38966, val loss: nan, lr: 0.0010000, time: 10.89\n",
      "2022-08-19 11:09:17,888 Epoch[38/75] train loss: 0.38947, val loss: nan, lr: 0.0010000, time: 10.75\n",
      "2022-08-19 11:09:29,329 Epoch[39/75] train loss: 0.38734, val loss: nan, lr: 0.0010000, time: 11.44\n",
      "2022-08-19 11:09:39,847 Epoch[40/75] train loss: 0.38766, val loss: nan, lr: 0.0010000, time: 10.52\n",
      "2022-08-19 11:09:50,158 Epoch[41/75] train loss: 0.38732, val loss: nan, lr: 0.0010000, time: 10.31\n",
      "2022-08-19 11:10:01,775 Epoch[42/75] train loss: 0.38764, val loss: nan, lr: 0.0010000, time: 11.62\n",
      "2022-08-19 11:10:13,157 Epoch[43/75] train loss: 0.38660, val loss: nan, lr: 0.0010000, time: 11.38\n",
      "2022-08-19 11:10:23,505 Epoch[44/75] train loss: 0.38661, val loss: nan, lr: 0.0010000, time: 10.35\n",
      "2022-08-19 11:10:33,823 Epoch[45/75] train loss: 0.38610, val loss: nan, lr: 0.0010000, time: 10.32\n",
      "2022-08-19 11:10:44,181 Epoch[46/75] train loss: 0.38528, val loss: nan, lr: 0.0010000, time: 10.36\n",
      "2022-08-19 11:10:54,521 Epoch[47/75] train loss: 0.38512, val loss: nan, lr: 0.0010000, time: 10.34\n",
      "2022-08-19 11:11:05,099 Epoch[48/75] train loss: 0.38526, val loss: nan, lr: 0.0010000, time: 10.58\n",
      "2022-08-19 11:11:16,933 Epoch[49/75] train loss: 0.38526, val loss: nan, lr: 0.0010000, time: 11.83\n",
      "2022-08-19 11:11:27,292 Epoch[50/75] train loss: 0.38517, val loss: nan, lr: 0.0010000, time: 10.36\n",
      "2022-08-19 11:11:37,578 Epoch[51/75] train loss: 0.38397, val loss: nan, lr: 0.0010000, time: 10.28\n",
      "2022-08-19 11:11:47,912 Epoch[52/75] train loss: 0.38507, val loss: nan, lr: 0.0010000, time: 10.33\n",
      "2022-08-19 11:11:59,071 Epoch[53/75] train loss: 0.38402, val loss: nan, lr: 0.0010000, time: 11.16\n",
      "2022-08-19 11:12:10,066 Epoch[54/75] train loss: 0.38311, val loss: nan, lr: 0.0010000, time: 10.99\n",
      "2022-08-19 11:12:21,512 Epoch[55/75] train loss: 0.38257, val loss: nan, lr: 0.0010000, time: 11.44\n",
      "2022-08-19 11:12:31,855 Epoch[56/75] train loss: 0.38353, val loss: nan, lr: 0.0010000, time: 10.34\n",
      "2022-08-19 11:12:42,768 Epoch[57/75] train loss: 0.38312, val loss: nan, lr: 0.0010000, time: 10.91\n",
      "2022-08-19 11:12:53,202 Epoch[58/75] train loss: 0.38231, val loss: nan, lr: 0.0010000, time: 10.43\n",
      "2022-08-19 11:13:03,545 Epoch[59/75] train loss: 0.38204, val loss: nan, lr: 0.0010000, time: 10.34\n",
      "2022-08-19 11:13:14,598 Epoch[60/75] train loss: 0.38170, val loss: nan, lr: 0.0010000, time: 11.05\n",
      "2022-08-19 11:13:26,382 Epoch[61/75] train loss: 0.38309, val loss: nan, lr: 0.0010000, time: 11.78\n",
      "2022-08-19 11:13:38,247 Epoch[62/75] train loss: 0.38151, val loss: nan, lr: 0.0010000, time: 11.86\n",
      "2022-08-19 11:13:48,950 Epoch[63/75] train loss: 0.38213, val loss: nan, lr: 0.0010000, time: 10.70\n",
      "2022-08-19 11:13:59,608 Epoch[64/75] train loss: 0.38113, val loss: nan, lr: 0.0010000, time: 10.66\n",
      "2022-08-19 11:14:10,100 Epoch[65/75] train loss: 0.38258, val loss: nan, lr: 0.0010000, time: 10.49\n",
      "2022-08-19 11:14:21,040 Epoch[66/75] train loss: 0.38117, val loss: nan, lr: 0.0010000, time: 10.94\n",
      "2022-08-19 11:14:31,492 Epoch[67/75] train loss: 0.38086, val loss: nan, lr: 0.0010000, time: 10.45\n",
      "2022-08-19 11:14:43,083 Epoch[68/75] train loss: 0.38096, val loss: nan, lr: 0.0010000, time: 11.59\n",
      "2022-08-19 11:14:53,895 Epoch[69/75] train loss: 0.38118, val loss: nan, lr: 0.0010000, time: 10.81\n",
      "2022-08-19 11:15:05,616 Epoch[70/75] train loss: 0.37972, val loss: nan, lr: 0.0010000, time: 11.72\n",
      "2022-08-19 11:15:16,529 Epoch[71/75] train loss: 0.38123, val loss: nan, lr: 0.0010000, time: 10.91\n",
      "2022-08-19 11:15:27,376 Epoch[72/75] train loss: 0.38098, val loss: nan, lr: 0.0010000, time: 10.84\n",
      "2022-08-19 11:15:37,754 Epoch[73/75] train loss: 0.37948, val loss: nan, lr: 0.0010000, time: 10.38\n",
      "2022-08-19 11:15:48,009 Epoch[74/75] train loss: 0.37970, val loss: nan, lr: 0.0010000, time: 10.25\n",
      "2022-08-19 11:15:59,248 Epoch[75/75] train loss: 0.38008, val loss: nan, lr: 0.0010000, time: 11.24\n",
      "2022-08-19 11:15:59,249 => end training\n",
      "2022-08-19 11:15:59,250 => calculating train scores\n",
      "2022-08-19 11:16:14,402 => train score\n",
      "accuracy: 0.9976209130269348\n",
      "presision: 0.6828505938737237\n",
      "recall: 0.996048632218845\n",
      "f1: 0.8102361231301768\n",
      "2022-08-19 11:16:14,404 => calculating test scores\n",
      "2022-08-19 11:16:18,305 => test score\n",
      "accuracy: 0.9919203007230885\n",
      "presision: 0.18538088947600176\n",
      "recall: 0.38168631006346326\n",
      "f1: 0.24955542382928272\n",
      "2022-08-19 11:16:18,320 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:16:28,714 Epoch[1/75] train loss: 0.51894, val loss: nan, lr: 0.0010000, time: 10.39\n",
      "2022-08-19 11:16:39,001 Epoch[2/75] train loss: 0.47887, val loss: nan, lr: 0.0010000, time: 10.29\n",
      "2022-08-19 11:16:49,926 Epoch[3/75] train loss: 0.47501, val loss: nan, lr: 0.0010000, time: 10.92\n",
      "2022-08-19 11:17:01,685 Epoch[4/75] train loss: 0.47196, val loss: nan, lr: 0.0010000, time: 11.76\n",
      "2022-08-19 11:17:11,930 Epoch[5/75] train loss: 0.46996, val loss: nan, lr: 0.0010000, time: 10.24\n",
      "2022-08-19 11:17:22,597 Epoch[6/75] train loss: 0.46690, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 11:17:33,451 Epoch[7/75] train loss: 0.46426, val loss: nan, lr: 0.0010000, time: 10.85\n",
      "2022-08-19 11:17:44,852 Epoch[8/75] train loss: 0.46292, val loss: nan, lr: 0.0010000, time: 11.40\n",
      "2022-08-19 11:17:56,060 Epoch[9/75] train loss: 0.46068, val loss: nan, lr: 0.0010000, time: 11.21\n",
      "2022-08-19 11:18:07,751 Epoch[10/75] train loss: 0.45958, val loss: nan, lr: 0.0010000, time: 11.69\n",
      "2022-08-19 11:18:19,638 Epoch[11/75] train loss: 0.45723, val loss: nan, lr: 0.0010000, time: 11.89\n",
      "2022-08-19 11:18:29,992 Epoch[12/75] train loss: 0.45597, val loss: nan, lr: 0.0010000, time: 10.35\n",
      "2022-08-19 11:18:40,289 Epoch[13/75] train loss: 0.45423, val loss: nan, lr: 0.0010000, time: 10.30\n",
      "2022-08-19 11:18:51,354 Epoch[14/75] train loss: 0.45252, val loss: nan, lr: 0.0010000, time: 11.06\n",
      "2022-08-19 11:19:02,912 Epoch[15/75] train loss: 0.45114, val loss: nan, lr: 0.0010000, time: 11.56\n",
      "2022-08-19 11:19:14,058 Epoch[16/75] train loss: 0.44925, val loss: nan, lr: 0.0010000, time: 11.14\n",
      "2022-08-19 11:19:24,532 Epoch[17/75] train loss: 0.44694, val loss: nan, lr: 0.0010000, time: 10.47\n",
      "2022-08-19 11:19:34,854 Epoch[18/75] train loss: 0.44738, val loss: nan, lr: 0.0010000, time: 10.32\n",
      "2022-08-19 11:19:45,284 Epoch[19/75] train loss: 0.44539, val loss: nan, lr: 0.0010000, time: 10.43\n",
      "2022-08-19 11:19:56,503 Epoch[20/75] train loss: 0.44380, val loss: nan, lr: 0.0010000, time: 11.22\n",
      "2022-08-19 11:20:07,354 Epoch[21/75] train loss: 0.44161, val loss: nan, lr: 0.0010000, time: 10.85\n",
      "2022-08-19 11:20:18,777 Epoch[22/75] train loss: 0.44099, val loss: nan, lr: 0.0010000, time: 11.42\n",
      "2022-08-19 11:20:30,702 Epoch[23/75] train loss: 0.43873, val loss: nan, lr: 0.0010000, time: 11.92\n",
      "2022-08-19 11:20:42,252 Epoch[24/75] train loss: 0.43784, val loss: nan, lr: 0.0010000, time: 11.55\n",
      "2022-08-19 11:20:53,859 Epoch[25/75] train loss: 0.43651, val loss: nan, lr: 0.0010000, time: 11.60\n",
      "2022-08-19 11:21:04,100 Epoch[26/75] train loss: 0.43620, val loss: nan, lr: 0.0010000, time: 10.24\n",
      "2022-08-19 11:21:14,459 Epoch[27/75] train loss: 0.43564, val loss: nan, lr: 0.0010000, time: 10.36\n",
      "2022-08-19 11:21:25,428 Epoch[28/75] train loss: 0.43388, val loss: nan, lr: 0.0010000, time: 10.97\n",
      "2022-08-19 11:21:35,873 Epoch[29/75] train loss: 0.43253, val loss: nan, lr: 0.0010000, time: 10.44\n",
      "2022-08-19 11:21:47,224 Epoch[30/75] train loss: 0.43178, val loss: nan, lr: 0.0010000, time: 11.35\n",
      "2022-08-19 11:21:57,716 Epoch[31/75] train loss: 0.43080, val loss: nan, lr: 0.0010000, time: 10.49\n",
      "2022-08-19 11:22:08,222 Epoch[32/75] train loss: 0.43140, val loss: nan, lr: 0.0010000, time: 10.50\n",
      "2022-08-19 11:22:19,701 Epoch[33/75] train loss: 0.43011, val loss: nan, lr: 0.0010000, time: 11.48\n",
      "2022-08-19 11:22:30,699 Epoch[34/75] train loss: 0.42816, val loss: nan, lr: 0.0010000, time: 11.00\n",
      "2022-08-19 11:22:41,117 Epoch[35/75] train loss: 0.42878, val loss: nan, lr: 0.0010000, time: 10.42\n",
      "2022-08-19 11:22:51,304 Epoch[36/75] train loss: 0.42726, val loss: nan, lr: 0.0010000, time: 10.18\n",
      "2022-08-19 11:23:03,241 Epoch[37/75] train loss: 0.42617, val loss: nan, lr: 0.0010000, time: 11.94\n",
      "2022-08-19 11:23:13,906 Epoch[38/75] train loss: 0.42559, val loss: nan, lr: 0.0010000, time: 10.66\n",
      "2022-08-19 11:23:24,334 Epoch[39/75] train loss: 0.42691, val loss: nan, lr: 0.0010000, time: 10.43\n",
      "2022-08-19 11:23:35,066 Epoch[40/75] train loss: 0.42551, val loss: nan, lr: 0.0010000, time: 10.73\n",
      "2022-08-19 11:23:46,655 Epoch[41/75] train loss: 0.42253, val loss: nan, lr: 0.0010000, time: 11.59\n",
      "2022-08-19 11:23:58,731 Epoch[42/75] train loss: 0.42334, val loss: nan, lr: 0.0010000, time: 12.07\n",
      "2022-08-19 11:24:09,032 Epoch[43/75] train loss: 0.42282, val loss: nan, lr: 0.0010000, time: 10.30\n",
      "2022-08-19 11:24:19,447 Epoch[44/75] train loss: 0.42272, val loss: nan, lr: 0.0010000, time: 10.41\n",
      "2022-08-19 11:24:31,277 Epoch[45/75] train loss: 0.42510, val loss: nan, lr: 0.0010000, time: 11.83\n",
      "2022-08-19 11:24:43,257 Epoch[46/75] train loss: 0.42260, val loss: nan, lr: 0.0010000, time: 11.98\n",
      "2022-08-19 11:24:53,725 Epoch[47/75] train loss: 0.42195, val loss: nan, lr: 0.0010000, time: 10.47\n",
      "2022-08-19 11:25:05,536 Epoch[48/75] train loss: 0.42182, val loss: nan, lr: 0.0010000, time: 11.81\n",
      "2022-08-19 11:25:16,203 Epoch[49/75] train loss: 0.42176, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 11:25:26,572 Epoch[50/75] train loss: 0.42013, val loss: nan, lr: 0.0010000, time: 10.37\n",
      "2022-08-19 11:25:36,751 Epoch[51/75] train loss: 0.41898, val loss: nan, lr: 0.0010000, time: 10.18\n",
      "2022-08-19 11:25:47,423 Epoch[52/75] train loss: 0.41954, val loss: nan, lr: 0.0010000, time: 10.67\n",
      "2022-08-19 11:25:57,876 Epoch[53/75] train loss: 0.42097, val loss: nan, lr: 0.0010000, time: 10.45\n",
      "2022-08-19 11:26:08,065 Epoch[54/75] train loss: 0.41829, val loss: nan, lr: 0.0010000, time: 10.19\n",
      "2022-08-19 11:26:20,186 Epoch[55/75] train loss: 0.41944, val loss: nan, lr: 0.0010000, time: 12.12\n",
      "2022-08-19 11:26:31,576 Epoch[56/75] train loss: 0.41956, val loss: nan, lr: 0.0010000, time: 11.39\n",
      "2022-08-19 11:26:41,835 Epoch[57/75] train loss: 0.41796, val loss: nan, lr: 0.0010000, time: 10.26\n",
      "2022-08-19 11:26:53,329 Epoch[58/75] train loss: 0.41785, val loss: nan, lr: 0.0010000, time: 11.49\n",
      "2022-08-19 11:27:03,726 Epoch[59/75] train loss: 0.41706, val loss: nan, lr: 0.0010000, time: 10.39\n",
      "2022-08-19 11:27:14,029 Epoch[60/75] train loss: 0.41647, val loss: nan, lr: 0.0010000, time: 10.30\n",
      "2022-08-19 11:27:25,958 Epoch[61/75] train loss: 0.41727, val loss: nan, lr: 0.0010000, time: 11.93\n",
      "2022-08-19 11:27:36,400 Epoch[62/75] train loss: 0.41620, val loss: nan, lr: 0.0010000, time: 10.44\n",
      "2022-08-19 11:27:47,128 Epoch[63/75] train loss: 0.41619, val loss: nan, lr: 0.0010000, time: 10.73\n",
      "2022-08-19 11:27:58,108 Epoch[64/75] train loss: 0.41717, val loss: nan, lr: 0.0010000, time: 10.98\n",
      "2022-08-19 11:28:09,325 Epoch[65/75] train loss: 0.41686, val loss: nan, lr: 0.0010000, time: 11.21\n",
      "2022-08-19 11:28:21,210 Epoch[66/75] train loss: 0.41798, val loss: nan, lr: 0.0010000, time: 11.88\n",
      "2022-08-19 11:28:32,704 Epoch[67/75] train loss: 0.41504, val loss: nan, lr: 0.0010000, time: 11.49\n",
      "2022-08-19 11:28:44,132 Epoch[68/75] train loss: 0.41516, val loss: nan, lr: 0.0010000, time: 11.43\n",
      "2022-08-19 11:28:55,649 Epoch[69/75] train loss: 0.41498, val loss: nan, lr: 0.0010000, time: 11.51\n",
      "2022-08-19 11:29:07,685 Epoch[70/75] train loss: 0.41295, val loss: nan, lr: 0.0010000, time: 12.03\n",
      "2022-08-19 11:29:17,973 Epoch[71/75] train loss: 0.41366, val loss: nan, lr: 0.0010000, time: 10.29\n",
      "2022-08-19 11:29:29,469 Epoch[72/75] train loss: 0.41458, val loss: nan, lr: 0.0010000, time: 11.49\n",
      "2022-08-19 11:29:40,059 Epoch[73/75] train loss: 0.41330, val loss: nan, lr: 0.0010000, time: 10.59\n",
      "2022-08-19 11:29:51,205 Epoch[74/75] train loss: 0.41498, val loss: nan, lr: 0.0010000, time: 11.14\n",
      "2022-08-19 11:30:02,190 Epoch[75/75] train loss: 0.41412, val loss: nan, lr: 0.0010000, time: 10.98\n",
      "2022-08-19 11:30:02,191 => end training\n",
      "2022-08-19 11:30:02,192 => calculating train scores\n",
      "2022-08-19 11:30:17,210 => train score\n",
      "accuracy: 0.9939306159045451\n",
      "presision: 0.4556343019135365\n",
      "recall: 0.9770516717325228\n",
      "f1: 0.6214596423392943\n",
      "2022-08-19 11:30:17,213 => calculating test scores\n",
      "2022-08-19 11:30:21,064 => test score\n",
      "accuracy: 0.9874241331554864\n",
      "presision: 0.12018201284796574\n",
      "recall: 0.4070716228467815\n",
      "f1: 0.18557553213473857\n",
      "2022-08-19 11:30:21,082 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:30:34,166 Epoch[1/75] train loss: 0.46070, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:30:47,166 Epoch[2/75] train loss: 0.39776, val loss: nan, lr: 0.0010000, time: 13.00\n",
      "2022-08-19 11:31:00,323 Epoch[3/75] train loss: 0.39469, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:31:13,400 Epoch[4/75] train loss: 0.39359, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:31:26,542 Epoch[5/75] train loss: 0.39233, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:31:39,719 Epoch[6/75] train loss: 0.39107, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:31:52,830 Epoch[7/75] train loss: 0.38966, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:32:06,019 Epoch[8/75] train loss: 0.38890, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:32:19,208 Epoch[9/75] train loss: 0.38779, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:32:32,478 Epoch[10/75] train loss: 0.38717, val loss: nan, lr: 0.0010000, time: 13.27\n",
      "2022-08-19 11:32:45,646 Epoch[11/75] train loss: 0.38628, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:32:58,999 Epoch[12/75] train loss: 0.38567, val loss: nan, lr: 0.0010000, time: 13.35\n",
      "2022-08-19 11:33:12,249 Epoch[13/75] train loss: 0.38468, val loss: nan, lr: 0.0010000, time: 13.25\n",
      "2022-08-19 11:33:25,426 Epoch[14/75] train loss: 0.38358, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:33:38,651 Epoch[15/75] train loss: 0.38286, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:33:51,896 Epoch[16/75] train loss: 0.38175, val loss: nan, lr: 0.0010000, time: 13.24\n",
      "2022-08-19 11:34:05,093 Epoch[17/75] train loss: 0.38097, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:34:18,232 Epoch[18/75] train loss: 0.38028, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:34:31,448 Epoch[19/75] train loss: 0.37913, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:34:44,534 Epoch[20/75] train loss: 0.37914, val loss: nan, lr: 0.0010000, time: 13.08\n",
      "2022-08-19 11:34:57,808 Epoch[21/75] train loss: 0.37783, val loss: nan, lr: 0.0010000, time: 13.27\n",
      "2022-08-19 11:35:10,950 Epoch[22/75] train loss: 0.37644, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:35:24,073 Epoch[23/75] train loss: 0.37609, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:35:37,350 Epoch[24/75] train loss: 0.37562, val loss: nan, lr: 0.0010000, time: 13.28\n",
      "2022-08-19 11:35:50,520 Epoch[25/75] train loss: 0.37422, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:36:03,739 Epoch[26/75] train loss: 0.37379, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:36:17,004 Epoch[27/75] train loss: 0.37319, val loss: nan, lr: 0.0010000, time: 13.26\n",
      "2022-08-19 11:36:30,194 Epoch[28/75] train loss: 0.37270, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:36:43,300 Epoch[29/75] train loss: 0.37174, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:36:56,552 Epoch[30/75] train loss: 0.37051, val loss: nan, lr: 0.0010000, time: 13.25\n",
      "2022-08-19 11:37:09,821 Epoch[31/75] train loss: 0.37082, val loss: nan, lr: 0.0010000, time: 13.27\n",
      "2022-08-19 11:37:22,980 Epoch[32/75] train loss: 0.37015, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:37:36,210 Epoch[33/75] train loss: 0.36922, val loss: nan, lr: 0.0010000, time: 13.23\n",
      "2022-08-19 11:37:49,405 Epoch[34/75] train loss: 0.36915, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:38:02,523 Epoch[35/75] train loss: 0.36873, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:38:15,747 Epoch[36/75] train loss: 0.36827, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:38:28,876 Epoch[37/75] train loss: 0.36772, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:38:42,091 Epoch[38/75] train loss: 0.36821, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:38:55,284 Epoch[39/75] train loss: 0.36767, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:39:08,421 Epoch[40/75] train loss: 0.36652, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:39:21,644 Epoch[41/75] train loss: 0.36638, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:39:34,819 Epoch[42/75] train loss: 0.36613, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:39:47,954 Epoch[43/75] train loss: 0.36532, val loss: nan, lr: 0.0010000, time: 13.13\n",
      "2022-08-19 11:40:01,125 Epoch[44/75] train loss: 0.36553, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:40:14,289 Epoch[45/75] train loss: 0.36576, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:40:27,490 Epoch[46/75] train loss: 0.36532, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:40:40,661 Epoch[47/75] train loss: 0.36513, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:40:53,781 Epoch[48/75] train loss: 0.36461, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:41:06,919 Epoch[49/75] train loss: 0.36450, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:41:19,969 Epoch[50/75] train loss: 0.36440, val loss: nan, lr: 0.0010000, time: 13.05\n",
      "2022-08-19 11:41:33,129 Epoch[51/75] train loss: 0.36393, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:41:46,329 Epoch[52/75] train loss: 0.36398, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:41:59,486 Epoch[53/75] train loss: 0.36435, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:42:12,661 Epoch[54/75] train loss: 0.36320, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:42:25,870 Epoch[55/75] train loss: 0.36447, val loss: nan, lr: 0.0010000, time: 13.21\n",
      "2022-08-19 11:42:39,056 Epoch[56/75] train loss: 0.36365, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:42:52,238 Epoch[57/75] train loss: 0.36303, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:43:05,418 Epoch[58/75] train loss: 0.36330, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:43:18,521 Epoch[59/75] train loss: 0.36323, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:43:31,641 Epoch[60/75] train loss: 0.36253, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:43:44,811 Epoch[61/75] train loss: 0.36355, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:43:57,844 Epoch[62/75] train loss: 0.36320, val loss: nan, lr: 0.0010000, time: 13.03\n",
      "2022-08-19 11:44:11,047 Epoch[63/75] train loss: 0.36265, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:44:24,187 Epoch[64/75] train loss: 0.36239, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:44:37,389 Epoch[65/75] train loss: 0.36188, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:44:50,559 Epoch[66/75] train loss: 0.36305, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:45:03,628 Epoch[67/75] train loss: 0.36190, val loss: nan, lr: 0.0010000, time: 13.07\n",
      "2022-08-19 11:45:16,790 Epoch[68/75] train loss: 0.36268, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:45:29,957 Epoch[69/75] train loss: 0.36236, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:45:43,122 Epoch[70/75] train loss: 0.36228, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:45:56,301 Epoch[71/75] train loss: 0.36142, val loss: nan, lr: 0.0010000, time: 13.18\n",
      "2022-08-19 11:46:09,478 Epoch[72/75] train loss: 0.36287, val loss: nan, lr: 0.0010000, time: 13.17\n",
      "2022-08-19 11:46:22,641 Epoch[73/75] train loss: 0.36156, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:46:35,833 Epoch[74/75] train loss: 0.36199, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:46:49,031 Epoch[75/75] train loss: 0.36187, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:46:49,032 => end training\n",
      "2022-08-19 11:46:49,032 => calculating train scores\n",
      "2022-08-19 11:47:04,941 => train score\n",
      "accuracy: 0.9978347983704416\n",
      "presision: 0.7087100330760749\n",
      "recall: 0.9768996960486322\n",
      "f1: 0.8214696485623004\n",
      "2022-08-19 11:47:04,942 => calculating test scores\n",
      "2022-08-19 11:47:08,899 => test score\n",
      "accuracy: 0.9920096496882359\n",
      "presision: 0.16240963855421686\n",
      "recall: 0.3055303717135086\n",
      "f1: 0.21208307111390812\n",
      "2022-08-19 11:47:08,914 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 11:47:22,104 Epoch[1/75] train loss: 0.47154, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:47:35,218 Epoch[2/75] train loss: 0.42835, val loss: nan, lr: 0.0010000, time: 13.11\n",
      "2022-08-19 11:47:48,363 Epoch[3/75] train loss: 0.42495, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:48:01,514 Epoch[4/75] train loss: 0.42291, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:48:14,661 Epoch[5/75] train loss: 0.42128, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:48:27,866 Epoch[6/75] train loss: 0.41919, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:48:41,022 Epoch[7/75] train loss: 0.41814, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:48:54,145 Epoch[8/75] train loss: 0.41633, val loss: nan, lr: 0.0010000, time: 13.12\n",
      "2022-08-19 11:49:07,345 Epoch[9/75] train loss: 0.41456, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:49:20,499 Epoch[10/75] train loss: 0.41382, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:49:33,801 Epoch[11/75] train loss: 0.41245, val loss: nan, lr: 0.0010000, time: 13.30\n",
      "2022-08-19 11:49:46,907 Epoch[12/75] train loss: 0.41156, val loss: nan, lr: 0.0010000, time: 13.10\n",
      "2022-08-19 11:50:00,050 Epoch[13/75] train loss: 0.41046, val loss: nan, lr: 0.0010000, time: 13.14\n",
      "2022-08-19 11:50:13,216 Epoch[14/75] train loss: 0.40867, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:50:26,382 Epoch[15/75] train loss: 0.40775, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:50:39,540 Epoch[16/75] train loss: 0.40612, val loss: nan, lr: 0.0010000, time: 13.16\n",
      "2022-08-19 11:50:52,798 Epoch[17/75] train loss: 0.40544, val loss: nan, lr: 0.0010000, time: 13.26\n",
      "2022-08-19 11:51:06,002 Epoch[18/75] train loss: 0.40331, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:51:19,333 Epoch[19/75] train loss: 0.40267, val loss: nan, lr: 0.0010000, time: 13.33\n",
      "2022-08-19 11:51:32,529 Epoch[20/75] train loss: 0.40106, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:51:45,727 Epoch[21/75] train loss: 0.40056, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:51:59,011 Epoch[22/75] train loss: 0.39919, val loss: nan, lr: 0.0010000, time: 13.28\n",
      "2022-08-19 11:52:12,201 Epoch[23/75] train loss: 0.39835, val loss: nan, lr: 0.0010000, time: 13.19\n",
      "2022-08-19 11:52:25,358 Epoch[24/75] train loss: 0.39800, val loss: nan, lr: 0.0010000, time: 13.15\n",
      "2022-08-19 11:52:38,557 Epoch[25/75] train loss: 0.39648, val loss: nan, lr: 0.0010000, time: 13.20\n",
      "2022-08-19 11:52:51,774 Epoch[26/75] train loss: 0.39552, val loss: nan, lr: 0.0010000, time: 13.22\n",
      "2022-08-19 11:53:04,937 Epoch[27/75] train loss: 0.39529, val loss: nan, lr: 0.0010000, time: 13.16\n"
     ]
    }
   ],
   "source": [
    "max_acc = [[0, 0, 0, 0], None]\n",
    "max_pre = [[0, 0, 0, 0], None]\n",
    "max_rcl = [[0, 0, 0, 0], None]\n",
    "max_f1 = [[0, 0, 0, 0], None]\n",
    "max_models = [None for _ in range(4)]\n",
    "\n",
    "for n_rnns in params['n_rnns']:\n",
    "    for dim in params['rnn_hidden_dim']:\n",
    "        for weight in params['pos_weight']:\n",
    "            param = dict(n_rnns=n_rnns, rnn_hidden_dim=dim, weight=weight)\n",
    "            print(param)\n",
    "            \n",
    "            # update config\n",
    "            config = {}\n",
    "            for key, val in mdl_cfg.items():\n",
    "                config[key] = val\n",
    "            for key, val in param.items():\n",
    "                config[key] = val\n",
    "            pos_weight = param[\"weight\"]\n",
    "                \n",
    "            # init model, loss, optim\n",
    "            model = init_model(config, device)\n",
    "            criterion = init_loss([1, pos_weight], device)\n",
    "            optimizer, scheduler = init_optim(\n",
    "                model, train_cfg[\"optim\"][\"lr\"], train_cfg[\"optim\"][\"lr_rate\"]\n",
    "            )\n",
    "            \n",
    "            # training\n",
    "            model, epoch, history = train(\n",
    "                model, train_loader, val_loader,\n",
    "                criterion, optimizer, scheduler,\n",
    "                epoch_len, logger, device\n",
    "            )\n",
    "            \n",
    "            # test\n",
    "            score = test(model, test_loader, logger, device)\n",
    "            acc, pre, rcl, f1 = score\n",
    "            \n",
    "            # update max scores\n",
    "            if acc > max_acc[0][0]:\n",
    "                max_acc[0] = score\n",
    "                max_acc[1] = param\n",
    "                max_models[0] = model\n",
    "            if pre > max_pre[0][1]:\n",
    "                max_pre[0] = score\n",
    "                max_pre[1] = param\n",
    "                max_models[1] = model\n",
    "            if rcl > max_rcl[0][2]:\n",
    "                max_rcl[0] = score\n",
    "                max_rcl[1] = param\n",
    "                max_models[2] = model\n",
    "            if f1 > max_f1[0][3]:\n",
    "                max_f1[0] = score\n",
    "                max_f1[1] = param\n",
    "                max_models[3] = model\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd10c2-70ac-46bb-a799-ea597a2204ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"epoch={epoch}\")\n",
    "print('max accuracy: ', max_acc[1])\n",
    "acc, pre, rcl, f1 = max_acc[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max precision: ', max_pre[1])\n",
    "acc, pre, rcl, f1 = max_pre[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max recall: ', max_rcl[1])\n",
    "acc, pre, rcl, f1 = max_rcl[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max f1: ', max_f1[1])\n",
    "acc, pre, rcl, f1 = max_f1[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "784c9760-81f6-4649-8df0-1d465e53a98f",
   "metadata": {},
   "source": [
    "epoch=75\n",
    "max accuracy:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.533 recall: 0.419 f1_score: 0.469\n",
    "max precision:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.533 recall: 0.419 f1_score: 0.469\n",
    "max recall:  {'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 32}\n",
    "accuracy: 0.985 precision: 0.194 recall: 0.664 f1_score: 0.300\n",
    "max f1:  {'n_rnns': 2, 'rnn_hidden_dim': 256, 'weight': 8}\n",
    "accuracy: 0.995 precision: 0.493 recall: 0.525 f1_score: 0.509"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0835b-4abf-46d4-ba43-1d4c26646dbb",
   "metadata": {},
   "source": [
    "## モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54bf6e-f404-4857-b6cb-5b82b32d6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max recall\n",
    "model = max_models[2]\n",
    "param = max_rcl[1]\n",
    "config = {}\n",
    "for key, val in mdl_cfg.items():\n",
    "    config[key] = val\n",
    "for key, val in param.items():\n",
    "    config[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9824f0c-aaf5-4d21-9350-2b5137621cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/passing/pass_model_lstm_recall_ep{epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0d883-965c-43a5-9c60-bac39e468dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"pretrained_path\"] = model_path\n",
    "with open(f'config/passing/pass_model_lstm_recall_ep{epoch}.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e18e5-12d3-41cb-a631-48554ecc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max f1\n",
    "model = max_models[3]\n",
    "param = max_f1[1]\n",
    "config = {}\n",
    "for key, val in mdl_cfg.items():\n",
    "    config[key] = val\n",
    "for key, val in param.items():\n",
    "    config[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc4a91-ce20-4aa0-a790-effed2c75aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/passing/pass_model_lstm_f1_ep{epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb143daa-abbe-419a-9fb9-8d58fc1ad234",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"pretrained_path\"] = model_path\n",
    "with open(f'config/passing/pass_model_lstm_f1_ep{epoch}.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a60fd-b6fe-4f37-9dea-75091bdeaf20",
   "metadata": {},
   "source": [
    "# 検証\n",
    "## モデルロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3656ce-2abd-4508-9594-2a72718a379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "epoch = 75\n",
    "rcl_f1 = \"f1\"\n",
    "\n",
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "    del model\n",
    "    gc.collect()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "mdl_cfg_path = f'config/passing/pass_model_lstm_{rcl_f1}_ep{epoch}.yaml'\n",
    "with open(mdl_cfg_path, \"r\") as f:\n",
    "    mdl_cfg = yaml.safe_load(f)\n",
    "model = init_model(mdl_cfg, device)\n",
    "\n",
    "param = torch.load(mdl_cfg[\"pretrained_path\"])\n",
    "model.load_state_dict(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caade6b7-93f0-4a5a-ac67-4901ddddaafe",
   "metadata": {},
   "source": [
    "## データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517fea7-35d8-4ed8-a364-cd8b41d3bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict, y_dict = make_all_data(inds, train_cfg[\"dataset\"][\"setting\"], grp_cfg[\"passing\"][\"default\"], logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082c4c2-657e-4d5c-a9df-7a629c82cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(train_cfg[\"dataset\"][\"random_seed\"])\n",
    "\n",
    "seq_len = grp_cfg[\"passing\"][\"default\"][\"seq_len\"]\n",
    "size = mdl_cfg[\"size\"]\n",
    "\n",
    "keys_1 = [key for key in x_dict if 1 in y_dict[key]]\n",
    "keys_0 = [key for key in x_dict if 1 not in y_dict[key]]\n",
    "random_keys_1 = np.random.choice(keys_1, size=len(keys_1), replace=False)\n",
    "random_keys_0 = np.random.choice(keys_0, size=len(keys_0), replace=False)\n",
    "\n",
    "train_ratio = train_cfg[\"dataset\"][\"train_ratio\"]\n",
    "val_ratio = train_cfg[\"dataset\"][\"val_ratio\"]\n",
    "train_len_1 = int(len(keys_1) * train_ratio)\n",
    "train_len_0 = int(len(keys_0) * train_ratio)\n",
    "val_len_1 = int(len(keys_1) * val_ratio)\n",
    "val_len_0 = int(len(keys_0) * val_ratio)\n",
    "\n",
    "train_keys_1 = random_keys_1[:train_len_1].tolist()\n",
    "val_keys_1 = random_keys_1[train_len_1 : train_len_1 + val_len_1].tolist()\n",
    "test_keys_1 = random_keys_1[train_len_1 + val_len_1 :].tolist()\n",
    "train_keys_0 = random_keys_0[:train_len_0].tolist()\n",
    "test_keys_0 = random_keys_0[train_len_0:].tolist()\n",
    "val_keys_0 = random_keys_1[train_len_0 : train_len_0 + val_len_0].tolist()\n",
    "\n",
    "train_keys = sorted(train_keys_1 + train_keys_0)\n",
    "val_keys = sorted(val_keys_1 + val_keys_0)\n",
    "test_keys = sorted(test_keys_1 + test_keys_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc30e4-b08b-4287-8b07-f8effaaebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(x_lst, y_lst, seq_len=30, size=4):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(x_lst) - seq_len + 1):\n",
    "        x = x_lst[i:i + seq_len]\n",
    "        x_seq.append(x)\n",
    "        y_seq.append(y_lst[i + seq_len - 1])\n",
    "    \n",
    "    return x_seq, y_seq\n",
    "\n",
    "\n",
    "columns = [\"distance\", \"body_direction\", \"arm_ave\", \"wrist_distance\"]\n",
    "def plot(x_lst, y_lst, pred, seq_len=30, path=None):\n",
    "    x_lst = [[0 for _ in range(x_lst.shape[1])]] + [[np.nan for _ in range(x_lst.shape[1])] for i in range(seq_len - 1)] + x_lst.tolist()\n",
    "    y_lst = [0] + [np.nan for i in range(seq_len - 1)] + y_lst\n",
    "    pred = [0] + [np.nan for i in range(seq_len - 1)] + pred.tolist()\n",
    "    \n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    ax = fig.add_axes((0.04, 0.17, 0.80, 0.81))\n",
    "    \n",
    "    ax.plot(pred, label='pred')\n",
    "    ax.plot(y_lst, linestyle=':', label='ground truth')\n",
    "    for i, feature in enumerate(np.array(x_lst).T):\n",
    "        ax.plot(feature, alpha=0.4, label=columns[i])\n",
    "\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    ax.set_xlabel('frame')\n",
    "    ax.legend(\n",
    "        bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0,\n",
    "        fontsize=20, handlelength=0.8, handletextpad=0.2\n",
    "    )\n",
    "    \n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    if path is not None:\n",
    "        fig.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae855e-89c6-4545-8cc2-6850204c1cf9",
   "metadata": {},
   "source": [
    "## トレインデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a72bc4-e0f7-42e4-946d-0727cdf210a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keys = [\n",
    "    '02_06_1_3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f9e0e-6b00-4dac-9641-1088126b63c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_train = []\n",
    "pred_all_train = []\n",
    "y_eve_train = []\n",
    "pred_eve_train = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in train_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "        \n",
    "        x, _ = create_sequence(x_lst, y_lst, seq_len, size)\n",
    "        x = torch.Tensor(np.array(x)).float().to(device)\n",
    "        \n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[seq_len - 1:]\n",
    "        y_lst = y_lst[seq_len - 1:]\n",
    "            \n",
    "        y_all_train += y_lst\n",
    "        pred_all_train += pred.tolist()\n",
    "        y_eve_train.append(1 in y_lst)\n",
    "        pred_eve_train.append(1 in pred.tolist())\n",
    "        \n",
    "        if 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        path = None\n",
    "        if key in save_keys:\n",
    "            path = os.path.join(\"data\", \"passing\", \"image\", f\"rnn_test_{key}.pdf\")\n",
    "        plot(x_lst, y_lst, pred, seq_len, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24e519-53ca-405c-a4ed-5bc31fc7d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_train, pred_all_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_train, pred_all_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_train, pred_all_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_train, pred_all_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388e620-e79f-4a62-9530-ba821dcb9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per event\n",
    "print('accuracy: {:.3f}'.format(accuracy_score(y_eve_train, pred_eve_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_eve_train, pred_eve_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_eve_train, pred_eve_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_eve_train, pred_eve_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055dc76-a0e1-42b0-85a8-358c036dba57",
   "metadata": {},
   "source": [
    "## テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445c2a5-4a0f-49c4-9ef1-97983f804401",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keys = [\n",
    "    '08_03_2_5',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4075ac9-b3b6-460b-9cc2-dac368fed21f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_test = []\n",
    "pred_all_test = []\n",
    "y_eve_test = []\n",
    "pred_eve_test = []\n",
    "tn, fn = 0, 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in test_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "\n",
    "        x, _ = create_sequence(x_lst, y_lst, seq_len, size)\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "\n",
    "        if len(x) == 0:\n",
    "            tn += 1\n",
    "            continue\n",
    "            \n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[seq_len - 1:]\n",
    "        y_lst = y_lst[seq_len - 1:]\n",
    "        \n",
    "        y_all_test += y_lst\n",
    "        pred_all_test += pred.tolist()\n",
    "        y_eve_test.append(1 in y_lst)\n",
    "        pred_eve_test.append(1 in pred.tolist())\n",
    "        if 1 not in y_lst:\n",
    "            if 1 not in pred:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        \n",
    "        if 1 not in pred and 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        path = None\n",
    "        if key in save_keys:\n",
    "            path = os.path.join(\"data\", \"passing\", \"image\", f\"rnn_test_{key}.pdf\")\n",
    "        plot(x_lst, y_lst, pred, seq_len, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125394d0-a266-4220-9cab-a86b943a9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_test, pred_all_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_test, pred_all_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_test, pred_all_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_test, pred_all_test)))\n",
    "\n",
    "cm = confusion_matrix(y_all_test, pred_all_test)\n",
    "sns.heatmap(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa66db1-dae9-433e-a64b-803a7d9f02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per event\n",
    "print('accuracy: {:.3f}'.format(accuracy_score(y_eve_test, pred_eve_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_eve_test, pred_eve_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_eve_test, pred_eve_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_eve_test, pred_eve_test)))\n",
    "\n",
    "print('true negative:', tn)\n",
    "print('false negative:', fn)\n",
    "\n",
    "cm = confusion_matrix(y_eve_test, pred_eve_test)\n",
    "sns.heatmap(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30255301-5894-4c67-961f-6123eff18fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
