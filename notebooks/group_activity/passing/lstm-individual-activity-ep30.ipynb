{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621a2a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid6/home/yokoyama/research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyama/research/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# back to project root\n",
    "%cd ~/research\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch import nn, optim\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "from group.passing.dataset import make_data_loaders, make_all_data\n",
    "from group.passing.lstm_model import LSTMModel\n",
    "from utility.activity_loader import load_individuals\n",
    "from utility.logger import logger\n",
    "from tools.train_passing import init_model, init_loss, init_optim, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc298add-7d1e-4c1a-8a98-767bde6e9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams[\"font.size\"] = 24\n",
    "plt.rcParams['xtick.direction'] = 'in'  # x axis in\n",
    "plt.rcParams['ytick.direction'] = 'in'  # y axis in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28083f0-6a29-4348-b2f0-6099f5289d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f8937b-15e0-489c-adfe-fc605429bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"config/passing/pass_train.yaml\"\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    train_cfg = yaml.safe_load(f)\n",
    "with open(train_cfg[\"config_path\"][\"individual\"], \"r\") as f:\n",
    "    ind_cfg = yaml.safe_load(f)\n",
    "with open(train_cfg[\"config_path\"][\"group\"], \"r\") as f:\n",
    "    grp_cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe7d65b-260f-4091-b271-5cf80ff3c575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:05<00:00, 10.98s/it]\n"
     ]
    }
   ],
   "source": [
    "data_dirs_all = {}\n",
    "for room_num, surgery_items in train_cfg[\"dataset\"][\"setting\"].items():\n",
    "    for surgery_num in surgery_items.keys():\n",
    "        dirs = sorted(glob(os.path.join(\"data\", room_num, surgery_num, \"passing\", \"*\")))\n",
    "        data_dirs_all[f\"{room_num}_{surgery_num}\"] = dirs\n",
    "\n",
    "inds = {}\n",
    "for key_prefix, dirs in tqdm(data_dirs_all.items()):\n",
    "    for model_path in dirs:\n",
    "        num = model_path.split(\"/\")[-1]\n",
    "        json_path = os.path.join(model_path, \".json\", \"individual.json\")\n",
    "        tmp_inds = load_individuals(json_path, ind_cfg)\n",
    "        for pid, ind in tmp_inds.items():\n",
    "            inds[f\"{key_prefix}_{num}_{pid}\"] = ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b174-dd28-4aa8-8d26-9bc4427a0163",
   "metadata": {},
   "source": [
    "# グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b443de49-2306-476a-b2bb-295506a68dc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 20:29:05,285 => createing time series 02_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:04<00:00,  3.98it/s]\n",
      "2022-08-13 20:29:09,563 => createing time series 07_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:29<00:00,  1.65it/s]\n",
      "2022-08-13 20:29:38,661 => createing time series 08_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:05<00:00,  6.59it/s]\n",
      "2022-08-13 20:29:44,433 => createing time series 08_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:31<00:00,  1.44it/s]\n",
      "2022-08-13 20:30:15,745 => createing time series 09_001\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.06it/s]\n",
      "2022-08-13 20:30:18,688 => createing time series 09_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.20it/s]\n",
      "2022-08-13 20:30:32,038 => extracting feature 02_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:16<00:00,  1.03it/s]\n",
      "2022-08-13 20:30:48,566 => extracting feature 07_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:55<00:00,  1.16s/it]\n",
      "2022-08-13 20:31:44,483 => extracting feature 08_001\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:12<00:00,  3.01it/s]\n",
      "2022-08-13 20:31:57,125 => extracting feature 08_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [01:03<00:00,  1.41s/it]\n",
      "2022-08-13 20:33:00,616 => extracting feature 09_001\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:09<00:00,  1.09s/it]\n",
      "2022-08-13 20:33:10,459 => extracting feature 09_002\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:41<00:00,  2.58s/it]\n",
      "2022-08-13 20:33:51,948 => create train loader\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:03<00:00, 2791.62it/s]\n",
      "2022-08-13 20:33:55,566 => skip creating val loader\n",
      "2022-08-13 20:33:55,566 => create test loader\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2520/2520 [00:00<00:00, 8967.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# create data loader\n",
    "dataset_cfg = train_cfg[\"dataset\"]\n",
    "passing_defs = grp_cfg[\"passing\"][\"default\"]\n",
    "train_loader, val_loader, test_loader = make_data_loaders(\n",
    "    inds, dataset_cfg, passing_defs, logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60011bb5-8a2a-497d-8f5e-a1fe6b56b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "mdl_cfg = {\n",
    "    \"dropouts\": [0.1, 0],\n",
    "    \"hidden_dims\": [128, 64],\n",
    "    \"n_classes\": 2,\n",
    "    \"n_linears\": 2,\n",
    "    \"rnn_dropout\": 0.1,\n",
    "    \"size\": 4,\n",
    "}\n",
    "\n",
    "# grid search parameters\n",
    "params = {\n",
    "    'n_rnns': [1, 2, 3],\n",
    "    'rnn_hidden_dim': [128, 256],\n",
    "    'pos_weight': [8, 16, 32]\n",
    "}\n",
    "\n",
    "# epoch\n",
    "# epoch_len = train_cfg[\"optim\"][\"epoch\"]\n",
    "epoch_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9a76f-fd7b-4bde-8e77-33dba46fd26a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 20:33:58,804 => start training\n",
      "2022-08-13 20:34:09,732 Epoch[1/30] train loss: 0.45273, val loss: nan, lr: 0.0010000, time: 10.93\n",
      "2022-08-13 20:34:21,468 Epoch[2/30] train loss: 0.39710, val loss: nan, lr: 0.0010000, time: 11.73\n",
      "2022-08-13 20:34:35,222 Epoch[3/30] train loss: 0.39456, val loss: nan, lr: 0.0010000, time: 13.75\n",
      "2022-08-13 20:34:51,687 Epoch[4/30] train loss: 0.39283, val loss: nan, lr: 0.0010000, time: 16.46\n",
      "2022-08-13 20:35:07,775 Epoch[5/30] train loss: 0.39210, val loss: nan, lr: 0.0010000, time: 16.09\n",
      "2022-08-13 20:35:23,470 Epoch[6/30] train loss: 0.39115, val loss: nan, lr: 0.0010000, time: 15.69\n",
      "2022-08-13 20:35:40,173 Epoch[7/30] train loss: 0.39045, val loss: nan, lr: 0.0010000, time: 16.70\n",
      "2022-08-13 20:35:56,619 Epoch[8/30] train loss: 0.38957, val loss: nan, lr: 0.0010000, time: 16.44\n",
      "2022-08-13 20:36:12,460 Epoch[9/30] train loss: 0.38884, val loss: nan, lr: 0.0010000, time: 15.84\n",
      "2022-08-13 20:36:29,178 Epoch[10/30] train loss: 0.38766, val loss: nan, lr: 0.0010000, time: 16.72\n",
      "2022-08-13 20:36:45,246 Epoch[11/30] train loss: 0.38700, val loss: nan, lr: 0.0010000, time: 16.07\n",
      "2022-08-13 20:37:00,169 Epoch[12/30] train loss: 0.38620, val loss: nan, lr: 0.0010000, time: 14.92\n",
      "2022-08-13 20:37:15,762 Epoch[13/30] train loss: 0.38598, val loss: nan, lr: 0.0010000, time: 15.59\n",
      "2022-08-13 20:37:31,437 Epoch[14/30] train loss: 0.38505, val loss: nan, lr: 0.0010000, time: 15.67\n",
      "2022-08-13 20:37:46,745 Epoch[15/30] train loss: 0.38399, val loss: nan, lr: 0.0010000, time: 15.30\n",
      "2022-08-13 20:38:02,466 Epoch[16/30] train loss: 0.38335, val loss: nan, lr: 0.0010000, time: 15.72\n",
      "2022-08-13 20:38:18,784 Epoch[17/30] train loss: 0.38252, val loss: nan, lr: 0.0010000, time: 16.32\n",
      "2022-08-13 20:38:34,608 Epoch[18/30] train loss: 0.38194, val loss: nan, lr: 0.0010000, time: 15.82\n",
      "2022-08-13 20:38:50,238 Epoch[19/30] train loss: 0.38123, val loss: nan, lr: 0.0010000, time: 15.63\n",
      "2022-08-13 20:39:05,851 Epoch[20/30] train loss: 0.38096, val loss: nan, lr: 0.0010000, time: 15.61\n",
      "2022-08-13 20:39:21,949 Epoch[21/30] train loss: 0.37997, val loss: nan, lr: 0.0010000, time: 16.10\n",
      "2022-08-13 20:39:37,773 Epoch[22/30] train loss: 0.37914, val loss: nan, lr: 0.0010000, time: 15.82\n",
      "2022-08-13 20:39:53,670 Epoch[23/30] train loss: 0.37882, val loss: nan, lr: 0.0010000, time: 15.89\n",
      "2022-08-13 20:40:09,243 Epoch[24/30] train loss: 0.37752, val loss: nan, lr: 0.0010000, time: 15.57\n",
      "2022-08-13 20:40:25,328 Epoch[25/30] train loss: 0.37727, val loss: nan, lr: 0.0010000, time: 16.08\n",
      "2022-08-13 20:40:41,859 Epoch[26/30] train loss: 0.37643, val loss: nan, lr: 0.0010000, time: 16.53\n",
      "2022-08-13 20:40:59,287 Epoch[27/30] train loss: 0.37588, val loss: nan, lr: 0.0010000, time: 17.43\n",
      "2022-08-13 20:41:15,298 Epoch[28/30] train loss: 0.37519, val loss: nan, lr: 0.0010000, time: 16.01\n",
      "2022-08-13 20:41:31,561 Epoch[29/30] train loss: 0.37471, val loss: nan, lr: 0.0010000, time: 16.26\n",
      "2022-08-13 20:41:47,822 Epoch[30/30] train loss: 0.37474, val loss: nan, lr: 0.0010000, time: 16.26\n",
      "2022-08-13 20:41:47,823 => end training\n",
      "2022-08-13 20:41:47,824 => calculating train scores\n",
      "2022-08-13 20:42:08,404 => train score\n",
      "accuracy: 0.9945862209792073\n",
      "presision: 0.4817610062893082\n",
      "recall: 0.8148936170212766\n",
      "f1: 0.6055335968379447\n",
      "2022-08-13 20:42:08,406 => calculating test scores\n",
      "2022-08-13 20:42:13,702 => test score\n",
      "accuracy: 0.9919777393435404\n",
      "presision: 0.17622762735199632\n",
      "recall: 0.34814143245693563\n",
      "f1: 0.23400365630712983\n",
      "2022-08-13 20:42:13,716 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 20:42:28,765 Epoch[1/30] train loss: 0.49457, val loss: nan, lr: 0.0010000, time: 15.05\n",
      "2022-08-13 20:42:44,362 Epoch[2/30] train loss: 0.42916, val loss: nan, lr: 0.0010000, time: 15.59\n",
      "2022-08-13 20:43:01,019 Epoch[3/30] train loss: 0.42532, val loss: nan, lr: 0.0010000, time: 16.66\n",
      "2022-08-13 20:43:17,363 Epoch[4/30] train loss: 0.42372, val loss: nan, lr: 0.0010000, time: 16.34\n",
      "2022-08-13 20:43:33,285 Epoch[5/30] train loss: 0.42235, val loss: nan, lr: 0.0010000, time: 15.92\n",
      "2022-08-13 20:43:49,514 Epoch[6/30] train loss: 0.42102, val loss: nan, lr: 0.0010000, time: 16.23\n",
      "2022-08-13 20:44:05,357 Epoch[7/30] train loss: 0.41871, val loss: nan, lr: 0.0010000, time: 15.84\n",
      "2022-08-13 20:44:21,571 Epoch[8/30] train loss: 0.41790, val loss: nan, lr: 0.0010000, time: 16.21\n",
      "2022-08-13 20:44:38,051 Epoch[9/30] train loss: 0.41673, val loss: nan, lr: 0.0010000, time: 16.48\n",
      "2022-08-13 20:44:54,632 Epoch[10/30] train loss: 0.41457, val loss: nan, lr: 0.0010000, time: 16.58\n",
      "2022-08-13 20:45:10,513 Epoch[11/30] train loss: 0.41394, val loss: nan, lr: 0.0010000, time: 15.88\n",
      "2022-08-13 20:45:25,990 Epoch[12/30] train loss: 0.41223, val loss: nan, lr: 0.0010000, time: 15.48\n",
      "2022-08-13 20:45:41,350 Epoch[13/30] train loss: 0.41147, val loss: nan, lr: 0.0010000, time: 15.36\n",
      "2022-08-13 20:45:57,398 Epoch[14/30] train loss: 0.41013, val loss: nan, lr: 0.0010000, time: 16.05\n",
      "2022-08-13 20:46:12,491 Epoch[15/30] train loss: 0.40849, val loss: nan, lr: 0.0010000, time: 15.09\n",
      "2022-08-13 20:46:28,631 Epoch[16/30] train loss: 0.40737, val loss: nan, lr: 0.0010000, time: 16.14\n",
      "2022-08-13 20:46:44,565 Epoch[17/30] train loss: 0.40746, val loss: nan, lr: 0.0010000, time: 15.93\n",
      "2022-08-13 20:47:00,282 Epoch[18/30] train loss: 0.40573, val loss: nan, lr: 0.0010000, time: 15.72\n",
      "2022-08-13 20:47:16,209 Epoch[19/30] train loss: 0.40396, val loss: nan, lr: 0.0010000, time: 15.92\n",
      "2022-08-13 20:47:31,897 Epoch[20/30] train loss: 0.40315, val loss: nan, lr: 0.0010000, time: 15.69\n",
      "2022-08-13 20:47:47,506 Epoch[21/30] train loss: 0.40175, val loss: nan, lr: 0.0010000, time: 15.61\n",
      "2022-08-13 20:48:04,450 Epoch[22/30] train loss: 0.40061, val loss: nan, lr: 0.0010000, time: 16.94\n",
      "2022-08-13 20:48:20,269 Epoch[23/30] train loss: 0.39919, val loss: nan, lr: 0.0010000, time: 15.82\n",
      "2022-08-13 20:48:36,246 Epoch[24/30] train loss: 0.39844, val loss: nan, lr: 0.0010000, time: 15.98\n",
      "2022-08-13 20:48:51,648 Epoch[25/30] train loss: 0.39697, val loss: nan, lr: 0.0010000, time: 15.40\n",
      "2022-08-13 20:49:06,099 Epoch[26/30] train loss: 0.39689, val loss: nan, lr: 0.0010000, time: 14.45\n",
      "2022-08-13 20:49:22,187 Epoch[27/30] train loss: 0.39535, val loss: nan, lr: 0.0010000, time: 16.09\n",
      "2022-08-13 20:49:38,011 Epoch[28/30] train loss: 0.39471, val loss: nan, lr: 0.0010000, time: 15.82\n",
      "2022-08-13 20:49:53,486 Epoch[29/30] train loss: 0.39502, val loss: nan, lr: 0.0010000, time: 15.47\n",
      "2022-08-13 20:50:08,624 Epoch[30/30] train loss: 0.39376, val loss: nan, lr: 0.0010000, time: 15.14\n",
      "2022-08-13 20:50:08,625 => end training\n",
      "2022-08-13 20:50:08,626 => calculating train scores\n",
      "2022-08-13 20:50:29,707 => train score\n",
      "accuracy: 0.9924496923848294\n",
      "presision: 0.3850570535649393\n",
      "recall: 0.8051671732522796\n",
      "f1: 0.520969565858695\n",
      "2022-08-13 20:50:29,709 => calculating test scores\n",
      "2022-08-13 20:50:35,749 => test score\n",
      "accuracy: 0.9891504828035153\n",
      "presision: 0.1375828337014831\n",
      "recall: 0.3952855847688123\n",
      "f1: 0.20411985018726592\n",
      "2022-08-13 20:50:35,763 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 20:50:52,118 Epoch[1/30] train loss: 0.51521, val loss: nan, lr: 0.0010000, time: 16.35\n",
      "2022-08-13 20:51:07,263 Epoch[2/30] train loss: 0.47905, val loss: nan, lr: 0.0010000, time: 15.14\n",
      "2022-08-13 20:51:23,940 Epoch[3/30] train loss: 0.47616, val loss: nan, lr: 0.0010000, time: 16.68\n",
      "2022-08-13 20:51:40,086 Epoch[4/30] train loss: 0.47297, val loss: nan, lr: 0.0010000, time: 16.14\n",
      "2022-08-13 20:51:56,468 Epoch[5/30] train loss: 0.47165, val loss: nan, lr: 0.0010000, time: 16.38\n",
      "2022-08-13 20:52:12,321 Epoch[6/30] train loss: 0.46954, val loss: nan, lr: 0.0010000, time: 15.85\n",
      "2022-08-13 20:52:27,994 Epoch[7/30] train loss: 0.46673, val loss: nan, lr: 0.0010000, time: 15.67\n",
      "2022-08-13 20:52:44,942 Epoch[8/30] train loss: 0.46510, val loss: nan, lr: 0.0010000, time: 16.95\n",
      "2022-08-13 20:53:00,683 Epoch[9/30] train loss: 0.46372, val loss: nan, lr: 0.0010000, time: 15.74\n",
      "2022-08-13 20:53:16,598 Epoch[10/30] train loss: 0.46173, val loss: nan, lr: 0.0010000, time: 15.91\n",
      "2022-08-13 20:53:32,293 Epoch[11/30] train loss: 0.45908, val loss: nan, lr: 0.0010000, time: 15.69\n",
      "2022-08-13 20:53:48,788 Epoch[12/30] train loss: 0.45692, val loss: nan, lr: 0.0010000, time: 16.49\n",
      "2022-08-13 20:54:04,224 Epoch[13/30] train loss: 0.45531, val loss: nan, lr: 0.0010000, time: 15.43\n",
      "2022-08-13 20:54:21,033 Epoch[14/30] train loss: 0.45492, val loss: nan, lr: 0.0010000, time: 16.81\n",
      "2022-08-13 20:54:36,854 Epoch[15/30] train loss: 0.45151, val loss: nan, lr: 0.0010000, time: 15.82\n",
      "2022-08-13 20:54:52,870 Epoch[16/30] train loss: 0.44992, val loss: nan, lr: 0.0010000, time: 16.01\n",
      "2022-08-13 20:55:08,533 Epoch[17/30] train loss: 0.44913, val loss: nan, lr: 0.0010000, time: 15.66\n",
      "2022-08-13 20:55:22,748 Epoch[18/30] train loss: 0.44670, val loss: nan, lr: 0.0010000, time: 14.21\n",
      "2022-08-13 20:55:39,482 Epoch[19/30] train loss: 0.44549, val loss: nan, lr: 0.0010000, time: 16.73\n",
      "2022-08-13 20:55:55,787 Epoch[20/30] train loss: 0.44492, val loss: nan, lr: 0.0010000, time: 16.30\n",
      "2022-08-13 20:56:11,362 Epoch[21/30] train loss: 0.44367, val loss: nan, lr: 0.0010000, time: 15.57\n",
      "2022-08-13 20:56:27,693 Epoch[22/30] train loss: 0.44128, val loss: nan, lr: 0.0010000, time: 16.33\n",
      "2022-08-13 20:56:43,961 Epoch[23/30] train loss: 0.44061, val loss: nan, lr: 0.0010000, time: 16.27\n",
      "2022-08-13 20:57:00,170 Epoch[24/30] train loss: 0.44036, val loss: nan, lr: 0.0010000, time: 16.21\n",
      "2022-08-13 20:57:16,030 Epoch[25/30] train loss: 0.43730, val loss: nan, lr: 0.0010000, time: 15.86\n",
      "2022-08-13 20:57:31,556 Epoch[26/30] train loss: 0.43607, val loss: nan, lr: 0.0010000, time: 15.52\n",
      "2022-08-13 20:57:47,764 Epoch[27/30] train loss: 0.43520, val loss: nan, lr: 0.0010000, time: 16.21\n",
      "2022-08-13 20:58:04,022 Epoch[28/30] train loss: 0.43448, val loss: nan, lr: 0.0010000, time: 16.26\n",
      "2022-08-13 20:58:20,971 Epoch[29/30] train loss: 0.43277, val loss: nan, lr: 0.0010000, time: 16.95\n",
      "2022-08-13 20:58:37,735 Epoch[30/30] train loss: 0.43173, val loss: nan, lr: 0.0010000, time: 16.76\n",
      "2022-08-13 20:58:37,737 => end training\n",
      "2022-08-13 20:58:37,738 => calculating train scores\n",
      "2022-08-13 20:58:58,615 => train score\n",
      "accuracy: 0.9858866671161358\n",
      "presision: 0.25263695134399455\n",
      "recall: 0.9027355623100304\n",
      "f1: 0.39478931277415924\n",
      "2022-08-13 20:58:58,616 => calculating test scores\n",
      "2022-08-13 20:59:04,781 => test score\n",
      "accuracy: 0.9822259380045824\n",
      "presision: 0.09850799928096352\n",
      "recall: 0.4968268359020852\n",
      "f1: 0.1644164416441644\n",
      "2022-08-13 20:59:04,801 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 20:59:21,307 Epoch[1/30] train loss: 0.48750, val loss: nan, lr: 0.0010000, time: 16.50\n",
      "2022-08-13 20:59:37,555 Epoch[2/30] train loss: 0.40020, val loss: nan, lr: 0.0010000, time: 16.25\n",
      "2022-08-13 20:59:54,491 Epoch[3/30] train loss: 0.39568, val loss: nan, lr: 0.0010000, time: 16.93\n",
      "2022-08-13 21:00:10,535 Epoch[4/30] train loss: 0.39414, val loss: nan, lr: 0.0010000, time: 16.04\n",
      "2022-08-13 21:00:27,084 Epoch[5/30] train loss: 0.39274, val loss: nan, lr: 0.0010000, time: 16.55\n",
      "2022-08-13 21:00:43,526 Epoch[6/30] train loss: 0.39218, val loss: nan, lr: 0.0010000, time: 16.44\n",
      "2022-08-13 21:01:00,541 Epoch[7/30] train loss: 0.39102, val loss: nan, lr: 0.0010000, time: 17.01\n",
      "2022-08-13 21:01:17,634 Epoch[8/30] train loss: 0.39002, val loss: nan, lr: 0.0010000, time: 17.09\n",
      "2022-08-13 21:01:33,480 Epoch[9/30] train loss: 0.38922, val loss: nan, lr: 0.0010000, time: 15.84\n",
      "2022-08-13 21:01:50,414 Epoch[10/30] train loss: 0.38800, val loss: nan, lr: 0.0010000, time: 16.93\n",
      "2022-08-13 21:02:06,619 Epoch[11/30] train loss: 0.38736, val loss: nan, lr: 0.0010000, time: 16.20\n",
      "2022-08-13 21:02:23,230 Epoch[12/30] train loss: 0.38657, val loss: nan, lr: 0.0010000, time: 16.61\n",
      "2022-08-13 21:02:40,874 Epoch[13/30] train loss: 0.38557, val loss: nan, lr: 0.0010000, time: 17.64\n",
      "2022-08-13 21:02:57,700 Epoch[14/30] train loss: 0.38505, val loss: nan, lr: 0.0010000, time: 16.82\n",
      "2022-08-13 21:03:14,081 Epoch[15/30] train loss: 0.38426, val loss: nan, lr: 0.0010000, time: 16.38\n",
      "2022-08-13 21:03:30,092 Epoch[16/30] train loss: 0.38357, val loss: nan, lr: 0.0010000, time: 16.01\n",
      "2022-08-13 21:03:45,592 Epoch[17/30] train loss: 0.38259, val loss: nan, lr: 0.0010000, time: 15.50\n",
      "2022-08-13 21:04:02,158 Epoch[18/30] train loss: 0.38137, val loss: nan, lr: 0.0010000, time: 16.56\n",
      "2022-08-13 21:04:19,448 Epoch[19/30] train loss: 0.38088, val loss: nan, lr: 0.0010000, time: 17.29\n",
      "2022-08-13 21:04:35,972 Epoch[20/30] train loss: 0.37960, val loss: nan, lr: 0.0010000, time: 16.52\n",
      "2022-08-13 21:04:52,716 Epoch[21/30] train loss: 0.37874, val loss: nan, lr: 0.0010000, time: 16.74\n",
      "2022-08-13 21:05:09,993 Epoch[22/30] train loss: 0.37806, val loss: nan, lr: 0.0010000, time: 17.28\n",
      "2022-08-13 21:05:27,221 Epoch[23/30] train loss: 0.37726, val loss: nan, lr: 0.0010000, time: 17.23\n",
      "2022-08-13 21:05:44,259 Epoch[24/30] train loss: 0.37667, val loss: nan, lr: 0.0010000, time: 17.04\n",
      "2022-08-13 21:06:00,635 Epoch[25/30] train loss: 0.37586, val loss: nan, lr: 0.0010000, time: 16.37\n",
      "2022-08-13 21:06:17,387 Epoch[26/30] train loss: 0.37520, val loss: nan, lr: 0.0010000, time: 16.75\n",
      "2022-08-13 21:06:33,516 Epoch[27/30] train loss: 0.37441, val loss: nan, lr: 0.0010000, time: 16.13\n",
      "2022-08-13 21:06:50,041 Epoch[28/30] train loss: 0.37333, val loss: nan, lr: 0.0010000, time: 16.52\n",
      "2022-08-13 21:07:05,696 Epoch[29/30] train loss: 0.37299, val loss: nan, lr: 0.0010000, time: 15.65\n",
      "2022-08-13 21:07:20,966 Epoch[30/30] train loss: 0.37173, val loss: nan, lr: 0.0010000, time: 15.27\n",
      "2022-08-13 21:07:20,967 => end training\n",
      "2022-08-13 21:07:20,968 => calculating train scores\n",
      "2022-08-13 21:07:41,126 => train score\n",
      "accuracy: 0.9951015606655554\n",
      "presision: 0.5129954841946814\n",
      "recall: 0.7768996960486322\n",
      "f1: 0.6179510426110607\n",
      "2022-08-13 21:07:41,129 => calculating test scores\n",
      "2022-08-13 21:07:46,545 => test score\n",
      "accuracy: 0.9925553165825297\n",
      "presision: 0.18970736629667004\n",
      "recall: 0.34088848594741616\n",
      "f1: 0.24376012965964342\n",
      "2022-08-13 21:07:46,561 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 21:08:03,320 Epoch[1/30] train loss: 0.47584, val loss: nan, lr: 0.0010000, time: 16.76\n",
      "2022-08-13 21:08:19,679 Epoch[2/30] train loss: 0.42855, val loss: nan, lr: 0.0010000, time: 16.36\n",
      "2022-08-13 21:08:36,141 Epoch[3/30] train loss: 0.42515, val loss: nan, lr: 0.0010000, time: 16.46\n",
      "2022-08-13 21:08:52,810 Epoch[4/30] train loss: 0.42339, val loss: nan, lr: 0.0010000, time: 16.67\n",
      "2022-08-13 21:09:09,392 Epoch[5/30] train loss: 0.42164, val loss: nan, lr: 0.0010000, time: 16.58\n",
      "2022-08-13 21:09:26,423 Epoch[6/30] train loss: 0.42060, val loss: nan, lr: 0.0010000, time: 17.03\n",
      "2022-08-13 21:09:43,042 Epoch[7/30] train loss: 0.41916, val loss: nan, lr: 0.0010000, time: 16.62\n",
      "2022-08-13 21:09:59,308 Epoch[8/30] train loss: 0.41740, val loss: nan, lr: 0.0010000, time: 16.26\n",
      "2022-08-13 21:10:15,457 Epoch[9/30] train loss: 0.41558, val loss: nan, lr: 0.0010000, time: 16.15\n",
      "2022-08-13 21:10:31,955 Epoch[10/30] train loss: 0.41399, val loss: nan, lr: 0.0010000, time: 16.50\n",
      "2022-08-13 21:10:48,600 Epoch[11/30] train loss: 0.41302, val loss: nan, lr: 0.0010000, time: 16.64\n",
      "2022-08-13 21:11:05,032 Epoch[12/30] train loss: 0.41140, val loss: nan, lr: 0.0010000, time: 16.43\n",
      "2022-08-13 21:11:22,000 Epoch[13/30] train loss: 0.41074, val loss: nan, lr: 0.0010000, time: 16.97\n",
      "2022-08-13 21:11:38,294 Epoch[14/30] train loss: 0.40904, val loss: nan, lr: 0.0010000, time: 16.29\n",
      "2022-08-13 21:11:55,157 Epoch[15/30] train loss: 0.40679, val loss: nan, lr: 0.0010000, time: 16.86\n",
      "2022-08-13 21:12:11,336 Epoch[16/30] train loss: 0.40587, val loss: nan, lr: 0.0010000, time: 16.18\n",
      "2022-08-13 21:12:27,394 Epoch[17/30] train loss: 0.40471, val loss: nan, lr: 0.0010000, time: 16.06\n",
      "2022-08-13 21:12:44,437 Epoch[18/30] train loss: 0.40346, val loss: nan, lr: 0.0010000, time: 17.04\n",
      "2022-08-13 21:13:01,383 Epoch[19/30] train loss: 0.40163, val loss: nan, lr: 0.0010000, time: 16.95\n",
      "2022-08-13 21:13:17,723 Epoch[20/30] train loss: 0.40212, val loss: nan, lr: 0.0010000, time: 16.34\n",
      "2022-08-13 21:13:33,705 Epoch[21/30] train loss: 0.39995, val loss: nan, lr: 0.0010000, time: 15.98\n",
      "2022-08-13 21:13:50,658 Epoch[22/30] train loss: 0.39901, val loss: nan, lr: 0.0010000, time: 16.95\n",
      "2022-08-13 21:14:07,362 Epoch[23/30] train loss: 0.39757, val loss: nan, lr: 0.0010000, time: 16.70\n",
      "2022-08-13 21:14:23,101 Epoch[24/30] train loss: 0.39636, val loss: nan, lr: 0.0010000, time: 15.74\n",
      "2022-08-13 21:14:39,428 Epoch[25/30] train loss: 0.39625, val loss: nan, lr: 0.0010000, time: 16.32\n",
      "2022-08-13 21:14:56,637 Epoch[26/30] train loss: 0.39616, val loss: nan, lr: 0.0010000, time: 17.21\n",
      "2022-08-13 21:15:13,332 Epoch[27/30] train loss: 0.39406, val loss: nan, lr: 0.0010000, time: 16.69\n",
      "2022-08-13 21:15:29,990 Epoch[28/30] train loss: 0.39351, val loss: nan, lr: 0.0010000, time: 16.66\n",
      "2022-08-13 21:15:46,645 Epoch[29/30] train loss: 0.39215, val loss: nan, lr: 0.0010000, time: 16.65\n",
      "2022-08-13 21:16:03,873 Epoch[30/30] train loss: 0.39210, val loss: nan, lr: 0.0010000, time: 17.23\n",
      "2022-08-13 21:16:03,875 => end training\n",
      "2022-08-13 21:16:03,876 => calculating train scores\n",
      "2022-08-13 21:16:23,297 => train score\n",
      "accuracy: 0.9916832699039299\n",
      "presision: 0.3731516558719296\n",
      "recall: 0.9281155015197569\n",
      "f1: 0.5322932101455591\n",
      "2022-08-13 21:16:23,300 => calculating test scores\n",
      "2022-08-13 21:16:29,408 => test score\n",
      "accuracy: 0.9874241331554864\n",
      "presision: 0.12853403141361255\n",
      "recall: 0.44514959202175886\n",
      "f1: 0.19947186674791795\n",
      "2022-08-13 21:16:29,420 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 1, 'rnn_hidden_dim': 256, 'weight': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 21:16:46,400 Epoch[1/30] train loss: 0.51960, val loss: nan, lr: 0.0010000, time: 16.98\n",
      "2022-08-13 21:17:02,475 Epoch[2/30] train loss: 0.47905, val loss: nan, lr: 0.0010000, time: 16.07\n",
      "2022-08-13 21:17:18,368 Epoch[3/30] train loss: 0.47639, val loss: nan, lr: 0.0010000, time: 15.89\n",
      "2022-08-13 21:17:33,772 Epoch[4/30] train loss: 0.47333, val loss: nan, lr: 0.0010000, time: 15.40\n",
      "2022-08-13 21:17:50,289 Epoch[5/30] train loss: 0.47275, val loss: nan, lr: 0.0010000, time: 16.51\n",
      "2022-08-13 21:18:07,099 Epoch[6/30] train loss: 0.47001, val loss: nan, lr: 0.0010000, time: 16.81\n",
      "2022-08-13 21:18:24,166 Epoch[7/30] train loss: 0.46670, val loss: nan, lr: 0.0010000, time: 17.07\n",
      "2022-08-13 21:18:41,385 Epoch[8/30] train loss: 0.46499, val loss: nan, lr: 0.0010000, time: 17.22\n",
      "2022-08-13 21:18:58,556 Epoch[9/30] train loss: 0.46188, val loss: nan, lr: 0.0010000, time: 17.17\n",
      "2022-08-13 21:19:15,440 Epoch[10/30] train loss: 0.46117, val loss: nan, lr: 0.0010000, time: 16.88\n",
      "2022-08-13 21:19:32,548 Epoch[11/30] train loss: 0.45939, val loss: nan, lr: 0.0010000, time: 17.11\n",
      "2022-08-13 21:19:49,344 Epoch[12/30] train loss: 0.45778, val loss: nan, lr: 0.0010000, time: 16.79\n",
      "2022-08-13 21:20:06,462 Epoch[13/30] train loss: 0.45529, val loss: nan, lr: 0.0010000, time: 17.12\n",
      "2022-08-13 21:20:23,840 Epoch[14/30] train loss: 0.45290, val loss: nan, lr: 0.0010000, time: 17.38\n",
      "2022-08-13 21:20:41,838 Epoch[15/30] train loss: 0.45178, val loss: nan, lr: 0.0010000, time: 18.00\n",
      "2022-08-13 21:20:58,475 Epoch[16/30] train loss: 0.45086, val loss: nan, lr: 0.0010000, time: 16.63\n",
      "2022-08-13 21:21:15,638 Epoch[17/30] train loss: 0.44769, val loss: nan, lr: 0.0010000, time: 17.16\n",
      "2022-08-13 21:21:32,888 Epoch[18/30] train loss: 0.44580, val loss: nan, lr: 0.0010000, time: 17.24\n",
      "2022-08-13 21:21:49,909 Epoch[19/30] train loss: 0.44499, val loss: nan, lr: 0.0010000, time: 17.02\n",
      "2022-08-13 21:22:06,693 Epoch[20/30] train loss: 0.44274, val loss: nan, lr: 0.0010000, time: 16.78\n",
      "2022-08-13 21:22:23,156 Epoch[21/30] train loss: 0.44354, val loss: nan, lr: 0.0010000, time: 16.46\n",
      "2022-08-13 21:22:40,163 Epoch[22/30] train loss: 0.44065, val loss: nan, lr: 0.0010000, time: 17.01\n",
      "2022-08-13 21:22:57,137 Epoch[23/30] train loss: 0.43992, val loss: nan, lr: 0.0010000, time: 16.97\n",
      "2022-08-13 21:23:13,005 Epoch[24/30] train loss: 0.43871, val loss: nan, lr: 0.0010000, time: 15.87\n",
      "2022-08-13 21:23:30,266 Epoch[25/30] train loss: 0.43621, val loss: nan, lr: 0.0010000, time: 17.26\n",
      "2022-08-13 21:23:46,328 Epoch[26/30] train loss: 0.43608, val loss: nan, lr: 0.0010000, time: 16.06\n",
      "2022-08-13 21:24:03,253 Epoch[27/30] train loss: 0.43420, val loss: nan, lr: 0.0010000, time: 16.92\n",
      "2022-08-13 21:24:19,295 Epoch[28/30] train loss: 0.43458, val loss: nan, lr: 0.0010000, time: 16.04\n",
      "2022-08-13 21:24:35,468 Epoch[29/30] train loss: 0.43336, val loss: nan, lr: 0.0010000, time: 16.17\n",
      "2022-08-13 21:24:51,371 Epoch[30/30] train loss: 0.43194, val loss: nan, lr: 0.0010000, time: 15.90\n",
      "2022-08-13 21:24:51,372 => end training\n",
      "2022-08-13 21:24:51,373 => calculating train scores\n",
      "2022-08-13 21:25:11,574 => train score\n",
      "accuracy: 0.984064766961844\n",
      "presision: 0.23073367995378394\n",
      "recall: 0.9104863221884498\n",
      "f1: 0.3681671531725303\n",
      "2022-08-13 21:25:11,577 => calculating test scores\n",
      "2022-08-13 21:25:17,130 => test score\n",
      "accuracy: 0.9794114456024354\n",
      "presision: 0.09136745607333843\n",
      "recall: 0.5421577515865821\n",
      "f1: 0.15638075313807534\n",
      "2022-08-13 21:25:17,147 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 2, 'rnn_hidden_dim': 128, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 21:25:33,376 Epoch[1/30] train loss: 0.43976, val loss: nan, lr: 0.0010000, time: 16.23\n",
      "2022-08-13 21:25:50,077 Epoch[2/30] train loss: 0.39734, val loss: nan, lr: 0.0010000, time: 16.70\n",
      "2022-08-13 21:26:06,781 Epoch[3/30] train loss: 0.39491, val loss: nan, lr: 0.0010000, time: 16.70\n",
      "2022-08-13 21:26:23,926 Epoch[4/30] train loss: 0.39330, val loss: nan, lr: 0.0010000, time: 17.14\n",
      "2022-08-13 21:26:40,601 Epoch[5/30] train loss: 0.39206, val loss: nan, lr: 0.0010000, time: 16.67\n",
      "2022-08-13 21:26:56,981 Epoch[6/30] train loss: 0.39149, val loss: nan, lr: 0.0010000, time: 16.38\n",
      "2022-08-13 21:27:13,500 Epoch[7/30] train loss: 0.38975, val loss: nan, lr: 0.0010000, time: 16.52\n",
      "2022-08-13 21:27:29,693 Epoch[8/30] train loss: 0.38925, val loss: nan, lr: 0.0010000, time: 16.19\n",
      "2022-08-13 21:27:45,789 Epoch[9/30] train loss: 0.38797, val loss: nan, lr: 0.0010000, time: 16.09\n",
      "2022-08-13 21:28:02,441 Epoch[10/30] train loss: 0.38661, val loss: nan, lr: 0.0010000, time: 16.65\n",
      "2022-08-13 21:28:19,233 Epoch[11/30] train loss: 0.38559, val loss: nan, lr: 0.0010000, time: 16.79\n",
      "2022-08-13 21:28:36,090 Epoch[12/30] train loss: 0.38474, val loss: nan, lr: 0.0010000, time: 16.85\n",
      "2022-08-13 21:28:53,032 Epoch[13/30] train loss: 0.38359, val loss: nan, lr: 0.0010000, time: 16.94\n",
      "2022-08-13 21:29:09,111 Epoch[14/30] train loss: 0.38251, val loss: nan, lr: 0.0010000, time: 16.08\n",
      "2022-08-13 21:29:25,233 Epoch[15/30] train loss: 0.38157, val loss: nan, lr: 0.0010000, time: 16.12\n",
      "2022-08-13 21:29:40,870 Epoch[16/30] train loss: 0.37965, val loss: nan, lr: 0.0010000, time: 15.63\n",
      "2022-08-13 21:29:57,192 Epoch[17/30] train loss: 0.37811, val loss: nan, lr: 0.0010000, time: 16.32\n",
      "2022-08-13 21:30:13,207 Epoch[18/30] train loss: 0.37689, val loss: nan, lr: 0.0010000, time: 16.01\n",
      "2022-08-13 21:30:30,388 Epoch[19/30] train loss: 0.37639, val loss: nan, lr: 0.0010000, time: 17.18\n",
      "2022-08-13 21:30:47,037 Epoch[20/30] train loss: 0.37507, val loss: nan, lr: 0.0010000, time: 16.65\n",
      "2022-08-13 21:31:03,391 Epoch[21/30] train loss: 0.37442, val loss: nan, lr: 0.0010000, time: 16.35\n",
      "2022-08-13 21:31:19,816 Epoch[22/30] train loss: 0.37339, val loss: nan, lr: 0.0010000, time: 16.42\n",
      "2022-08-13 21:31:35,905 Epoch[23/30] train loss: 0.37210, val loss: nan, lr: 0.0010000, time: 16.09\n",
      "2022-08-13 21:31:51,691 Epoch[24/30] train loss: 0.37197, val loss: nan, lr: 0.0010000, time: 15.78\n",
      "2022-08-13 21:32:07,888 Epoch[25/30] train loss: 0.37135, val loss: nan, lr: 0.0010000, time: 16.19\n",
      "2022-08-13 21:32:25,350 Epoch[26/30] train loss: 0.37035, val loss: nan, lr: 0.0010000, time: 17.46\n",
      "2022-08-13 21:32:41,595 Epoch[27/30] train loss: 0.36940, val loss: nan, lr: 0.0010000, time: 16.24\n",
      "2022-08-13 21:32:58,779 Epoch[28/30] train loss: 0.36929, val loss: nan, lr: 0.0010000, time: 17.18\n",
      "2022-08-13 21:33:14,976 Epoch[29/30] train loss: 0.36892, val loss: nan, lr: 0.0010000, time: 16.19\n",
      "2022-08-13 21:33:31,313 Epoch[30/30] train loss: 0.36766, val loss: nan, lr: 0.0010000, time: 16.34\n",
      "2022-08-13 21:33:31,315 => end training\n",
      "2022-08-13 21:33:31,315 => calculating train scores\n",
      "2022-08-13 21:33:51,864 => train score\n",
      "accuracy: 0.9961221657285935\n",
      "presision: 0.5760617760617761\n",
      "recall: 0.9069908814589666\n",
      "f1: 0.7046044864226684\n",
      "2022-08-13 21:33:51,868 => calculating test scores\n",
      "2022-08-13 21:33:57,951 => test score\n",
      "accuracy: 0.9919936945158881\n",
      "presision: 0.1580739299610895\n",
      "recall: 0.29465095194922936\n",
      "f1: 0.20576131687242796\n",
      "2022-08-13 21:33:57,964 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 2, 'rnn_hidden_dim': 128, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 21:34:13,839 Epoch[1/30] train loss: 0.48112, val loss: nan, lr: 0.0010000, time: 15.87\n",
      "2022-08-13 21:34:29,854 Epoch[2/30] train loss: 0.42961, val loss: nan, lr: 0.0010000, time: 16.01\n",
      "2022-08-13 21:34:46,462 Epoch[3/30] train loss: 0.42597, val loss: nan, lr: 0.0010000, time: 16.61\n",
      "2022-08-13 21:35:02,731 Epoch[4/30] train loss: 0.42423, val loss: nan, lr: 0.0010000, time: 16.27\n",
      "2022-08-13 21:35:18,931 Epoch[5/30] train loss: 0.42301, val loss: nan, lr: 0.0010000, time: 16.20\n",
      "2022-08-13 21:35:35,206 Epoch[6/30] train loss: 0.42163, val loss: nan, lr: 0.0010000, time: 16.27\n",
      "2022-08-13 21:35:51,606 Epoch[7/30] train loss: 0.42051, val loss: nan, lr: 0.0010000, time: 16.40\n",
      "2022-08-13 21:36:08,070 Epoch[8/30] train loss: 0.41840, val loss: nan, lr: 0.0010000, time: 16.46\n",
      "2022-08-13 21:36:24,509 Epoch[9/30] train loss: 0.41759, val loss: nan, lr: 0.0010000, time: 16.44\n",
      "2022-08-13 21:36:40,566 Epoch[10/30] train loss: 0.41577, val loss: nan, lr: 0.0010000, time: 16.05\n",
      "2022-08-13 21:36:56,651 Epoch[11/30] train loss: 0.41542, val loss: nan, lr: 0.0010000, time: 16.08\n",
      "2022-08-13 21:37:12,559 Epoch[12/30] train loss: 0.41378, val loss: nan, lr: 0.0010000, time: 15.91\n",
      "2022-08-13 21:37:28,270 Epoch[13/30] train loss: 0.41190, val loss: nan, lr: 0.0010000, time: 15.71\n",
      "2022-08-13 21:37:42,475 Epoch[14/30] train loss: 0.41175, val loss: nan, lr: 0.0010000, time: 14.20\n",
      "2022-08-13 21:37:58,849 Epoch[15/30] train loss: 0.40893, val loss: nan, lr: 0.0010000, time: 16.37\n",
      "2022-08-13 21:38:15,254 Epoch[16/30] train loss: 0.40784, val loss: nan, lr: 0.0010000, time: 16.40\n",
      "2022-08-13 21:38:32,082 Epoch[17/30] train loss: 0.40618, val loss: nan, lr: 0.0010000, time: 16.83\n",
      "2022-08-13 21:38:49,413 Epoch[18/30] train loss: 0.40516, val loss: nan, lr: 0.0010000, time: 17.33\n",
      "2022-08-13 21:39:05,456 Epoch[19/30] train loss: 0.40320, val loss: nan, lr: 0.0010000, time: 16.04\n",
      "2022-08-13 21:39:22,006 Epoch[20/30] train loss: 0.40112, val loss: nan, lr: 0.0010000, time: 16.55\n",
      "2022-08-13 21:39:38,233 Epoch[21/30] train loss: 0.39873, val loss: nan, lr: 0.0010000, time: 16.22\n",
      "2022-08-13 21:39:53,071 Epoch[22/30] train loss: 0.39714, val loss: nan, lr: 0.0010000, time: 14.84\n",
      "2022-08-13 21:40:09,542 Epoch[23/30] train loss: 0.39778, val loss: nan, lr: 0.0010000, time: 16.47\n",
      "2022-08-13 21:40:25,647 Epoch[24/30] train loss: 0.39665, val loss: nan, lr: 0.0010000, time: 16.10\n",
      "2022-08-13 21:40:41,940 Epoch[25/30] train loss: 0.39606, val loss: nan, lr: 0.0010000, time: 16.29\n",
      "2022-08-13 21:40:58,234 Epoch[26/30] train loss: 0.39346, val loss: nan, lr: 0.0010000, time: 16.29\n",
      "2022-08-13 21:41:14,818 Epoch[27/30] train loss: 0.39213, val loss: nan, lr: 0.0010000, time: 16.58\n",
      "2022-08-13 21:41:31,363 Epoch[28/30] train loss: 0.39149, val loss: nan, lr: 0.0010000, time: 16.54\n",
      "2022-08-13 21:41:48,217 Epoch[29/30] train loss: 0.38963, val loss: nan, lr: 0.0010000, time: 16.85\n",
      "2022-08-13 21:42:04,623 Epoch[30/30] train loss: 0.39009, val loss: nan, lr: 0.0010000, time: 16.40\n",
      "2022-08-13 21:42:04,625 => end training\n",
      "2022-08-13 21:42:04,626 => calculating train scores\n",
      "2022-08-13 21:42:25,717 => train score\n",
      "accuracy: 0.994029809107331\n",
      "presision: 0.4566692367000771\n",
      "recall: 0.9001519756838906\n",
      "f1: 0.6059335038363171\n",
      "2022-08-13 21:42:25,720 => calculating test scores\n",
      "2022-08-13 21:42:31,788 => test score\n",
      "accuracy: 0.9902896821091461\n",
      "presision: 0.14206642066420663\n",
      "recall: 0.34904805077062556\n",
      "f1: 0.20194072908471017\n",
      "2022-08-13 21:42:31,805 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 2, 'rnn_hidden_dim': 128, 'weight': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 21:42:48,321 Epoch[1/30] train loss: 0.52745, val loss: nan, lr: 0.0010000, time: 16.52\n",
      "2022-08-13 21:43:05,311 Epoch[2/30] train loss: 0.48048, val loss: nan, lr: 0.0010000, time: 16.99\n",
      "2022-08-13 21:43:21,446 Epoch[3/30] train loss: 0.47776, val loss: nan, lr: 0.0010000, time: 16.13\n",
      "2022-08-13 21:43:38,166 Epoch[4/30] train loss: 0.47469, val loss: nan, lr: 0.0010000, time: 16.72\n",
      "2022-08-13 21:43:54,791 Epoch[5/30] train loss: 0.47258, val loss: nan, lr: 0.0010000, time: 16.62\n",
      "2022-08-13 21:44:11,455 Epoch[6/30] train loss: 0.47081, val loss: nan, lr: 0.0010000, time: 16.66\n",
      "2022-08-13 21:44:27,581 Epoch[7/30] train loss: 0.46905, val loss: nan, lr: 0.0010000, time: 16.12\n",
      "2022-08-13 21:44:44,460 Epoch[8/30] train loss: 0.46730, val loss: nan, lr: 0.0010000, time: 16.88\n",
      "2022-08-13 21:45:00,689 Epoch[9/30] train loss: 0.46515, val loss: nan, lr: 0.0010000, time: 16.23\n",
      "2022-08-13 21:45:17,217 Epoch[10/30] train loss: 0.46235, val loss: nan, lr: 0.0010000, time: 16.53\n",
      "2022-08-13 21:45:33,981 Epoch[11/30] train loss: 0.46066, val loss: nan, lr: 0.0010000, time: 16.76\n",
      "2022-08-13 21:45:50,299 Epoch[12/30] train loss: 0.45951, val loss: nan, lr: 0.0010000, time: 16.32\n",
      "2022-08-13 21:46:07,271 Epoch[13/30] train loss: 0.45741, val loss: nan, lr: 0.0010000, time: 16.97\n",
      "2022-08-13 21:46:23,873 Epoch[14/30] train loss: 0.45462, val loss: nan, lr: 0.0010000, time: 16.60\n",
      "2022-08-13 21:46:40,027 Epoch[15/30] train loss: 0.45350, val loss: nan, lr: 0.0010000, time: 16.15\n",
      "2022-08-13 21:46:56,542 Epoch[16/30] train loss: 0.45211, val loss: nan, lr: 0.0010000, time: 16.51\n",
      "2022-08-13 21:47:12,837 Epoch[17/30] train loss: 0.44834, val loss: nan, lr: 0.0010000, time: 16.29\n",
      "2022-08-13 21:47:29,279 Epoch[18/30] train loss: 0.44551, val loss: nan, lr: 0.0010000, time: 16.44\n",
      "2022-08-13 21:47:45,478 Epoch[19/30] train loss: 0.44503, val loss: nan, lr: 0.0010000, time: 16.20\n",
      "2022-08-13 21:48:01,658 Epoch[20/30] train loss: 0.44445, val loss: nan, lr: 0.0010000, time: 16.18\n",
      "2022-08-13 21:48:18,244 Epoch[21/30] train loss: 0.44365, val loss: nan, lr: 0.0010000, time: 16.58\n",
      "2022-08-13 21:48:35,570 Epoch[22/30] train loss: 0.43932, val loss: nan, lr: 0.0010000, time: 17.32\n",
      "2022-08-13 21:48:51,998 Epoch[23/30] train loss: 0.44081, val loss: nan, lr: 0.0010000, time: 16.43\n",
      "2022-08-13 21:49:09,019 Epoch[24/30] train loss: 0.43804, val loss: nan, lr: 0.0010000, time: 17.02\n",
      "2022-08-13 21:49:25,985 Epoch[25/30] train loss: 0.43518, val loss: nan, lr: 0.0010000, time: 16.96\n",
      "2022-08-13 21:49:42,170 Epoch[26/30] train loss: 0.43404, val loss: nan, lr: 0.0010000, time: 16.18\n",
      "2022-08-13 21:49:59,147 Epoch[27/30] train loss: 0.43795, val loss: nan, lr: 0.0010000, time: 16.98\n",
      "2022-08-13 21:50:16,517 Epoch[28/30] train loss: 0.43424, val loss: nan, lr: 0.0010000, time: 17.37\n",
      "2022-08-13 21:50:32,294 Epoch[29/30] train loss: 0.43387, val loss: nan, lr: 0.0010000, time: 15.78\n",
      "2022-08-13 21:50:48,273 Epoch[30/30] train loss: 0.43180, val loss: nan, lr: 0.0010000, time: 15.98\n",
      "2022-08-13 21:50:48,275 => end training\n",
      "2022-08-13 21:50:48,276 => calculating train scores\n",
      "2022-08-13 21:51:09,182 => train score\n",
      "accuracy: 0.9842437796949964\n",
      "presision: 0.23675344563552833\n",
      "recall: 0.9398176291793313\n",
      "f1: 0.3782262996941896\n",
      "2022-08-13 21:51:09,184 => calculating test scores\n",
      "2022-08-13 21:51:14,022 => test score\n",
      "accuracy: 0.9783360669861956\n",
      "presision: 0.085205719288007\n",
      "recall: 0.5294650951949229\n",
      "f1: 0.14678899082568805\n",
      "2022-08-13 21:51:14,041 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 2, 'rnn_hidden_dim': 256, 'weight': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 21:51:39,826 Epoch[1/30] train loss: 0.46634, val loss: nan, lr: 0.0010000, time: 25.78\n",
      "2022-08-13 21:52:05,268 Epoch[2/30] train loss: 0.39891, val loss: nan, lr: 0.0010000, time: 25.44\n",
      "2022-08-13 21:52:30,870 Epoch[3/30] train loss: 0.39586, val loss: nan, lr: 0.0010000, time: 25.60\n",
      "2022-08-13 21:52:56,440 Epoch[4/30] train loss: 0.39422, val loss: nan, lr: 0.0010000, time: 25.57\n",
      "2022-08-13 21:53:21,952 Epoch[5/30] train loss: 0.39283, val loss: nan, lr: 0.0010000, time: 25.51\n",
      "2022-08-13 21:53:48,128 Epoch[6/30] train loss: 0.39174, val loss: nan, lr: 0.0010000, time: 26.17\n",
      "2022-08-13 21:54:13,900 Epoch[7/30] train loss: 0.39047, val loss: nan, lr: 0.0010000, time: 25.77\n",
      "2022-08-13 21:54:39,534 Epoch[8/30] train loss: 0.38866, val loss: nan, lr: 0.0010000, time: 25.63\n",
      "2022-08-13 21:55:05,340 Epoch[9/30] train loss: 0.38702, val loss: nan, lr: 0.0010000, time: 25.80\n",
      "2022-08-13 21:55:31,039 Epoch[10/30] train loss: 0.38605, val loss: nan, lr: 0.0010000, time: 25.70\n",
      "2022-08-13 21:55:57,297 Epoch[11/30] train loss: 0.38439, val loss: nan, lr: 0.0010000, time: 26.26\n",
      "2022-08-13 21:56:23,013 Epoch[12/30] train loss: 0.38269, val loss: nan, lr: 0.0010000, time: 25.71\n",
      "2022-08-13 21:56:48,566 Epoch[13/30] train loss: 0.38180, val loss: nan, lr: 0.0010000, time: 25.55\n",
      "2022-08-13 21:57:13,903 Epoch[14/30] train loss: 0.38046, val loss: nan, lr: 0.0010000, time: 25.33\n",
      "2022-08-13 21:57:40,371 Epoch[15/30] train loss: 0.37898, val loss: nan, lr: 0.0010000, time: 26.47\n",
      "2022-08-13 21:58:06,074 Epoch[16/30] train loss: 0.37749, val loss: nan, lr: 0.0010000, time: 25.70\n",
      "2022-08-13 21:58:32,003 Epoch[17/30] train loss: 0.37555, val loss: nan, lr: 0.0010000, time: 25.93\n",
      "2022-08-13 21:58:57,473 Epoch[18/30] train loss: 0.37430, val loss: nan, lr: 0.0010000, time: 25.47\n",
      "2022-08-13 21:59:22,665 Epoch[19/30] train loss: 0.37408, val loss: nan, lr: 0.0010000, time: 25.19\n",
      "2022-08-13 21:59:48,261 Epoch[20/30] train loss: 0.37240, val loss: nan, lr: 0.0010000, time: 25.59\n",
      "2022-08-13 22:00:14,052 Epoch[21/30] train loss: 0.37097, val loss: nan, lr: 0.0010000, time: 25.79\n",
      "2022-08-13 22:00:39,991 Epoch[22/30] train loss: 0.36975, val loss: nan, lr: 0.0010000, time: 25.94\n",
      "2022-08-13 22:01:05,499 Epoch[23/30] train loss: 0.36878, val loss: nan, lr: 0.0010000, time: 25.51\n",
      "2022-08-13 22:01:31,637 Epoch[24/30] train loss: 0.36847, val loss: nan, lr: 0.0010000, time: 26.14\n",
      "2022-08-13 22:01:57,309 Epoch[25/30] train loss: 0.36779, val loss: nan, lr: 0.0010000, time: 25.67\n",
      "2022-08-13 22:02:23,409 Epoch[26/30] train loss: 0.36767, val loss: nan, lr: 0.0010000, time: 26.10\n",
      "2022-08-13 22:02:48,979 Epoch[27/30] train loss: 0.36660, val loss: nan, lr: 0.0010000, time: 25.57\n",
      "2022-08-13 22:03:15,033 Epoch[28/30] train loss: 0.36627, val loss: nan, lr: 0.0010000, time: 26.05\n",
      "2022-08-13 22:03:40,720 Epoch[29/30] train loss: 0.36507, val loss: nan, lr: 0.0010000, time: 25.68\n",
      "2022-08-13 22:04:06,682 Epoch[30/30] train loss: 0.36550, val loss: nan, lr: 0.0010000, time: 25.96\n",
      "2022-08-13 22:04:06,683 => end training\n",
      "2022-08-13 22:04:06,684 => calculating train scores\n",
      "2022-08-13 22:04:28,760 => train score\n",
      "accuracy: 0.9973582060289319\n",
      "presision: 0.6918330308529945\n",
      "recall: 0.8689969604863221\n",
      "f1: 0.7703603907039407\n",
      "2022-08-13 22:04:28,763 => calculating test scores\n",
      "2022-08-13 22:04:35,330 => test score\n",
      "accuracy: 0.9931488489938668\n",
      "presision: 0.1773794808405439\n",
      "recall: 0.2601994560290118\n",
      "f1: 0.2109518559353179\n",
      "2022-08-13 22:04:35,359 => start training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_rnns': 2, 'rnn_hidden_dim': 256, 'weight': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 22:05:00,825 Epoch[1/30] train loss: 0.47475, val loss: nan, lr: 0.0010000, time: 25.46\n",
      "2022-08-13 22:05:26,467 Epoch[2/30] train loss: 0.42929, val loss: nan, lr: 0.0010000, time: 25.64\n",
      "2022-08-13 22:05:51,967 Epoch[3/30] train loss: 0.42622, val loss: nan, lr: 0.0010000, time: 25.50\n",
      "2022-08-13 22:06:18,092 Epoch[4/30] train loss: 0.42479, val loss: nan, lr: 0.0010000, time: 26.12\n",
      "2022-08-13 22:06:44,026 Epoch[5/30] train loss: 0.42345, val loss: nan, lr: 0.0010000, time: 25.93\n",
      "2022-08-13 22:07:10,089 Epoch[6/30] train loss: 0.42212, val loss: nan, lr: 0.0010000, time: 26.06\n",
      "2022-08-13 22:07:35,691 Epoch[7/30] train loss: 0.42047, val loss: nan, lr: 0.0010000, time: 25.60\n",
      "2022-08-13 22:08:01,175 Epoch[8/30] train loss: 0.41948, val loss: nan, lr: 0.0010000, time: 25.48\n",
      "2022-08-13 22:08:26,633 Epoch[9/30] train loss: 0.41777, val loss: nan, lr: 0.0010000, time: 25.46\n",
      "2022-08-13 22:08:52,782 Epoch[10/30] train loss: 0.41568, val loss: nan, lr: 0.0010000, time: 26.15\n",
      "2022-08-13 22:09:18,909 Epoch[11/30] train loss: 0.41406, val loss: nan, lr: 0.0010000, time: 26.13\n",
      "2022-08-13 22:09:44,501 Epoch[12/30] train loss: 0.41232, val loss: nan, lr: 0.0010000, time: 25.59\n"
     ]
    }
   ],
   "source": [
    "max_acc = [[0, 0, 0, 0], None]\n",
    "max_pre = [[0, 0, 0, 0], None]\n",
    "max_rcl = [[0, 0, 0, 0], None]\n",
    "max_f1 = [[0, 0, 0, 0], None]\n",
    "max_models = [None for _ in range(4)]\n",
    "\n",
    "for n_rnns in params['n_rnns']:\n",
    "    for dim in params['rnn_hidden_dim']:\n",
    "        for weight in params['pos_weight']:\n",
    "            param = dict(n_rnns=n_rnns, rnn_hidden_dim=dim, weight=weight)\n",
    "            print(param)\n",
    "            \n",
    "            # update config\n",
    "            config = {}\n",
    "            for key, val in mdl_cfg.items():\n",
    "                config[key] = val\n",
    "            for key, val in param.items():\n",
    "                config[key] = val\n",
    "            pos_weight = param[\"weight\"]\n",
    "                \n",
    "            # init model, loss, optim\n",
    "            model = init_model(config, device)\n",
    "            criterion = init_loss([1, pos_weight], device)\n",
    "            optimizer, scheduler = init_optim(\n",
    "                model, train_cfg[\"optim\"][\"lr\"], train_cfg[\"optim\"][\"lr_rate\"]\n",
    "            )\n",
    "            \n",
    "            # training\n",
    "            model, epoch, history = train(\n",
    "                model, train_loader, val_loader,\n",
    "                criterion, optimizer, scheduler,\n",
    "                epoch_len, logger, device\n",
    "            )\n",
    "            \n",
    "            # test\n",
    "            score = test(model, test_loader, logger, device)\n",
    "            acc, pre, rcl, f1 = score\n",
    "            \n",
    "            # update max scores\n",
    "            if acc > max_acc[0][0]:\n",
    "                max_acc[0] = score\n",
    "                max_acc[1] = param\n",
    "                max_models[0] = model\n",
    "            if pre > max_pre[0][1]:\n",
    "                max_pre[0] = score\n",
    "                max_pre[1] = param\n",
    "                max_models[1] = model\n",
    "            if rcl > max_rcl[0][2]:\n",
    "                max_rcl[0] = score\n",
    "                max_rcl[1] = param\n",
    "                max_models[2] = model\n",
    "            if f1 > max_f1[0][3]:\n",
    "                max_f1[0] = score\n",
    "                max_f1[1] = param\n",
    "                max_models[3] = model\n",
    "                \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd10c2-70ac-46bb-a799-ea597a2204ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"epoch={epoch}\")\n",
    "print('max accuracy: ', max_acc[1])\n",
    "acc, pre, rcl, f1 = max_acc[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max precision: ', max_pre[1])\n",
    "acc, pre, rcl, f1 = max_pre[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max recall: ', max_rcl[1])\n",
    "acc, pre, rcl, f1 = max_rcl[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))\n",
    "\n",
    "print('max f1: ', max_f1[1])\n",
    "acc, pre, rcl, f1 = max_f1[0]\n",
    "print('accuracy: {:.3f}'.format(acc), 'precision: {:.3f}'.format(pre), 'recall: {:.3f}'.format(rcl), 'f1_score: {:.3f}'.format(f1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "784c9760-81f6-4649-8df0-1d465e53a98f",
   "metadata": {},
   "source": [
    "epoch=50\n",
    "max accuracy:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.522 recall: 0.475 f1_score: 0.497\n",
    "max precision:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.522 recall: 0.475 f1_score: 0.497\n",
    "max recall:  {'n_rnns': 1, 'rnn_hidden_dim': 128, 'weight': 32}\n",
    "accuracy: 0.979 precision: 0.158 recall: 0.760 f1_score: 0.261\n",
    "max f1:  {'n_rnns': 3, 'rnn_hidden_dim': 256, 'weight': 16}\n",
    "accuracy: 0.995 precision: 0.522 recall: 0.475 f1_score: 0.497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0835b-4abf-46d4-ba43-1d4c26646dbb",
   "metadata": {},
   "source": [
    "## モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54bf6e-f404-4857-b6cb-5b82b32d6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max recall\n",
    "model = max_models[2]\n",
    "param = max_rcl[1]\n",
    "config = {}\n",
    "for key, val in mdl_cfg.items():\n",
    "    config[key] = val\n",
    "for key, val in param.items():\n",
    "    config[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9824f0c-aaf5-4d21-9350-2b5137621cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/passing/pass_model_lstm_recall_ep{epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0d883-965c-43a5-9c60-bac39e468dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"pretrained_path\"] = model_path\n",
    "with open(f'config/passing/pass_model_lstm_recall_ep{epoch}.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e18e5-12d3-41cb-a631-48554ecc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max f1\n",
    "model = max_models[3]\n",
    "param = max_f1[1]\n",
    "config = {}\n",
    "for key, val in mdl_cfg.items():\n",
    "    config[key] = val\n",
    "for key, val in param.items():\n",
    "    config[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc4a91-ce20-4aa0-a790-effed2c75aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'models/passing/pass_model_lstm_f1_ep{epoch}.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb143daa-abbe-419a-9fb9-8d58fc1ad234",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"pretrained_path\"] = model_path\n",
    "with open(f'config/passing/pass_model_lstm_f1_ep{epoch}.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a60fd-b6fe-4f37-9dea-75091bdeaf20",
   "metadata": {},
   "source": [
    "# 検証\n",
    "## モデルロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3656ce-2abd-4508-9594-2a72718a379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "epoch = 30\n",
    "rcl_f1 = \"f1\"\n",
    "\n",
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "    del model\n",
    "    gc.collect()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "mdl_cfg_path = f'config/passing/pass_model_lstm_{rcl_f1}_ep{epoch}.yaml'\n",
    "with open(mdl_cfg_path, \"r\") as f:\n",
    "    mdl_cfg = yaml.safe_load(f)\n",
    "model = init_model(mdl_cfg, device)\n",
    "\n",
    "param = torch.load(mdl_cfg[\"pretrained_path\"])\n",
    "model.load_state_dict(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caade6b7-93f0-4a5a-ac67-4901ddddaafe",
   "metadata": {},
   "source": [
    "## データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbc7d5-075e-4f54-af8d-bac19a4860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict, y_dict = make_all_data(inds, train_cfg[\"dataset\"][\"setting\"], grp_cfg[\"passing\"][\"default\"], logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77857721-bff3-42e1-af5a-83703d6d769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(train_cfg[\"dataset\"][\"random_seed\"])\n",
    "\n",
    "seq_len = grp_cfg[\"passing\"][\"default\"][\"seq_len\"]\n",
    "size = mdl_cfg[\"size\"]\n",
    "\n",
    "keys_1 = [key for key in x_dict if 1 in y_dict[key]]\n",
    "keys_0 = [key for key in x_dict if 1 not in y_dict[key]]\n",
    "random_keys_1 = np.random.choice(keys_1, size=len(keys_1), replace=False)\n",
    "random_keys_0 = np.random.choice(keys_0, size=len(keys_0), replace=False)\n",
    "\n",
    "train_ratio = train_cfg[\"dataset\"][\"train_ratio\"]\n",
    "val_ratio = train_cfg[\"dataset\"][\"val_ratio\"]\n",
    "train_len_1 = int(len(keys_1) * train_ratio)\n",
    "train_len_0 = int(len(keys_0) * train_ratio)\n",
    "val_len_1 = int(len(keys_1) * val_ratio)\n",
    "val_len_0 = int(len(keys_0) * val_ratio)\n",
    "\n",
    "train_keys_1 = random_keys_1[:train_len_1].tolist()\n",
    "val_keys_1 = random_keys_1[train_len_1 : train_len_1 + val_len_1].tolist()\n",
    "test_keys_1 = random_keys_1[train_len_1 + val_len_1 :].tolist()\n",
    "train_keys_0 = random_keys_0[:train_len_0].tolist()\n",
    "test_keys_0 = random_keys_0[train_len_0:].tolist()\n",
    "val_keys_0 = random_keys_1[train_len_0 : train_len_0 + val_len_0].tolist()\n",
    "\n",
    "train_keys = sorted(train_keys_1 + train_keys_0)\n",
    "val_keys = sorted(val_keys_1 + val_keys_0)\n",
    "test_keys = sorted(test_keys_1 + test_keys_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc30e4-b08b-4287-8b07-f8effaaebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(x_lst, y_lst, seq_len=30, size=4):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(x_lst) - seq_len + 1):\n",
    "        x = x_lst[i:i + seq_len]\n",
    "        x_seq.append(x)\n",
    "        y_seq.append(y_lst[i + seq_len - 1])\n",
    "    \n",
    "    return x_seq, y_seq\n",
    "\n",
    "\n",
    "columns = [\"distance\", \"body_direction\", \"arm_ave\", \"wrist_distance\"]\n",
    "def plot(x_lst, y_lst, pred, seq_len=30, path=None):\n",
    "    x_lst = [[0 for _ in range(x_lst.shape[1])]] + [[np.nan for _ in range(x_lst.shape[1])] for i in range(seq_len - 1)] + x_lst.tolist()\n",
    "    y_lst = [0] + [np.nan for i in range(seq_len - 1)] + y_lst\n",
    "    pred = [0] + [np.nan for i in range(seq_len - 1)] + pred.tolist()\n",
    "    \n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    ax = fig.add_axes((0.04, 0.17, 0.80, 0.81))\n",
    "    \n",
    "    ax.plot(pred, label='pred')\n",
    "    ax.plot(y_lst, linestyle=':', label='ground truth')\n",
    "    for i, feature in enumerate(np.array(x_lst).T):\n",
    "        ax.plot(feature, alpha=0.4, label=columns[i])\n",
    "\n",
    "    ax.set_ylim((-0.05, 1.05))\n",
    "    ax.set_xlabel('frame')\n",
    "    ax.legend(\n",
    "        bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0,\n",
    "        fontsize=20, handlelength=0.8, handletextpad=0.2\n",
    "    )\n",
    "    \n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    if path is not None:\n",
    "        fig.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae855e-89c6-4545-8cc2-6850204c1cf9",
   "metadata": {},
   "source": [
    "## トレインデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a72bc4-e0f7-42e4-946d-0727cdf210a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keys = [\n",
    "    '02_06_1_3',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f9e0e-6b00-4dac-9641-1088126b63c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_train = []\n",
    "pred_all_train = []\n",
    "y_eve_train = []\n",
    "pred_eve_train = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in train_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "        \n",
    "        x, _ = create_sequence(x_lst, y_lst, seq_len, size)\n",
    "        x = torch.Tensor(np.array(x)).float().to(device)\n",
    "        \n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[seq_len - 1:]\n",
    "        y_lst = y_lst[seq_len - 1:]\n",
    "            \n",
    "        y_all_train += y_lst\n",
    "        pred_all_train += pred.tolist()\n",
    "        y_eve_train.append(1 in y_lst)\n",
    "        pred_eve_train.append(1 in pred.tolist())\n",
    "        \n",
    "        if 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        path = None\n",
    "        if key in save_keys:\n",
    "            path = os.path.join(\"data\", \"passing\", \"image\", f\"rnn_test_{key}.pdf\")\n",
    "        plot(x_lst, y_lst, pred, seq_len, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24e519-53ca-405c-a4ed-5bc31fc7d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_train, pred_all_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_train, pred_all_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_train, pred_all_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_train, pred_all_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388e620-e79f-4a62-9530-ba821dcb9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per event\n",
    "print('accuracy: {:.3f}'.format(accuracy_score(y_eve_train, pred_eve_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_eve_train, pred_eve_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_eve_train, pred_eve_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_eve_train, pred_eve_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055dc76-a0e1-42b0-85a8-358c036dba57",
   "metadata": {},
   "source": [
    "## テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445c2a5-4a0f-49c4-9ef1-97983f804401",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_keys = [\n",
    "    '08_03_2_5',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4075ac9-b3b6-460b-9cc2-dac368fed21f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_test = []\n",
    "pred_all_test = []\n",
    "y_eve_test = []\n",
    "pred_eve_test = []\n",
    "tn, fn = 0, 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in test_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "\n",
    "        x, _ = create_sequence(x_lst, y_lst, seq_len, size)\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "\n",
    "        if len(x) == 0:\n",
    "            tn += 1\n",
    "            continue\n",
    "            \n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[seq_len - 1:]\n",
    "        y_lst = y_lst[seq_len - 1:]\n",
    "        \n",
    "        y_all_test += y_lst\n",
    "        pred_all_test += pred.tolist()\n",
    "        y_eve_test.append(1 in y_lst)\n",
    "        pred_eve_test.append(1 in pred.tolist())\n",
    "        if 1 not in y_lst:\n",
    "            if 1 not in pred:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        \n",
    "        if 1 not in pred and 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        path = None\n",
    "        if key in save_keys:\n",
    "            path = os.path.join(\"data\", \"passing\", \"image\", f\"rnn_test_{key}.pdf\")\n",
    "        plot(x_lst, y_lst, pred, seq_len, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125394d0-a266-4220-9cab-a86b943a9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_test, pred_all_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_test, pred_all_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_test, pred_all_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_test, pred_all_test)))\n",
    "\n",
    "cm = confusion_matrix(y_all_test, pred_all_test)\n",
    "sns.heatmap(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa66db1-dae9-433e-a64b-803a7d9f02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per event\n",
    "print('accuracy: {:.3f}'.format(accuracy_score(y_eve_test, pred_eve_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_eve_test, pred_eve_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_eve_test, pred_eve_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_eve_test, pred_eve_test)))\n",
    "\n",
    "print('true negative:', tn)\n",
    "print('false negative:', fn)\n",
    "\n",
    "cm = confusion_matrix(y_eve_test, pred_eve_test)\n",
    "sns.heatmap(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30255301-5894-4c67-961f-6123eff18fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
