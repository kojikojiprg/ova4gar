{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621a2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import yaml\n",
    "sys.path.append('../../../src')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from common import common, transform, json\n",
    "from common.json import IA_FORMAT, START_IDX\n",
    "from common.functions import gauss, cos_similarity, standardize\n",
    "from common.default import PASSING_DEFAULT\n",
    "from individual_activity.individual_activity import IndividualActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28083f0-6a29-4348-b2f0-6099f5289d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_idx = 0\n",
    "device = f'cuda:{device_idx}' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5529414-c955-4937-a3ae-fee227a8c985",
   "metadata": {},
   "source": [
    "# Indivisual Activity をロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13258793-9215-437d-aaa5-2d3c5e1676ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_settings = [\n",
    "    {'room_num': '02', 'date': '20210903', 'option': 'passing'},\n",
    "    {'room_num': '08', 'date': '20210915', 'option': 'passing'},\n",
    "    {'room_num': '09', 'date': '20210706', 'option': 'passing'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f9fd05-6b39-4482-a6e9-6f76c4fe1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# homography\n",
    "def get_homo(room_num):\n",
    "    field_path = os.path.join(common.data_dir, '{}/field.png'.format(room_num))\n",
    "    field_raw = cv2.imread(field_path)\n",
    "    p_video = transform.homo[room_num][0]\n",
    "    p_field = transform.homo[room_num][1]\n",
    "    homo = transform.Homography(p_video, p_field, field_raw.shape)\n",
    "    return homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d90bf23-ef9b-477e-9bc1-a78b6a8b9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_individuals(json_data, prefix, homo):\n",
    "    individuals = {}\n",
    "    for data in json_data:\n",
    "        label = prefix + str(data[IA_FORMAT[0]])\n",
    "        frame_num = data[IA_FORMAT[1]]\n",
    "        tracking_point = data[IA_FORMAT[2]]\n",
    "        keypoints = data[IA_FORMAT[3]]\n",
    "\n",
    "        if label not in individuals:\n",
    "            ia = IndividualActivity(label, homo)\n",
    "            individuals[label] = ia\n",
    "        else:\n",
    "            ia = individuals[label]\n",
    "\n",
    "        ia.tracking_points[frame_num] = tracking_point\n",
    "        ia.keypoints[frame_num] = keypoints\n",
    "        for f in IA_FORMAT[START_IDX:]:\n",
    "            ia.indicator_dict[f][frame_num] = data[f]\n",
    "            \n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cc34c2-b791-4675-8da9-15703afaa5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'room_num': '02', 'date': '20210903', 'option': 'passing'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'room_num': '08', 'date': '20210915', 'option': 'passing'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [00:02<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'room_num': '09', 'date': '20210706', 'option': 'passing'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00,  9.58it/s]\n"
     ]
    }
   ],
   "source": [
    "individuals = {}\n",
    "for setting in data_settings:\n",
    "    print(setting)\n",
    "    room_num = setting['room_num']\n",
    "    date = setting['date']\n",
    "    opt = setting['option']\n",
    "    \n",
    "    homo = get_homo(room_num)\n",
    "    \n",
    "    if opt is None:\n",
    "        dir_path = f'{common.data_dir}/{room_num}/{date}/*'\n",
    "    else:\n",
    "        dir_path = f'{common.data_dir}/{room_num}/{date}/{opt}/*'\n",
    "    dirs = glob.glob(dir_path)\n",
    "    dirs = sorted(dirs)[:-1]  # delete make_csv.csv\n",
    "    \n",
    "    for path in tqdm(dirs):\n",
    "        path = f'{path}/json/individual_activity.json'\n",
    "        json_data = json.load(path)\n",
    "        prefix = common.split_path(path)[-6] + '_' + common.split_path(path)[-3] + '_'  # room-num_date_\n",
    "        individuals.update(load_individuals(json_data, prefix, homo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72004e68-6780-49fc-a9b0-39956994bf8c",
   "metadata": {},
   "source": [
    "# 特徴量抽出とデータ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6813548-8e32-424d-8f3f-9e7e19da345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(frame_num, label1, label2, individuals):\n",
    "    if label1 not in individuals or label2 not in individuals:\n",
    "        return None\n",
    "        \n",
    "    individual1 = individuals[label1]\n",
    "    pos1 = individual1.get_indicator('position', frame_num)\n",
    "    body1 = individual1.get_indicator('body_vector', frame_num)\n",
    "    arm1 = individual1.get_indicator('arm_ext', frame_num)\n",
    "    wrist1 = [\n",
    "        individual1.get_keypoints('LWrist', frame_num),\n",
    "        individual1.get_keypoints('RWrist', frame_num)\n",
    "    ]\n",
    "    if pos1 is None or body1 is None or arm1 is None or None in wrist1:\n",
    "        return None\n",
    "    \n",
    "    individual2 = individuals[label2]\n",
    "    pos2 = individual2.get_indicator('position', frame_num)\n",
    "    body2 = individual2.get_indicator('body_vector', frame_num)\n",
    "    arm2 = individual2.get_indicator('arm_ext', frame_num)\n",
    "    wrist2 = [\n",
    "        individual2.get_keypoints('LWrist', frame_num),\n",
    "        individual2.get_keypoints('RWrist', frame_num)\n",
    "    ]\n",
    "    if pos2 is None or body2 is None or arm2 is None or None in wrist2:\n",
    "        return None\n",
    "    \n",
    "    # ポジション間の距離\n",
    "    norm = np.linalg.norm(np.array(pos1) - np.array(pos2), ord=2)\n",
    "    distance_prob = gauss(\n",
    "        norm,\n",
    "        mu=PASSING_DEFAULT['gauss_mu'],\n",
    "        sigma=PASSING_DEFAULT['gauss_sig_min']\n",
    "    )\n",
    "    \n",
    "    # 体の向き\n",
    "    pos1 = np.array(pos1)\n",
    "    pos2 = np.array(pos2)\n",
    "    p1p2 = pos2 - pos1\n",
    "    p2p1 = pos1 - pos2\n",
    "    p1_sim = cos_similarity(body1, p1p2)\n",
    "    p2_sim = cos_similarity(body2, p2p1)\n",
    "    body_direction = (np.average([p1_sim, p2_sim]) + 1) / 2  # [-1, 1] -> [0, 1]\n",
    "    \n",
    "    # 腕の上げ下げ\n",
    "    arm_ave = np.average([arm1, arm2])\n",
    "    \n",
    "    # 手首の距離\n",
    "    min_norm = np.inf\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            norm = np.linalg.norm(\n",
    "                np.array(wrist1[i]) - np.array(wrist2[j]), ord=2)\n",
    "            if norm < min_norm:\n",
    "                min_norm = norm\n",
    "    distance_prob_wrist = gauss(\n",
    "        min_norm,\n",
    "        mu=PASSING_DEFAULT['wrist_gauss_mu'],\n",
    "        sigma=PASSING_DEFAULT['wrist_gauss_sig_min']\n",
    "    )\n",
    "\n",
    "    return [distance_prob, body_direction, arm_ave, distance_prob_wrist]\n",
    "\n",
    "columns = ['distance', 'body direction', 'arm average', 'wrist distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca85d7d5-9ff3-4597-aba6-5a5b50f945e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02, 20210903, 01: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3328/3328 [00:00<00:00, 15504.33it/s]\n",
      "02, 20210903, 02: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9548/9548 [00:00<00:00, 15527.48it/s]\n",
      "02, 20210903, 03: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3281/3281 [00:00<00:00, 16114.50it/s]\n",
      "02, 20210903, 04: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1843/1843 [00:00<00:00, 16213.31it/s]\n",
      "02, 20210903, 05: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3695/3695 [00:00<00:00, 15152.98it/s]\n",
      "02, 20210903, 06: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5134/5134 [00:00<00:00, 15716.17it/s]\n",
      "02, 20210903, 07: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4698/4698 [00:00<00:00, 16328.58it/s]\n",
      "02, 20210903, 08: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7890/7890 [00:00<00:00, 16070.18it/s]\n",
      "02, 20210903, 09: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13816/13816 [00:00<00:00, 15675.20it/s]\n",
      "02, 20210903, 10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31839/31839 [00:02<00:00, 15584.28it/s]\n",
      "02, 20210903, 11: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14263/14263 [00:00<00:00, 15733.73it/s]\n",
      "02, 20210903, 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5074/5074 [00:00<00:00, 15790.66it/s]\n",
      "02, 20210903, 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9464/9464 [00:00<00:00, 15709.60it/s]\n",
      "02, 20210903, 14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10527/10527 [00:00<00:00, 15950.45it/s]\n",
      "02, 20210903, 15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23269/23269 [00:01<00:00, 15692.08it/s]\n",
      "02, 20210903, 16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4578/4578 [00:00<00:00, 16186.52it/s]\n",
      "02, 20210903, 17: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2131/2131 [00:00<00:00, 15475.66it/s]\n",
      "02, 20210903, 18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11139/11139 [00:00<00:00, 15787.31it/s]\n",
      "02, 20210903, 19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2586/2586 [00:00<00:00, 15672.62it/s]\n",
      "02, 20210903, 20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3981/3981 [00:00<00:00, 15568.12it/s]\n",
      "02, 20210903, 21: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3568/3568 [00:00<00:00, 15688.01it/s]\n",
      "02, 20210903, 22: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3668/3668 [00:00<00:00, 15530.87it/s]\n",
      "02, 20210903, 23: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5215/5215 [00:00<00:00, 15628.76it/s]\n",
      "08, 20210915, 01: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4381/4381 [00:00<00:00, 16041.59it/s]\n",
      "08, 20210915, 02: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4355/4355 [00:00<00:00, 15655.55it/s]\n",
      "08, 20210915, 03: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12757/12757 [00:00<00:00, 15741.01it/s]\n",
      "08, 20210915, 04: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4116/4116 [00:00<00:00, 16134.52it/s]\n",
      "08, 20210915, 05: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3386/3386 [00:00<00:00, 15614.05it/s]\n",
      "08, 20210915, 06: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2205/2205 [00:00<00:00, 15997.05it/s]\n",
      "08, 20210915, 07: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3134/3134 [00:00<00:00, 16724.00it/s]\n",
      "08, 20210915, 08: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4325/4325 [00:00<00:00, 15504.39it/s]\n",
      "08, 20210915, 09: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2471/2471 [00:00<00:00, 15630.09it/s]\n",
      "08, 20210915, 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5287/5287 [00:00<00:00, 15434.65it/s]\n",
      "08, 20210915, 11: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5526/5526 [00:00<00:00, 15933.89it/s]\n",
      "08, 20210915, 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5037/5037 [00:00<00:00, 16545.61it/s]\n",
      "08, 20210915, 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5103/5103 [00:00<00:00, 15645.35it/s]\n",
      "08, 20210915, 14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5790/5790 [00:00<00:00, 15858.03it/s]\n",
      "08, 20210915, 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3479/3479 [00:00<00:00, 15870.70it/s]\n",
      "08, 20210915, 16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3391/3391 [00:00<00:00, 16051.87it/s]\n",
      "08, 20210915, 17: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1432/1432 [00:00<00:00, 16008.79it/s]\n",
      "08, 20210915, 18: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2297/2297 [00:00<00:00, 16033.60it/s]\n",
      "08, 20210915, 19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6157/6157 [00:00<00:00, 16098.88it/s]\n",
      "08, 20210915, 20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2466/2466 [00:00<00:00, 15951.74it/s]\n",
      "08, 20210915, 21: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2030/2030 [00:00<00:00, 15079.33it/s]\n",
      "08, 20210915, 22: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3113/3113 [00:00<00:00, 16507.68it/s]\n",
      "08, 20210915, 23: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2325/2325 [00:00<00:00, 16406.85it/s]\n",
      "08, 20210915, 24: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6137/6137 [00:00<00:00, 16124.24it/s]\n",
      "08, 20210915, 25: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6947/6947 [00:00<00:00, 15992.35it/s]\n",
      "08, 20210915, 26: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3791/3791 [00:00<00:00, 15417.33it/s]\n",
      "08, 20210915, 27: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6807/6807 [00:00<00:00, 15939.45it/s]\n",
      "08, 20210915, 28: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4945/4945 [00:00<00:00, 16210.94it/s]\n",
      "08, 20210915, 29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3176/3176 [00:00<00:00, 16575.31it/s]\n",
      "08, 20210915, 30: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1613/1613 [00:00<00:00, 16704.52it/s]\n",
      "08, 20210915, 31: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4961/4961 [00:00<00:00, 15193.87it/s]\n",
      "08, 20210915, 32: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4920/4920 [00:00<00:00, 15884.90it/s]\n",
      "08, 20210915, 33: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1694/1694 [00:00<00:00, 15850.48it/s]\n",
      "08, 20210915, 34: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1720/1720 [00:00<00:00, 17506.97it/s]\n",
      "08, 20210915, 35: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5527/5527 [00:00<00:00, 15766.40it/s]\n",
      "08, 20210915, 36: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2004/2004 [00:00<00:00, 15027.22it/s]\n",
      "08, 20210915, 37: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7944/7944 [00:00<00:00, 15951.70it/s]\n",
      "08, 20210915, 38: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1717/1717 [00:00<00:00, 15958.53it/s]\n",
      "08, 20210915, 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2911/2911 [00:00<00:00, 15835.61it/s]\n",
      "08, 20210915, 40: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2638/2638 [00:00<00:00, 16204.61it/s]\n",
      "08, 20210915, 41: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2045/2045 [00:00<00:00, 15400.77it/s]\n",
      "09, 20210706, 01: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7458/7458 [00:00<00:00, 15900.85it/s]\n",
      "09, 20210706, 02: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13408/13408 [00:00<00:00, 15787.31it/s]\n",
      "09, 20210706, 03: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31522/31522 [00:02<00:00, 15712.68it/s]\n",
      "09, 20210706, 04: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22777/22777 [00:01<00:00, 15503.45it/s]\n",
      "09, 20210706, 05: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6496/6496 [00:00<00:00, 15569.38it/s]\n",
      "09, 20210706, 06: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7968/7968 [00:00<00:00, 15793.86it/s]\n",
      "09, 20210706, 07: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3219/3219 [00:00<00:00, 16118.00it/s]\n",
      "09, 20210706, 08: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6247/6247 [00:00<00:00, 15888.11it/s]\n",
      "09, 20210706, 09: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2833/2833 [00:00<00:00, 16880.42it/s]\n"
     ]
    }
   ],
   "source": [
    "x_dict = {}\n",
    "y_dict = {}\n",
    "for setting in data_settings:\n",
    "    room_num = setting['room_num']\n",
    "    date = setting['date']\n",
    "    opt = setting['option']\n",
    "    \n",
    "    dirs = sorted(glob.glob(f'{common.data_dir}/{room_num}/{date}/{opt}/*'))\n",
    "    if dirs[-1].endswith('make_csv.csv'):\n",
    "        dirs = dirs[:-1]\n",
    "\n",
    "    for path in dirs:\n",
    "        file_num = common.split_path(path)[-1]\n",
    "        csv_path = f'{path}/csv/data.csv'\n",
    "        csv_data = np.loadtxt(csv_path, delimiter=',', dtype=int, skiprows=1)\n",
    "\n",
    "        for row in tqdm(csv_data, desc=f'{room_num}, {date}, {file_num}'):\n",
    "            frame_num = row[0]\n",
    "            label1 = f'{room_num}_{file_num}_{row[1]}'\n",
    "            label2 = f'{room_num}_{file_num}_{row[2]}'\n",
    "\n",
    "            features = extract_features(frame_num, label1, label2, individuals)\n",
    "            key = f'{room_num}_{file_num}_{row[1]}_{row[2]}'\n",
    "\n",
    "            if key not in x_dict:\n",
    "                x_dict[key] = []\n",
    "                y_dict[key] = []\n",
    "\n",
    "            x_dict[key].append(features)\n",
    "            y_dict[key].append(row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c563a83-6385-4c71-b2a3-f099cf1f114e",
   "metadata": {},
   "source": [
    "## nanを穴埋めする"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05b350ab-c115-454e-ad37-ccb32a26a31f",
   "metadata": {
    "tags": []
   },
   "source": [
    "def fill_nan(x_lst, y_lst, window=3):\n",
    "    # はじめの None を飛ばす\n",
    "    for i in range(len(x_lst)):\n",
    "        if x_lst[i] is not None:\n",
    "            break\n",
    "    \n",
    "    pre_x = x_lst[i]\n",
    "    pre_y = y_lst[i]\n",
    "    \n",
    "    copy_x_lst = []\n",
    "    copy_y_lst = []\n",
    "    for x, y in zip(x_lst[i + 1:], y_lst[i + 1:]):\n",
    "        if x is not None:\n",
    "            if True in np.isnan(x):\n",
    "                x = np.where(np.isnan(x), pre_x, x).copy()\n",
    "            copy_x_lst.append(x)\n",
    "            copy_y_lst.append(y)\n",
    "            pre_x = x.copy()\n",
    "            pre_y = y\n",
    "        else:\n",
    "            # 前のフレームからコピー\n",
    "            copy_x_lst.append(pre_x)\n",
    "            copy_y_lst.append(pre_y)\n",
    "            \n",
    "    # return np.nan_to_num(copy_x_lst), copy_y_lst\n",
    "\n",
    "    # 残ったnanは移動平均で穴埋め\n",
    "    ma_x_lst = []\n",
    "    ma_y_lst = []\n",
    "    for i in range(0, len(copy_x_lst) - window + 1):\n",
    "        if copy_x_lst[i] is None:\n",
    "            print(copy_x_lst[i:i + window])\n",
    "        means = np.nanmean(copy_x_lst[i:i + window], axis=0)\n",
    "        for x, y in zip(copy_x_lst[i:i + window], copy_y_lst[i:i + window]):\n",
    "            if True in np.isnan(x):\n",
    "                x = np.where(np.isnan(x), means, x).copy()\n",
    "\n",
    "            if len(ma_x_lst) <= i + window:\n",
    "                ma_x_lst.append(x)\n",
    "                ma_y_lst.append(y)\n",
    "\n",
    "    return  np.array(ma_x_lst), np.array(ma_y_lst)\n",
    "\n",
    "\n",
    "x_dict_fill_nan = {}\n",
    "y_dict_fill_nan = {}\n",
    "for key, x_lst in tqdm(x_dict.items()):\n",
    "    y_lst = y_dict[key]\n",
    "    x_lst, y_lst = fill_nan(x_lst, y_lst, window=3)\n",
    "    \n",
    "    if len(x_lst) > 0:\n",
    "        x_dict_fill_nan[key] = x_lst\n",
    "        y_dict_fill_nan[key] = y_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0d581-b4c5-4b64-aee7-495d4b4f44d4",
   "metadata": {},
   "source": [
    "## pass以外の人を削除"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40685c96-9322-4b59-95c2-6881c0a6a24b",
   "metadata": {},
   "source": [
    "del_keys = []\n",
    "for key, y_lst in y_dict.items():\n",
    "    if 1 not in y_lst:\n",
    "        del_keys.append(key)\n",
    "\n",
    "for key in del_keys:\n",
    "    del x_dict[key]\n",
    "    del y_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6efab5-c58b-4959-b1b2-32e0bac45213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passing: 68\n",
      "not passing: 7908\n"
     ]
    }
   ],
   "source": [
    "len_pass = len([key for key, y_lst in y_dict.items() if 1 in y_lst])\n",
    "len_not_pass = len([key for key, y_lst in y_dict.items() if 1 not in y_lst])\n",
    "\n",
    "print(f'passing: {len_pass}')\n",
    "print(f'not passing: {len_not_pass}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a0f605-44bf-4709-a7db-72ec348c648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all length:452523\n",
      "passing: 2059\n",
      "not passing: 450464\n"
     ]
    }
   ],
   "source": [
    "y_lst_all = []\n",
    "for y_lst in y_dict.values():\n",
    "    y_lst_all += y_lst\n",
    "\n",
    "len_pass = len([i for i in y_lst_all if i == 1])\n",
    "len_not_pass = len([i for i in y_lst_all if i == 0])\n",
    "\n",
    "print(f'all length:{len(y_lst_all)}')\n",
    "print(f'passing: {len_pass}')\n",
    "print(f'not passing: {len_not_pass}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd9b3a-c263-4b7b-980f-f9c1f4e9a2c8",
   "metadata": {},
   "source": [
    "# 深層学習"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e854560b-7d9e-4c0d-a5e4-33c5654b426a",
   "metadata": {},
   "source": [
    "# SEQ_LEN = 30\n",
    "# n_rnn h_rnn d_rnn n_linear h_linear d_linear weight epoch batch lr    lr_rate f1_train f1_test\n",
    "  2     256   0.1   2        128,8    0.2,0    10     50    4096  0.001 0.99    0.414    0.235\n",
    "  2     256   0.1   2        128,8    0.2,0    10     66    4096  0.001 0.99    0.819    0.340\n",
    "  2     256   0.1   2        128,8    0.2,0    1      100   4096  0.001 0.99    0.529    0.396 <=\n",
    "  2     256   0.1   2        128,8    0.2,0    2      100   4096  0.001 0.99    0.701    0.300\n",
    "  2     256   0.1   2        128,8    0.2,0    3      50    4096  0.001 0.99    0.226    0.190\n",
    "  2     256   0.1   2        128,8    0.2,0    3      100   4096  0.001 0.99    0.684    0.318\n",
    "\n",
    "# SEQ_LEN = 16\n",
    "# n_rnn h_rnn d_rnn n_linear h_linear d_linear weight epoch batch lr    lr_rate f1_train f1_test\n",
    "  2     256   0.1   2        128,8    0.2,0    1      50    4096  0.001 0.99    0.389    0.315\n",
    "  2     256   0.1   2        128,8    0.2,0    1      100   4096  0.001 0.99    0.823    0.305\n",
    "  2     256   0.1   2        128,8    0.2,0    2      50    4096  0.001 0.99    0.409    0.310\n",
    "  2     256   0.1   2        128,8    0.2,0    10     50    4096  0.001 1.      0.354    0.259\n",
    "\n",
    "# SEQ_LEN = 8\n",
    "# n_rnn h_rnn d_rnn n_linear h_linear d_linear weight epoch batch lr    lr_rate f1_train f1_test\n",
    "  2     256   0.1   2        128,8    0.2,0    1      50    4096  0.001 0.99    0.480    0.351\n",
    "  2     256   0.1   2        128,8    0.2,0    1      100   4096  0.001 0.99    0.768    0.232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934b1c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cae569ef10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = len(list(x_dict.values())[0][0])\n",
    "SEQ_LEN = 30\n",
    "\n",
    "# leraning rate\n",
    "LR = 0.001\n",
    "LR_RATE = 1.0\n",
    "\n",
    "# pos weight\n",
    "POS_WEIGHT = [1., 10.]\n",
    "\n",
    "# training and data settings\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 1024 * 4\n",
    "TRAIN_RATIO = 0.65\n",
    "VAL_RATIO = 0.05\n",
    "\n",
    "config = {\n",
    "    'seq_len': SEQ_LEN,\n",
    "    'size': SIZE,\n",
    "    'n_rnns': 2,\n",
    "    'rnn_hidden_dim': 256,\n",
    "    'rnn_dropout': 0.1,\n",
    "    'n_linears': 2,\n",
    "    'hidden_dims': [128, 8],\n",
    "    'dropouts': [0.1, 0],\n",
    "    'n_classes': 2,\n",
    "    'lr': LR,\n",
    "    'lr_rate': LR_RATE,\n",
    "    'pos_weight': POS_WEIGHT,\n",
    "    'epoch': EPOCH,\n",
    "    'batch_size':BATCH_SIZE,\n",
    "    'device': device,\n",
    "}\n",
    "\n",
    "# setting random seed\n",
    "SEED = 64\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861bcb0-b6db-42ec-99c5-85885f7dcbc7",
   "metadata": {},
   "source": [
    "## データセット生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67c0601-d170-4016-a5dd-cd7b7b3959ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(x_lst, y_lst, **config):\n",
    "    seq_len = config['seq_len']\n",
    "    size = config['size']\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(x_lst) - seq_len + 1):\n",
    "        x = x_lst[i:i + seq_len]\n",
    "        x_seq.append(x)\n",
    "        y_seq.append(y_lst[i + seq_len - 1])\n",
    "    \n",
    "    return x_seq, y_seq\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_dict, y_dict, **kwargs):\n",
    "        self.x, self.y = [], []\n",
    "        for key in tqdm(x_dict.keys()):\n",
    "            x_lst = x_dict[key]\n",
    "            y_lst = y_dict[key]\n",
    "            x_seq, y_seq = create_sequence(x_lst, y_lst, **config)\n",
    "            self.x += x_seq\n",
    "            self.y += y_seq\n",
    "            \n",
    "        self.device = kwargs['device']\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            tensor(self.x[index]).float().to(self.device),\n",
    "            tensor(np.identity(2)[self.y[index]]).float().to(self.device)  # one-hot\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2ccdb9-88d7-473a-9f42-90eac8e19bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5184/5184 [00:00<00:00, 7086.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 398/398 [00:00<00:00, 43485.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2394/2394 [00:00<00:00, 68400.30it/s]\n"
     ]
    }
   ],
   "source": [
    "train_len = int(len(x_dict) * TRAIN_RATIO)\n",
    "val_len = int(len(x_dict) * VAL_RATIO)\n",
    "\n",
    "random_keys = np.random.choice(\n",
    "    list(x_dict.keys()),\n",
    "    size=len(x_dict),\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "train_keys = random_keys[:train_len]\n",
    "val_keys = random_keys[train_len:train_len + val_len]\n",
    "test_keys = random_keys[train_len + val_len:]\n",
    "\n",
    "x_train_dict = {key: x_dict[key] for key in train_keys}\n",
    "y_train_dict = {key: y_dict[key] for key in train_keys}\n",
    "train_dataset = MyDataset(x_train_dict, y_train_dict, **config)\n",
    "print(len(train_dataset))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "x_val_dict = {key: x_dict[key] for key in val_keys}\n",
    "y_val_dict = {key: y_dict[key] for key in val_keys}\n",
    "val_loader = DataLoader(\n",
    "    MyDataset(x_val_dict, y_val_dict, **config),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "x_test_dict = {key: x_dict[key] for key in test_keys}\n",
    "y_test_dict = {key: y_dict[key] for key in test_keys}\n",
    "test_loader = DataLoader(\n",
    "    MyDataset(x_test_dict, y_test_dict, **config),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7d795-5a3d-459a-9ddf-9f47fb100e22",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d57f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, **config):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # init rnn layers\n",
    "        in_dim = config['size']\n",
    "        out_dim = config['rnn_hidden_dim']\n",
    "        n_rnns = config['n_rnns']\n",
    "        rnn_dropout = config['rnn_dropout']\n",
    "        self.rnn = nn.LSTM(\n",
    "            in_dim, out_dim,\n",
    "            num_layers=n_rnns,\n",
    "            dropout=rnn_dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # init linear layers\n",
    "        self.linears = nn.Sequential()\n",
    "        for i in range(config['n_linears']):\n",
    "            if i == 0:\n",
    "                in_dim = config['rnn_hidden_dim']\n",
    "            else:\n",
    "                in_dim = config['hidden_dims'][i - 1]\n",
    "\n",
    "            out_dim = config['hidden_dims'][i]\n",
    "            dropout = config['dropouts'][i]\n",
    "            self.linears.add_module(\n",
    "                f'fc{i + 1}',\n",
    "                Linear(in_dim, out_dim, dropout)\n",
    "            )\n",
    "\n",
    "        # init output layers\n",
    "        self.output_layer = nn.Linear(config['hidden_dims'][-1], config['n_classes'])\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.rnn(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.linears(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Linear(nn.Sequential):\n",
    "    def __init__(self, in_dim, out_dim, dropout):\n",
    "        super(Linear, self).__init__(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0241b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (rnn): LSTM(4, 256, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (linears): Sequential(\n",
       "    (fc1): Linear(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fc2): Linear(\n",
       "      (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "      (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = RNNModel(**config)\n",
    "model = model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585d4040-f168-47c1-be50-5f83c4e01cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.tensor(POS_WEIGHT).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: LR_RATE ** epoch)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac6497-da5d-42c3-8cc3-907eca3aa841",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61b404",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = dict(train=[], val=[])\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    ts = time.time()\n",
    "\n",
    "    # train\n",
    "    model = model.train()\n",
    "    train_losses = []\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = criterion(pred.requires_grad_(), y)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    # validate\n",
    "    model = model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            pred = model(x)\n",
    "            \n",
    "            loss = criterion(pred.requires_grad_(), y)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    te = time.time()\n",
    "    train_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(val_losses)\n",
    "    history['train'].append(train_loss)\n",
    "    history['val'].append(val_loss)\n",
    "\n",
    "    print(f\"Epoch[{epoch}/{(EPOCH)}] train loss: {train_loss:.5f}, val loss: {val_loss:.5f}, lr: {lr:.7f}, time: {te - ts:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabef58-9d3d-494a-8437-1dfde06e192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['train'])\n",
    "plt.plot(history['val'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Loss over training epochs')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a60fd-b6fe-4f37-9dea-75091bdeaf20",
   "metadata": {},
   "source": [
    "## 検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78835d0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_train = []\n",
    "pred_all_train = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in train_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "        \n",
    "        x, _ = create_sequence(x_lst, y_lst, **config)\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        \n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "\n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[SEQ_LEN - 1:]\n",
    "        y_lst = y_lst[SEQ_LEN - 1:]\n",
    "            \n",
    "        y_all_train += y_lst\n",
    "        pred_all_train += pred.tolist()\n",
    "        \n",
    "        if 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        plt.figure(figsize=(10, 1.5))\n",
    "        # plt.rcParams[\"font.size\"] = 20\n",
    "        # plt.rcParams[\"font.family\"] = 'Times New Roman'\n",
    "        plt.plot(pred, label='pred')\n",
    "        plt.plot(y_lst, linestyle=':', label='ground truth')\n",
    "        for i, x in enumerate(x_lst.T):\n",
    "            plt.plot(x, alpha=0.4, label=columns[i])\n",
    "        plt.ylim((-0.05, 1.05))\n",
    "        plt.yticks([0, 1])\n",
    "        plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
    "        plt.subplots_adjust(left=0.04, right=1, bottom=0.1, top=1)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b575e4-2fd1-45db-b456-b8dcf21de3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_train, pred_all_train)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_train, pred_all_train)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_train, pred_all_train)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_train, pred_all_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2b46c-50ba-4ff0-bbf4-ec82af225199",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_all_test = []\n",
    "pred_all_test = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for key in test_keys:\n",
    "        x_lst = np.array(x_dict[key])\n",
    "        y_lst = y_dict[key]\n",
    "\n",
    "        x, _ = create_sequence(x_lst, y_lst, **config)\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "\n",
    "        x_lst = x_lst[SEQ_LEN - 1:]\n",
    "        y_lst = y_lst[SEQ_LEN - 1:]\n",
    "        \n",
    "        y_all_test += y_lst\n",
    "        pred_all_test += pred.tolist()\n",
    "        \n",
    "        if 1 not in pred and 1 not in y_lst:\n",
    "            continue\n",
    "            \n",
    "        print(key)\n",
    "        plt.figure(figsize=(10, 1.5))\n",
    "        # plt.rcParams[\"font.size\"] = 20\n",
    "        # plt.rcParams[\"font.family\"] = 'Times New Roman'\n",
    "        plt.plot(pred, label='pred')\n",
    "        plt.plot(y_lst, linestyle=':', label='ground truth')\n",
    "        for i, x in enumerate(x_lst.T):\n",
    "            plt.plot(x, alpha=0.4, label=columns[i])\n",
    "        plt.ylim((-0.05, 1.05))\n",
    "        plt.yticks([0, 1])\n",
    "        plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
    "        plt.subplots_adjust(left=0.04, right=1, bottom=0.1, top=1)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadc434-fed3-4ab8-bd91-d161ce278b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {:.3f}'.format(accuracy_score(y_all_test, pred_all_test)))\n",
    "print('precision: {:.3f}'.format(precision_score(y_all_test, pred_all_test)))\n",
    "print('recall: {:.3f}'.format(recall_score(y_all_test, pred_all_test)))\n",
    "print('f1_score: {:.3f}'.format(f1_score(y_all_test, pred_all_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b626c-3dfb-489f-ba0b-367942a43bb1",
   "metadata": {},
   "source": [
    "## モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc898c47-e62c-462e-871b-5a98012f51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{common.root}/model/checkpoint/pass_model_lstm.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7667da-c48c-40e8-beb8-261c8e6b24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{common.root}/model/config/pass_model_lstm.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7b174-dd28-4aa8-8d26-9bc4427a0163",
   "metadata": {},
   "source": [
    "# グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60011bb5-8a2a-497d-8f5e-a1fe6b56b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'seq_len': [8, 16, 30],\n",
    "    'n_rnns': [1, 2, 3],\n",
    "    'pos_weight': np.arange(1, 11, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37fb8392-e430-4972-ad71-c69b886a4f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5583/5583 [00:00<00:00, 69788.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2393/2393 [00:00<00:00, 70379.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_len = int(len(x_dict) * 0.7)\n",
    "\n",
    "random_keys = np.random.choice(\n",
    "    list(x_dict.keys()),\n",
    "    size=len(x_dict),\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "train_keys = random_keys[:train_len]\n",
    "test_keys = random_keys[train_len:]\n",
    "\n",
    "x_train_dict = {key: x_dict[key] for key in train_keys}\n",
    "y_train_dict = {key: y_dict[key] for key in train_keys}\n",
    "train_loader_gs = DataLoader(\n",
    "    MyDataset(x_train_dict, y_train_dict, **config),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "x_test_dict = {key: x_dict[key] for key in test_keys}\n",
    "y_test_dict = {key: y_dict[key] for key in test_keys}\n",
    "test_loader_gs = DataLoader(\n",
    "    MyDataset(x_test_dict, y_test_dict, **config),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d2d2b87-c2e0-4684-8178-c3ace42310c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(config):\n",
    "    model = None\n",
    "    torch.cuda.empty_cache()\n",
    "    model = RNNModel(**config)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_loss(pos_weight):\n",
    "    pos_weight = torch.tensor(pos_weight).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def init_optim(lr, rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: rate ** epoch)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def scores(model, loader):\n",
    "    preds, y_all = [], []\n",
    "    for x, y in loader:\n",
    "        pred = model(x)\n",
    "        pred = pred.max(1)[1]\n",
    "        pred = pred.cpu().numpy().tolist()\n",
    "        y = y.cpu().numpy().T[1].astype(int).tolist()\n",
    "        preds += pred\n",
    "        y_all += y\n",
    "    \n",
    "    accuracy = accuracy_score(y_all, preds)\n",
    "    precision = precision_score(y_all, preds)\n",
    "    recall = recall_score(y_all, preds)\n",
    "    f1 = f1_score(y_all, preds)\n",
    "    print(\n",
    "        'accuracy: {:.3f}'.format(accuracy),\n",
    "        'precision: {:.3f}'.format(precision),\n",
    "        'recall: {:.3f}'.format(recall),\n",
    "        'f1_score: {:.3f}'.format(f1)\n",
    "    )\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "    \n",
    "def training(model, criterion, optimizer, scheduler):\n",
    "    for epoch in tqdm(range(1, 50 + 1)):\n",
    "        # train\n",
    "        model = model.train()\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        for x, y in train_loader_gs:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "            loss = criterion(pred.requires_grad_(), y)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print('train scores')\n",
    "        scores(model, train_loader_gs)\n",
    "        print('test scores')\n",
    "        acc, pre, rcl, f1 = scores(model, test_loader_gs)\n",
    "    \n",
    "    return acc, pre, rcl, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9a76f-fd7b-4bde-8e77-33dba46fd26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_len': 8, 'n_rnns': 1, 'weight': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████████████████▉                                                                                                            | 13/50 [11:05<31:37, 51.30s/it]"
     ]
    }
   ],
   "source": [
    "max_acc = (0, None)\n",
    "max_pre = (0, None)\n",
    "max_rcl = (0, None)\n",
    "max_f1 = (0, None)\n",
    "\n",
    "for seq_len in params['seq_len']:\n",
    "    for n_rnns in params['n_rnns']:\n",
    "        for weight in params['pos_weight']:\n",
    "            param = dict(seq_len=seq_len, n_rnns=n_rnns, weight=weight)\n",
    "            print(param)\n",
    "            \n",
    "            config = {\n",
    "                'seq_len': seq_len,\n",
    "                'size': SIZE,\n",
    "                'n_rnns': n_rnns,\n",
    "                'rnn_hidden_dim': 256,\n",
    "                'rnn_dropout': 0.1,\n",
    "                'n_linears': 2,\n",
    "                'hidden_dims': [128, 8],\n",
    "                'dropouts': [0.1, 0],\n",
    "                'n_classes': 2,\n",
    "                'device': device,\n",
    "            }\n",
    "            model = init_model(config)\n",
    "            criterion = init_loss([1, weight])\n",
    "            optimizer, scheduler = init_optim(LR, LR_RATE)\n",
    "            \n",
    "            acc, pre, rcl, f1 = training(model, criterion, optimizer, scheduler)\n",
    "            if acc > max_acc[0]:\n",
    "                max_acc[0] = acc\n",
    "                max_acc[1] = param\n",
    "            if pew > max_pre[0]:\n",
    "                max_pre[0] = pre\n",
    "                max_pre[1] = param\n",
    "            if rcl > max_rcl[0]:\n",
    "                max_rcl[0] = rcl\n",
    "                max_rcl[1] = param\n",
    "            if f1 > max_f1[0]:\n",
    "                max_f1[0] = f1\n",
    "                max_f1[1] = param\n",
    "            \n",
    "\n",
    "print('max accuracy: ', max_acc[0], max_acc[1])\n",
    "print('max precision: ', max_pre[0], max_pre[1])\n",
    "print('max recall: ', max_rcl[0], max_rcl[1])\n",
    "print('max f1: ', max_f1[0], max_f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09014435-9f9f-4188-af61-d191be5d9b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
