{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/tmp/sh076018/mishare/Research Projects/yokoyama/notebooks')\n",
    "\n",
    "#ビデオファイルパス\n",
    "video_file_name = '09_05_Survey_20210706_082000_02.mp4'\n",
    "video_path = os.path.join('/tmp/sh076018/mishare/Research Projects/yokoyama/video_raw/', video_file_name)\n",
    "\n",
    "# 出力ディレクトリ\n",
    "out_dir = os.path.join(\n",
    "    '/tmp/sh076018/mishare/Research Projects/yokoyama/data/',\n",
    "    os.path.basename(video_path).replace('.mp4', ''))\n",
    "\n",
    "# AlphaPoseのモデルパス\n",
    "model_dir = '/tmp/sh076018/mishare/Research Projects/yokoyama/model/alphapose/'\n",
    "model_files = {'cfg': '256x192_w32_lr1e-3.yaml', 'checkpoint': 'hrnet_w32_256x192.pth'}\n",
    "cfg_path = os.path.join(model_dir, model_files['cfg'])\n",
    "checkpoint_path = os.path.join(model_dir, model_files['checkpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pose model from /tmp/sh076018/mishare/Research Projects/yokoyama/model/alphapose/hrnet_w32_256x192.pth...\n",
      "Loading YOLO model..\n",
      "  0%|                                     | 15/285205 [00:01<4:48:52, 16.45it/s][ERROR:0] global /tmp/pip-req-build-l1r0y34w/opencv/modules/videoio/src/cap_ffmpeg_impl.hpp (2719) open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0] global /tmp/pip-req-build-l1r0y34w/opencv/modules/videoio/src/cap_ffmpeg_impl.hpp (2791) open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n",
      "Try to use other video encoders...\n",
      "  1%|▎                                 | 2958/285205 [17:08<32:33:35,  2.41it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 324, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to open shared memory object </torch_42078_3638974698> in read-write mode\n",
      "  3%|▉                                 | 7605/285205 [47:38<28:09:42,  2.74it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 324, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to open shared memory object </torch_42078_772983182> in read-write mode\n",
      "  7%|██▏                            | 20429/285205 [1:59:44<23:20:11,  3.15it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 324, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to open shared memory object </torch_42078_3107233260> in read-write mode\n",
      "  8%|██▎                            | 21780/285205 [2:06:36<20:16:16,  3.61it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 324, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to open shared memory object </torch_42078_1115566534> in read-write mode\n",
      "  9%|██▊                            | 25424/285205 [2:25:34<19:37:04,  3.68it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 324, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to open shared memory object </torch_42078_2002397142> in read-write mode\n",
      " 12%|███▌                           | 32915/285205 [3:02:50<23:08:52,  3.03it/s]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 236, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 324, in reduce_storage\n",
      "    metadata = storage._share_filename_()\n",
      "RuntimeError: unable to open shared memory object </torch_42078_2492494837> in read-write mode\n",
      " 14%|████▍                          | 40713/285205 [3:44:04<21:04:42,  3.22it/s]"
     ]
    }
   ],
   "source": [
    "# os.chdir('/tmp/sh076018/mishare/Research Projects/yokoyama/alphapose')\n",
    "os.chdir('/opt/alphapose')\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python3 scripts/demo_inference.py\\\n",
    "    --cfg \"$cfg_path\"\\\n",
    "    --checkpoint \"$checkpoint_path\"\\\n",
    "    --outdir \"$out_dir\"\\\n",
    "    --eval\\\n",
    "    --video \"$video_path\"\\\n",
    "    --save_video\\\n",
    "#     --vis_fast\\\n",
    "#     --posebatch 80\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
